purpose for supplying it to police or even other government agencies right again like i spoke about daily 2 this.
is a recent example now if you ask it to generate images of success you can see that most of.
the images are of males if you ask it to generate images about sadness most of the females are about.
most of the images are about females right so this kind of gender bias or bias towards certain sections of.
the population is very common in these most deep learning models because of the bias and the training data that.
they have been trained with right and this again happens in various domains right so now if you use an.
ai model to decide whether you should give loan to someone or not again it would be biased towards certain.
sections of the society because it would be the case that in its training data there were certain sections which.
did not often pay their loans back right so it's biased for example against women migrants or people of color.