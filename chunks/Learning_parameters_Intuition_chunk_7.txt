still applies right because you just want to compute the derivative of the loss function with respect to each parameter.
and update the parameter accordingly right so insects now our delta theta looks much more complex so we have delta.
t the loss derivative of the loss partial derivative of the loss function with respect to w 1 1 1.
that is the first weight in w1 matrix all the way up to the n square weights that you have.
in the w1 matrix similarly the n square weights that you have in the w2 matrix similarly the n into.
k weights that you had in the last layer similarly the n biases that you had in each layer and.
the k biases that you had in the last layer right so this is not like a something cross n.
matrix right because this last row has only k right so it will not be like uh i just put.
everything together in one collection i'm not saying that this is a matrix right this is just a collection of.