did not often pay their loans back right so it's biased for example against women migrants or people of color.
right which is not fair right i mean you have to judge each case individually and not based on similar.
uh things that you have seen in the past right so there's and definitely not like two people who have.
the same profile but only differ in their terms of their skin color you cannot have a different decision for.
them right so that's what is happening in many of these models hence this calls for being fair and responsible.
and there is again a challenge right so now again people are becoming aware of these and trying to push.
research in these areas so stanford has this ai audit challenge where the idea is to build models which are.
compliant and do not do any illegal discrimination okay so while we are talking about fairness and responsible ai there.
is also another axis around which we need to talk about being responsible right so i was talking about the.