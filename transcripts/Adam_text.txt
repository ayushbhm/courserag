foreign [Music] okay so we have seen three adaptive algorithms so far one the first one was at a grad which had this problem of rapidly killing the learning rate which was solved by RMS prop by making using an exponentially averaged history but still it is the problem of dependency on the initial learning rate so then we saw add a Delta which got rid of this initial learning rate and made the effective learning rate a ratio of two histories right now continuing in our algorithms on in continuing our journey towards the algorithms for with adaptive learning rates we'll now look at Adam which is expands to Adaptive moments and the intuition here is that do everything that RMS prop does right to solve the DK problem of ADA grad which is to use an exponentially weighted history in addition use a cumulative history of the gradients as you used in a kind of a momentum based algorithm side where you use uh exponentially weighted history of the gradients as opposed to only relying on the current gradient right so this is what my uh uh so this is what my current gradient is but instead of only relying on the current gradient I'm looking at the history of the gradients right this is similar to what we have seen in the momentum based gradient descent and yeah this is classical momentum then you do something known as bias correction I'll just tell you the formula for now and not comment much on it as of now right so it's at time step T once you have computed empty then you compute the bias corrected value of empty which is empty hat which is just empty divided by 1 minus beta 1 raised to T then we have VT which was the usual VT which acted as a denominator for the effective learning rate this is the same as what we had in RMS prop right so as I said do everything that RMS prop does plus just add this classical momentum term right that's what Atom does so again you have a bias correction for VT also so you'll compute a VT hat which is VT divided by 1 minus beta 2 raised to T right and then your update is WT minus the effective learning rate into this uh moving average right as you have in momentum which is the exponentially weighted average right so this is what uh the update rules update equations for atom look like and here this is looking at the L2 Norm what we mean by that is that if you have or rather exponentially weighted average L2 numerate so you have uh V 0 it is simply Delta W 0 square right because initially you don't have any other term or rather 1 minus into one minus beta right and then if you look at VT it will have Delta W 0 square appropriately multiplied by some Decay Factor then Delta W 1 square again multiplied by some Decay factor and all the way up to the current gradient right multiplied by 1 minus beta right so if I just ignore the Decay factors and if I treat this as a collection of values as a vector then what I'm looking at is the L2 Norm of that Vector right so that's what I uh what is the meaning here and it's just not an L2 Norm it's an exponentially weighted L2 Norm that you are taking right so that's what you need to remember if you look at VT it has all the terms from Delta W 0 square all the way up to Delta w t square and they are exponentially weighted and you are taking the square so that's the same as taking like an exponentially weighted L2 Norm of a certain Vector right so that's what I wanted to indicate here uh and why am I saying that is something that will become clear I think a little bit later in the discussion and typical values for beta1 and beta 2 are beta 1 is 0.9 and beta2 is 0.999 so since beta 2 is 0.999 uh so this 1 minus beta 2 is essentially a very small quantity right so you're taking a very small fraction of the current uh gradient okay so now let's learn Adam and try to compare it with the other algorithms that we have yeah so let me just see again yeah so in this case again Ada Delta reached the conversions fast but atom is also uh reached faster than the other algorithms and RMS prop as usual has the uh convergence problem right so this is not to show that okay Adam is always going to be better than all the other algorithms but I'm just showing how Adam is behaving in this case right and there's a difference between atom and Delta uh atom is more in the line of RMS prop uh with the momentum whereas Adder Delta also and this uh adaptive effective learning rate whereas here you still have the initial learning rate right so you still have ETA here okay yeah so you saw what happens there and it seems to behave uh reasonably um okay so now I had mentioned that this Adam had this bias correction term right so uh the other Concepts in the equations of Adam you already know right you already know what VT does it kind of decays the learning rate you also know what Mt does right Mt is the classical momentum term the only new thing which has come up in Adam is this bias correction right which is not uh clear to us why we are doing that bias correction right so let's see why we are doing that bias correction right so these are the update equations for uh atom so note that we are taking like a running average of empty right we are in in Mt we are taking a running average of the gradients right so what do I mean by taking a running average of the gradients like I have the current gradient I'm giving it some weightage and I'm also accumulating the history so the reason we are doing this is that we don't want to rely too much on the current gradient right because you might get a sudden High gradient and then you might take a very large step and you might not want to rely too much on the current gradient this is the same explanation as we have in momentum where you want to keep looking at the history if I am constantly moving in a direction then I want to keep some weightage for the history also and then not make sudden movements based on just the current derivative right so that's what that's why you have this exponentially weighted average so that you have more weightage for the history because history has accumulated over time and less weightage for the current point in time gradient right so so one way of looking at this is that you are actually right what you want in empty is that you want to look at the expected value of the gradient as opposed to this current value of the gradient right so instead of just looking at the current gradient I would have ideally wanted to look at the expected value right so remember that our true gradient is actually a sum over all the data points that we have right but here we are going to do mini batch or some such version and say we are doing stochastic in the worst case right we are just looking at one data point then I don't want to make decisions based on this one data point but I would like to be closer to the mean of the gradients or the expected value of the gradients right and this exponentially weighted average is also trying to capture some kind of an average right now the question is whether this exponentially weighted average is close to the expected value of the gradient right because I am taking a average and exponentially moving average is that close to the expected value because ideally I would wanted the expected value because that would tell me over all the data points if I had taken all of them what would my gradient be right but I'm not able to take the expected value for because there are large number of data points right so what that means is instead of expected value of the derivative we are Computing empty as some kind of an average right so expectation you could think of expectation as the mean or the average but instead of computing the true expectation we are Computing some empty which is an exponentially moving average ideally we would want that the expected value of empty is the same as the expected value of the derivative itself of the gradient itself right this is what we would want ideally now let us see if that is really the case that is that happening if that's happening then perhaps we don't need to do anything right so remember the momentum equations that we had where we had u t is equal to Beta U T minus 1 plus Delta WT now in and when we had expanded out those equations that you can go back and check those videos uh we had so we had written it as u0 is equal to uh Delta W 0 U1 is equal to Beta times Delta W 0 plus Delta W 1 then U2 is equal to Beta Square Times Delta W 0 plus beta times Delta W1 plus Delta W 2 and so on right and this entire thing is essentially captured by this formula and so you can go back and look at those videos but now I've in fact already explained it here itself so you know what what I am talking about okay we now have in Adam we have a slight modification that we have uh beta1 and then 1 minus beta here right so here we only had the beta term we only had the beta term here but in atom we have beta and then this is also 1 minus beta right so we will arrive at a similar formula but just note that this 1 minus beta is there so let's see at what formula do we arrive at in the case of Adam so we'll have Mt is beta into Mt minus 1 so this is the 1 minus beta so m0 is 0 M1 is going to be this M2 is going to be this and again if I substitute uh the value of so what I did here is that I started off with uh can I move this [Music] this yeah I started off with M 0 equal to 0 then my M1 was 1 minus beta times Delta W 1 m 2 was beta into M1 plus 1 minus beta into Delta W 2 but then I have substituted the value of M1 as 1 minus beta into Delta W 1 and I'll keep doing this right so as I keep doing this let's see where I reach I'll again reach at some kind of a formula and so M3 is going to be this and if I expand it I get this and so now if I look at M3 it's actually 1 minus beta the 1 minus beta factor I can take out and it is time Step 1 2 3 beta raised to T minus Tau into the derivative at that time step right so that's what exactly what is happening here so I have the 1 minus beta term which I have taken out common then I have for t equal to 1 I have beta square into derivative of letter one right then I have beta into derivative of Delta W 2 and then I just have Delta W3 right so for 3 this would be 3 minus 3 which would become 0 so the beta Factor would disappear and you'll just have Delta W3 for 2 it would be uh 3 minus 2 so beta raised to 3 minus 2 which is the same as beta and then you will have the Delta W 2 here so this is how the formula has been arrived at so in general for the tth time step I am now ready to write the formula the formula would just be 1 minus beta of factor of 1 minus beta being common right and then beta raised to T minus Tau Delta W2 and it's very similar to this formula except that you had this 1 minus beta term which has shown up on this formula also right so nothing great here don't to worry too much if you have not understood this right away you can go back and look at the steps and you can derive this formula on your own right so I've derived the formula for Mt and this is important for the rest of the discussion that we'll have okay so now let's look at okay now let's take the expectation on both sides that I have empty on one side and I have uh the Delta WT quantity on the other side so I'm going to take expectation on both sides so expectation of m t is equal to the expected value of this expression now I'll just take the constants out and move the expectation inside so the expectation so 1 minus beta here will come out because it's a constant then I have the expectation of a sum which is the same as the sum of an expectation okay foreign and now again the beta term will come out and the expectation goes inside and now what I'm going to assume is that all the WTS they come from the same distribution right because I have what does that mean right so what does the distribution mean in this case so you could think of hey the gradient itself could have different values right and that those values could come from some distribution right so these are your derivative values on the x axis and you have a distribution that means certain values here have a higher density as opposed to other values right and now at every time step because your updates are changing and your weights are changing and you're moving along uh the loss surface this distribution might be different right at some time steps you might expect more smaller gradients at terms time trips you might expect larger gradients but we are making a simplifying assumption here that every time step this distribution looks the same right so whatever what does this distribution come from where does the randomness come from so it comes from the data point that I'm picking up right I'm picking up random data points at every time step so depending on the time data point that I have picked up my derivatives might be different and this is the distribution that I expect them to follow right and this distribution might change at different time steps but I am making this assumption that all at all time steps the distribution Remains the Same that means the expected value at any time step is equal to the same way so I am clocking that expected value of is the same for all the time steps that's one simplifying assumption that I have made and under that assumption now let's see where we reach so now we have made this assumption that all the derivatives were the same so then we have this expected value of delta w t now I can just it's it does not depend on the time safety anymore right so I can take it outside the summation so then I have 1 minus beta into expected value of delta W into that summation that I had now this summation looks familiar it's a summation of a series and this is beta raised to T minus 1 plus beta raised to T minus 2 all the way up to Beta 0 and the sum of that series is just going to be 1 minus beta T divided by 1 minus beta raised to T divided by 1 minus beta of course so now I get this equation so the expected value of Mt is actually the expected value of the derivative into 1 minus beta T so now if I had taken the expected value of m t by 1 minus beta T then I would have got the expected value of the grade right hence I need this bias correction I am just dividing the value of m t why this term 1 minus beta T because if I do that now this is actually my empty hat so now what this is telling me is that the expected value of empty hat is this same as the expected value of the derivative right so that's what I am doing this bias correction and you can have the similar derivation for the value of VT also right so that's why we have to use bias correction in Adam so that's the main point of discussion when we are talking about Adam right why do you need a bias correction all the other things in the equations are familiar one is related to momentum the other VT is related to decaying the learning rate in the denominator and again the vth self is an exponentially moving average as we had justified in the case of RMS prop right so there are no other unknown or New Concepts in the equation of atom but this bias correction is the main New Concept which we have just understood why to do that okay so now let's see what would happen if we don't do bias correction right so we'll again look at the equations put in some values and try to see what happens right so this is the equation for VT okay and now suppose Delta W naught is equal to 0.1 okay uh so now V naught is going to be beta 2 times 0 because VT minus 1 was 0 and then 0.001 times 0.1 Square so it's going to be 0.0001 okay and now ETA T the effective learning rate is going to be 1 divided by the square root of this which is going to be 316.22 right so it already looks a very high learning rate to me right now let's see what V2 would be V2 would be 0.999 into V naught plus 0.01 into 0 square and that would give me this quantity okay and that is again a reasonably High Learning array right so what we are seeing is that uh in the absence of bias correction this is not bias corrected I just took VT I did not take VT hat right please note that so in the absence of bias correction as the paper says uh your initial steps could be very large because your initial learning rate would be very high but now if I had done bias correction okay and I had the same situation my w naught was 0.1 so now V naught is this the bias collected value is 0.01 okay and now if I substitute this bias corrected value in ETA my effective learning rate is 10 as opposed to 316 here right similarly V2 gives me a certain value if I bias corrected it I get certain value and now my learning rate is 13.8 as opposed to 316 here right so in the bias correction when I'm doing bias correction my initial learning rates are not becoming very high right so that's why you need a bias correction to make sure that initially you are not doing some very rapid movements because that could be faulty and we'll see also through an example what happens right so let's uh look at this plot here so here I'm going to compare what happens when you have Adam with bias correction and Adam without bias correction and remember our understanding is that if you don't use bias correction the initial updates would be very high that means the algorithm would move very fast right so let's see if that is happening so notice that this blue curve corresponding to atom without bias correction would make very large initial updates that's what we expect so let's see if that is happening and that is indeed the case right it has like gone very fast ahead and then it had to come back right it still converts probably uh easily in this example right because this is a toy example and it had come came back from the valley but you could imagine situations where after making an initial update it would enter some region of the Lost surface from which a recovery might be difficult right it would have reached a region where in that region whatever Minima you could get would perhaps be much higher than what you could have got otherwise right so hence this initially the learning rate is uh very high uh in the case when you do not use bias connection right and that's what you're seeing here in these plots also so let's understand these plots so when we don't have bias correction you see that your learning rates are higher right there on this scale you have values which are 2 2.5 and so on whereas when you use bias correction your learning rates initially are smaller and then initially the learning rate was uh large uh and then it starts decaying and in the case of I battum with bias correction so remember this brown or the red curve actually corresponds to the learning rate for w and W was the direction which was sparse so as it uh came close to the Minima and it went into the valley it still had to make some updates for w so the learning rate was still increasing which is what we would want right so this atom with bias correction was able to adjust easier whereas this guy had some initial very high learning rate and then it had to follow some trajectory of course both of them converged that is not a problem but this is just to show that with without bias correction your initial learning rate could be very high so I'll stop here uh with the discussion on Adam and now uh we'll look at uh in the next half an hour or so we'll look at some variants of atom or maybe just one or two variants of atom okay thank you so welcome back uh and we were talking about Adam in the last lecture and I would just like to say a few more things about the bias kind Direction in Adam which may again relate to things that we are going to do today so I'll start with that and then I'll go to the next algorithm which is going to be Max prop right so let's start with uh let's just quickly talk about bias correction again right so one way of looking at uh what is happening uh in Adam is that or in many of these gradient descent based algorithms is that so you have these uh on the x-axis I have the number of iterations are epochs right and at every iteration maybe from a batch or in a stochastic from a mini batch or in a stochastic manner I am Computing the gradients right so let's uh say that and there is some Randomness in this there's some noise in this because it depends on the batch that I have picked up right so now the batch is not the mini batch is not a representation of the entire data so depending on how good this many batch is a representation of that entire data the gradients that I compute from this mini batch may vary as compared to what I would have gotten from the full match right so here what I'm trying to illustrate is that suppose I had computed the derivatives from the full batch right suppose the red function here is what my true derivative function would have looked like from time step 0 to time step 100 right but since I'm doing this mini batch version of the algorithms I'm Computing the derivatives from a smaller batch and hence I might get noisy estimates so you can see that every time step so this is the gradient that I computed at time step 0 this is at one this is a two and so on it's every Point here corresponds to one time step right so it's 0 200 so there are 100 points here right uh now uh as you can see that it's like kind of varying right it's uh not it's close to the true derivatives but also there is some noise right you see some up and down a movement there right and one way of dealing with this is to kind of say that instead of just relying on this gradient at this time step I will take the average of all the gradients that I have taken so far right or I would take the moving average of all the gradients so instead of just relying on this point for example this should be clear right suppose instead of relying on this value here alone let me just use a different color if I take like an average of things which fall in this window right and this is the same as saying that I mean an exponential average is almost similar like to taking an average in a small window because anyways outside this window your beta powers are so small that those points won't have much value right so here is you are kind of re-estimating uh the average in the case of empty you're writing it as beta into Mt minus 1 plus 1 minus beta into the current uh derivative right so the current derivative is this one blue point that you have instead of relying on that blue point you are also taking an exponentially weighted average of the history so this is your way of kind of uh accounting for the fact that the current batch could be uh noisy so hence let me look at the history also and kind of re-estimate this point right now if you don't do bias correction so now what I'm going to do is that for every black point I am going to compute the new value of that Black Point using this equation that means I'm going to compute this weighted history right so at time step 40 I have 39 Blue Points below it and I'm going to take the value of each of those 39 blue points and I will say that beta raised to 39 into the value at time step or beta raised to 40 I guess right maybe 39 or 40 whatever that power comes to into the value at time step 0 right then beta raised to 38 into the value of time step T1 all the way up to 1 minus beta into the value at this t48 time step right so my new value is going to be uh this exponentially weighted average right that's what I'm going to do so let's see if I plot that so now for each of these Blue Points I could compute the new uh exponentially weighted uh value and then I can plot that right so let me see what happens if I plot that so this is what happens if I plot that without the bias correction right so what happens is that I get you can see that my black curve now is a bit farther away from the red curve at least during the initial time steps right and yesterday also we had seen that during initial times test we have a problem when we use bias correction so why does that happen let's try to understand that so so our formula is beta into Mt minus 1 plus 1 minus beta into the current time step value right so that's it the Delta w t right now at time step 0 my Delta w t was around 1 right but my Beta is 0.999 and this is 1 minus beta so this is going to be 0.001 right and my m t minus 1 is 0 because I initialize at like so m t minus 1 since T is equal to 0 this is going to be M minus 1 and that I have initialized to 0 right so this whole sum moves towards zero it becomes very small and then the same thing keeps repeating right because in the next time step again now at time step uh one again my value was around say 0.8 right so then I have 1 minus beta into 0.8 right and plus beta into my history so far which was around say point zero zero one right and now again this 1 minus beta is a very small value so that's why it will stay towards close to zero and it'll take a while to then start coming close to the two values because after a while now this is your history and all these initial parts are getting very very small weightage and these new guys are getting higher weightage so then slowly it kind of gets rid of its history because of the large power of beta right and then it starts relying more on the recent guys and those recent guys are all farther away from zero so then it also starts coming close to the true curve right so that's why what happens if you don't use bias correction now the same thing if I had used bias correction this is what will happen right so now if I use bias correction then it gets divided by that one minus beta factor and then I don't have a problem right so in particular what happens right so I'll show you so my M 0 is minus 1 okay and my Mt is going to be beta into oh sorry m z sorry what am I seeing M minus 1 is 0 because I initialize it as 0 my history uh is initialized as a 0 then plus 1 minus beta into m t now at time step 0 uh uh my value is 0.5 right so this uh yeah so this value is 0.5 and this term is going to disappear right so I'll get 1 minus beta uh into 0.5 that's what my Mt is going to be okay the pen is not working well that's what my Mt is going to be and my M hat T which is the bias corrected guy is going to be Mt divided by 1 minus beta raised to 1 in this case and so now these two betas will cancel and I get 0.5 and hence my approximation is close to the True Value and now it stays like that right because it does not have this weight of 0 pulling it down at earlier it it started off at zero then it got stuck there and it took a while to get the shape of the function but now it has started from the right point and it's now closer to the uh function right so that's that's what happens in the case of uh exponentially moving average and that's why we use this bias correction in the case of atom okay uh as we are done with this so I'd skipped this part yesterday now the rest of the stuff of Adam we have already done and we already did this we looked at multiple explanations for why the initial uh updates are going to be larger right so we saw this these derivations then we saw this plot all of that is done right