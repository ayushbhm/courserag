foreign [Music] welcome back so we we cover are we currently right so we started with a simple Network which was only one neuron and he had two weights W and B and today for the first five ten minutes I'll actually revisit that and we'll you learn about the gradient descent algorithm for learning the parameters of this simple Network right and then we took this idea and went to a more complex setup when instead of a single one neurons with just two weights wnb we had a very deep neural network with many arbitrary number of hidden layers and arbitrary number of neurons in each layer and we saw that the same gradient descent algorithm we could extend it for this complex case also using what is known as back propagation and black propagation is essentially about Computing the gradients or the partial derivatives or of the loss function with respect to the parameters in an efficient manner right and we saw that we just move one layer at a time in the backward Direction in so that at every point we already have whatever we need to compute the derivative of the loss function with respect to that element in the chain right so first of all we had said that the derivative of the loss function with respect to any parameter can be expressed as a chain Rule and then you just keep Computing every element in that chain and the idea was that any single element is this change is easy to compute and you just keep doing that right and we came up with a very small algorithm right which like four or five steps and you just compute the gradients of the entire weight Vector entire bias Vector at one go for all the weights and biases in the network right now while doing that we had used the gradient descent algorithm right now today what we are going to do is we are going to look at various variants of the gradient descent algorithm and so to do that we'll first start with quickly revising the gradient descent algorithm that we had done and then we'll point out some peculiarities that we see there and then we'll keep trying to fix those peculiarities right we'll say okay this looks bad let's try to work around it we'll propose something new then we'll say okay this is fine but this has some other problems let's try to fix that fix that and it'll keep going to a series of uh algorithms which are all variants of the basic gradient descent algorithm okay so that's the agenda so with that the first 5-10 minutes is going to be like at a Brisk Pace where I have these around 30 slides on gradient descent which we have already covered uh in the lecture three uh like lecture three meaning the slide which had the title lecture three uh so those I'm going to rush through right is just to give you the context of what was gradient descent and then I'll start with identifying some problems in gradient descent and then move on to the other algorithms okay so don't uh be worried if you're thinking I'm going to first that's the intention because we've already done it in the past okay um yeah I should mention these acknowledgments I got the ideas for some of the visualizations uh from uh the videos by Ryan Harris this is long back uh six seven years I had seen that and then uh those were there initially in whatever visualizations they had the idea of this sort of uh the new version of this course is to make some of those visualizations even uh better so that's why I hope you have been able to do that and some of the content is also inspired by uh the course which Henry carpathy uh used to teach in cs231n right so I just wanted to make sure I mentioned those acknowledgments okay so let's uh start so this part as I said module 5.1 and 5.2 is just a reputation so we had looked at the guesswork algorithm so this is what our setup was we had a simple network with two ways W and B and we were interested in learning these uh weights right and what was uh the intention that we wanted to find a sigmoid uh function right or rather we wanted the weights to be such that that when I plot the sigmoid function using those weights then these two points should lie on that sigmoid function right that's what uh training uh meant that's what we meant by uh training and to do that what we decided is okay let's start with some uh random guesswork right so I was trying to take these W comma B values that you see here right and I was trying to move them this slider so that the values of w and B change and as every time I do that this blue sigmoid curve that you see was changing and ultimately I was able to come up with some curve which was passing through both the point so this was just random guess I used to move the w a bit okay it's changing like this I don't like it maybe I want it to come a bit lower so maybe let's move it in the other direction and so on right and uh then we were trying to connect this intuition right any one of you who takes this plot and tries to adjust it will definitely be able to come up with a sigmoid function of the logistic function which passes to the two points but what is it that you are doing right intuition is clear but what's the connection to the math path so the connection was the loss function right what you're trying to do subconsciously is that every time you are adjusting the W and the B you're trying to make that sure that the loss that I have which is the difference between the true value and the predicted value right is you're trying to make sure that that decreases that's what you are trying to do and you are able to actually compute that loss right so we knew what the loss function is we are using the squared error loss you knew the True Value you knew the predicted value and you could just actually compute that physical quantity and in this case with the current values of w and B this is how bad my uh approximation was right this is how bad my current sigmoid function is it gives me a loss of 0.099 now once I had handled for this loss I knew that I should keep trying to adjust the weights so that this loss decreases and I did that by some doing a guesswork at every Point slide guesswork slight smart guesswork I was seeing okay this brought it closer so maybe further move W in that direction this took it far so maybe let's not move W in that direction but maybe uh make it in the other direction right and here the two directions are like either increase W or decrease W right move it positive or move it negative and we are able to come up with the sigmoid function right now what we wanted is something better than the guesswork algorithm right so then we said that what you're trying to do is take every stage you're doing this random movements and trying to make sure that the loss decreases but what you know is there's some true loss for for a surface which exists right so this is the loss surface right which exists and if I had directly plotted this loss function and how do I plot this logs function for all values of w comma B all possible values of w comma B and in this case I have only com considered values which are ranging from say minus 6 to plus six right for both W and B I just computed the loss I plugged it into the formula of loss and whatever I got I just kept plotting here and that way I got this entire surface right but this and now in this surface I can see that the loss is very high here if I choose the values of w and B to be um say minus Phi and Phi then it's very high if I choose it to be 4 and minus 4 close to 4 and minus 4 then the loss seems to be low right I can do all this but this is not again feasible right so I just had two parameters and I just uh did this cheating of restricting the weights between minus six to six but actually the values are wnb can take our minus infinity to infinity and if you have like a large number of parameters that we had in that complex neural network then you can't really draw this plot that means Brute Force compute all the values for the loss and find that value which is the smallest and then go and find the W and B which will corresponding so you can't do this right so this guesswork or just Computing a Brute Force both are infeasible the guesswork can lead you to uh false Direction so when I was guessed trying to guess the values are W and B at some points I was making a guess such that my loss was actually more than what it was at my previous case so that doesn't work and this is the brute force method which also doesn't work right you cannot do this Brute Force search when you have a large number of parameters even for two parameters we cannot do right so you want something which is better than the uh Brute Force as well as the uh guesswork algorithm and now I just shown you the visualization for the guesswork algorithm right so what I was doing is that as I keep picking values from this table here uh my loss changes and what happens is actually I'm moving on this lost surface right so this yellow Point keeps changing depending on my current wnb and subconsciously I was actually moving on this lost surface without actually knowing what the loss surface was that's what I was doing in the uh in the in the guesswork algorithm and Computing this entire loss surface is difficult because you have values from minus infinity to Infinity right okay so then uh we said we want a more principled way such that I don't need to do Brute Force I don't need to compute all values of the loss function for or rather the value of the loss function for all values of w and B nor do I want to do this random guessing so that's where we went to gradient descent and the key I idea here was to rely on Taylor series right and I'll just skip all this part which was setting up the context for the Taylor series right so we all understand what Taylor series is allows us to compute the value of a function in a small neighborhood around the current point so if you know the value of the function around the current point you could compute its value in a small neighborhood around it right so that's what Taylor series was allowing us to do and the key thing for us why we needed Taylor series was this right so we started off with some a random value for the loss function right and we wanted to find a sorry sorry sorry sorry we started off with some random value for the parameter and we wanted a new value for the parameter right so we have started somewhere we know what the loss there is now from here I want to move somewhere else and what is my guiding principle that wherever I move my loss should decrease right that means this is the condition that I was aiming for that my new loss should be less than the current loss right and when we solved for this uh inequality uh we made some arguments and what we realized is that if you want that then this U which was the change that you were making uh which is a vector should be in the direction opposite to the gradient right so that's what we arrived at so we arrived at the gradient descent update rule that wherever you are okay you just move in the direction oppose it hence minus take a small step in the direction oppose it to the gradient and this is the gradient and what is this quantity what was the definition this is important because we will be using this quantity throughout this lecture was that you compute the partial derivative of the loss function with respect to w and then evaluate it at w equal to WT and be equal to b or BT right so suppose your loss function is x square so you have only one parameter X or let me just instead of x square let me just say w Square then you have only one parameter W and the derivative of the loss function with respect to W is 2W and this derivative evaluated the current value of w right which might be say w current is equal to 1 would just be 2 right because I'll substitute the value W equal to 1 in this equation right so that's what this means it's the derivative or the partial derivative of the loss function with respect to this variable evaluated at the current value of the variable right so this is what we had and then we also went ahead and computed that gradient right so we got the algorithm we this is what our algorithm is we'll initialize it randomly we'll keep doing these updates so at every Point wherever I'm I am I'll move to a new Point such that from the Taylor series I know that the loss at the new point is going to be less than the loss at the current point right so that's what the gradient descent update rule was but the only thing we don't know here is how to compute this gradient so we actually went ahead and computed that right so we did this derivation which I'll not go over but we knew how to compute the derivative and uh once we knew how to compute that derivative right it was this quantity we then wrote the gradient descent algorithm and what were we doing there for at every point we're Computing this gradient and then moving the direction opposite to the gradient and when we did that this is what happened right so this is yeah so this is what was happening in our gradient when we when we ran this algorithm right so let me just give some uh context here ignore this for now ignore the of yeah so ignore uh this for now right just focus on the uh top graph and I'll tell you what we are trying to do there okay yeah so I was just trying to run the gradient descent algorithm this was my the the Flying Carpet kind of a structure that you see it was what my loss function looked alike and I started with some random initial value right which is the black point where I have started this is the loss and these this is the point corresponding to W comma B right so my w was somewhere around -5 and my B was also somewhere around minus 5 right so that's the point from which I started and as you can see my loss is quite high it's around 0.4 or 0.5 something like that okay so now I run the gradient descent algorithm so at every step I am going to change my w and B so this point that you see on the bottom is going to keep moving in the WB plane right so what you see here is the WB plane right so at every point I'm Computing a new WB so I'm just going to keep plotting that right and this is how it is moving right so I'll make as this I'll just play it once and then make a few observations or I'll keep making the observation so right now you can see that I'm on a fairly flat surface right and because of that I'm moving very slowly right my updates are very slow they're so slow that when you see on the bottom you don't are not even able to distinguish between two points W and B right because they're so close to each other they're just looking like a snake's body right but when I come here okay it's still running okay so when I came here let's see okay now let me just annotate this right so in this region I was moving very very slowly and you can uh okay so in this region I was moving very slowly and you can see here the the change in wnb was so small that the two consecutive points were so close to each other that they're almost seeming connected right that's what is happening at the bottom and then when here in this region when I went inside the valley right so I was at the plateau at the top you can see that now my w and B are changing fast right so maybe it's not visible clearly now let me just uh so you know which region I want you to look at so now let me just try to expand this or rather make maximize this right so this region here is what I want you to look at and you can see that now my w and B are actually I mean the every new W comma B point is actually farther away from my previous W comma B point right what does that mean that my updates are getting bigger now because my new W is my old W plus sum quantity or rather minus some quantity so if that quantity is Big then I will start moving a bit uh farther away from where I was right so in this part where the slope was high right where I was entering uh into the valley at that point I'm seeing that uh I am uh the distance is increasing right and then again when I enter into the valley at that time again my updates become very small right so this is what my observation is so let's uh keep that and let's move to move ahead right so now what we have done so far is quickly revised what the gradient descent algorithm was and now we have made some observations about the gradient descent algorithm right and from here I want to move forward and talk about why are we making those observations right what's the Intuition or are we yeah what's the intuition behind the observations that we have made okay so let me go to the next slide yeah so now so let's ignore this figure for now right so what we observed in the previous slide was that when the slope when the curve was gentle right those ah yeah at the the red portion at the top or the pink portion at the top the slope was very gentle my movements were very small when the slope became steep My movement was a bit fast and then again when I came to this gentle slope my movement became slow right I'm trying to now and get a reasoning for this right why is this happening so what exactly is happening there right so what is our movement right what do I mean by the movement so let me just make that clear first right so my update rule is W is equal to W minus ETA into Delta W okay so now if my this quantity is very small let's say it's 0 right then my new W would be the same as the old W right I'll not be moving right hence when I was looking at this uh WB plane at the bottom right now I'm trying to update the values of w as well as uh B now these updates are very small right then what will happen is I was at some WB and I'll now again remain very close to that right and not move very far but if these updates are large then my w will change by a large value so say w was uh here it will change by a large value and go somewhere here and my B will also change by a large value and go somewhere else so hence now if I look at the original point where I was which I'll now Mark as red right this is where I was and if my Delta W and Delta B were large then I'll move to a point which is farther away from it right so that is what will happen that means these Delta quantities that you see here are controlling how much fast or or by La the amount by which I move right the magnitude by which I move and what are these quantities these are actually the partial derivatives of the loss function with respect to those parameters right so now how does this collect connect to the smooth and the gentle surfaces what is happening then on the smooth surfaces you are moving slowly that means your Delta W is small that's why you're moving slowly why should that be the case we will see that on the Steep surfaces you are moving fast because your Delta W is larger why should that be larger on the Steep surfaces that is something that we'll see now okay so that's the context and with that I'll just go back and play the video again right I'll just want you to observe that indeed when when you are on the smooth surfaces the movement is very very slow but when you come to the yeah so when you're on the smooth surfaces the movement is indeed very slow but when you come to the uh steep surfaces the movement becomes fast right so I'm going to to play the video again and observe that what happens when I transition from this red region here to jumping into the valley right you will see that there's a certain fast movement there just make sure you observe that okay see now I'm moving very very slowly very very slowly it's almost I mean I was for a minute worried whether the video is paused right that's how slow the movement is and here I can see it's flat and somehow on the flat region uh the Delta W is small why is that the case we'll see that soon but now let's see what happens right fast right it went very fast that means my updates were very happening were very large in that region where my slope was steep now why is it that the updates are large in the Steep areas and why is it that the updates are small in the gentle areas is what I'll now what we need to see in the next slide okay so that's where we'll go foreign and the video and all is a bit chaotic in terms of the interface okay so now let's see right so what is the derivative the derivative is the change in so I have written change in the function right so it's a change in the function by the change in the value right so what does the derivative capture as we had said it captures the sensitivity of the function to a change in the variable so if I change X by a small amount how much does the function change right so if you have x square then you know that if you change X from 2 to 2.5 still the square changes a bit quite a bit right it changes from 4 to 6.25 so although you have made only a 0.5 change in the value of x the square has changed by 2.25 right uh so that's that's what happens right so now let's look at what the so this is how I would note the gradient as so it is the movement in the y direction divided by the moment in the X direction right so in those regions now let's see this this here is a region where the store slope is steep right and this here is a region where the slope is gentle so now let's see what does the derivative look like in these two regions okay so I'll just try to move the point so in this region uh you can look at the value being computed here right which is d y by DX that's quite high right the derivative is minus 3.54 now and all of this are very steep regions right now slowly the slope is becoming gentle and when I come here to this point right you can see that the derivative is very small right why is that happening it's obvious because here for a small change in X you are getting a large change in y and that's what the derivative captures but here when you're closer to 1 right let me come this side so when you're closer to 1 when you're changing X by a small amount and the change in X is constant right I'm just changing X by 0.5 right so when I'm changing X by 0.5 my uh y would uh is uh the the change in y divided by the change in X is 1.17 in this region but as I go up right now when I'm around two as I was saying right so so when I change the gradient for example when I change from 1 . yeah so when I'm in this region around one okay so when I change to 1 say X from 1 to 1.5 right my uh my x square changes from 1 to 2.25 okay so that's the change that happens in X and Y but now when I'm around 2 right or maybe say around yeah let's look at around 2 here here I see that the slope is much more steeper what is happening there when I change X from 2 to 2.5 my y changes much more rapidly right so y changes from 4 to 6.25 so the difference here is 2.25 as opposed to 1.25 here so I did the same change in X my change in X was constant which was 0.5 but in one uh neighborhood my y change is very a lot the change in y is very high right that means d y by D X would be high in that region that means the gradient would be high and that gradient is essentially the slope uh of the function uh at that point right so in those regions the slope is very high and the slope is essentially the derivative so wherever I have steep slopes there my d y by DX or the derivative would be high and hence this quantity would be high so if this quantity is high my update or the change in W would be high and when I'm in gentle regions my derivative would be small and hence the change in W would be small because this quantity is small so whatever am I updating by is going to be small okay so that's the intuition and you could just play around with this curve a bit so I have kept the change to be constant at 0.5 you could also try with changing one and you could also try with different function right so currently the function is f x equal to 0.6 X square if I make it 2x square right then you can see that now the function has a even bigger slope in these regions and it does make sense right because the derivative of 2x square is foreign X where is the derivative of x square is 2x right so it does make sense that this is more uh steeper slope than the uh slope of the function x square right so the takeaway from here is that when you have a flat surfaces the gradient would be slow so the movement would be slow when you have steep surfaces the gradient would be large hence the movement or the change in W would be large right now what are the repercussions of this so the repercussion of this is what we saw in the previous slide that if you start off from a point as we are unfortunately done in the previous slide where the surface is largely flat right then your gradients are going to be very very very very very very small and you'll be making these tiny tiny updates W and take a long time to move away from that flat surface right so imagine like a very flat surface which is quite big right in terms of the W comma B neighborhood that it spans then you'll be stuck there for a very very very very long time right before you move to some favorable region where you see a slope and then you start going towards the Minima right and it could happen that you run so we remember we had sent said this Max iterations as thousand so it could happen that you are running your algorithm for thousand iterations but you are not seeing any dramatic change in the loss because indeed you are on this flat surface where the loss is more or less constant or very gentle slope right it's decreasing from say maybe 0.9 to 0.8999999 over a very long distance right and now if you're just stuck there and making these small changes to W you'd run the code for thousand iterations and you will see oh nothing is happening my loss is not changing my I'm not going towards a Minima and so on it will just be stuck there so you need to be able to come out of these situations right so this is one problem that you have with gradient descent that if it's stuck in regions which have a flat surface or have a very gentle slope then it'll take a lot of time if you perhaps run it for 10 000 iterations then it will come out and go to some slope and then take go towards the Minima right but then you might not have the patience to run it for 10 000 iteration so can we do something so that in these gentle regions the movement of gradient descent is fast right so that's the drawback that we want to solve okay so that's where we are headed and just to convince you that is not like uh I mean this is not a characteristic of where I started with and so on and just to give you a different starting point right and if you see a convenient starting point so this here was an example of me getting stuck right on I mean I just happened to start with this yellow Point here which was on a flat surface right so I'll take a while to come out of that flat surface now let me just try some different uh initialization right and there was some suggestion on the uh slides I'll just follow that suggestion oops yeah so the suggestion was to uh try W as minus 2 and B as 2 right so I'll just start that I'll just try that okay so I'll set this to -2 I'll set this to 2. okay so this is where I'm going to start now and now you can see that it's a slightly favorable point because I'm on a slope I'm not in a flat surface I am on a flow so on a on a steep surface so let's see what happens if I run now right see it's moving faster now it's immediately gone into the valley and I don't see now you can also see that these yellow dots are actually farther from each other because the updates are larger right so there is a corresponding plot being drawn on the WB plane also which you could perhaps uh see offline where you can see how the movement on the WB plane is happening and now again it has reached a region of uh of a flat surface out of a gentle slope and now you can't do anything right it'll just keep moving very very slowly and it is a lot of distance to cover uh to reach the Minima right and you can see that I've already exhausted my 100 iterations it's done I've done with 100 iterations but I have not been able to reach the Minima which would have been somewhere here right so so that did not happen maybe if I ran for 200 300 400 so you can go back and experiment and see how many iterations it takes and this looks a bit frustrating right because you know that you're almost there you just need to run faster and get there right but you're not able to run faster because the derivatives become small right and this will happen this will always happen when you're close to the convergence so when you're close to convergence your surface does not have a very high slope and now we are very very very slowly moving towards the Minima which you don't want to happen right so the problem that you want to solve is that in regions where you have a gentle slope you should be able to move faster right so we'll try to solve that problem but before that we'll perhaps take a D2 let me see what we have planned yeah so we uh okay so then what I'll do is I'll end this video here it's already been a long video and when we come back we'll first take a D2 try to understand what contos are uh then look at gradient distance in the context of Contours and then try to solve the problem that we just described which is on flat surfaces gradient descent moves very slowly okay thank you