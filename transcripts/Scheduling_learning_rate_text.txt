foreign [Music] descent momentum based gradient nestro vaccinated gradient descent and I know you are waiting for more algorithms Adam madagrad and so on but in between I took a slight D2 which is I went to the stochastic and minimatch gradient descent mini batch versions of these algorithms and we understood how they operate and before I go to these Advanced algorithms in today's lecture I want to do two more modules one is on adjusting the learning rate and momentum some tips for doing that and this I'll return back to this at the end of all the optimization algorithms once I finish all the optimized algorithms I'll revisit this part and the second module that I want to cover is on something known as line search right so both these are the two things that I've covered today and we'll end this lecture there and then in the next week I'll talk about some of the other Advanced optimization algorithms okay so let's start with this tips for adjusting the learning rate and uh momentum uh yeah right so now we were looking at gradient descent and this is where we had started right this was our first loss function where we started on this very flat uh plane right and then we argued that when you are in these flat surfaces the gradients are very small and hence your updates will be very small and you'll get stuck there and that's what the motivation for using momentum and nestro and so on right but you could have also argued right that instead of using momentum or nestro I could have just used a larger learning rate right so if I'd increase the learning rate and if my gradient is small it the gradient multiplied by the Learning rate would still have been a large quantity and I would still have got the effect of moving faster right and it does make sense that learning rate is how fast you move so maybe that would have helped so now let's see what happens if we had gone by this intuition and set the learning rate to 10 instead of 1 right and it's like 10 times what I had set it otherwise right so let's see what happens in that case so my learning rate is set to 10 now of course it's moving fast but then again you see the problem of oscillation right so it kind of uh on this you want it to be fast on the gentle places but you don't want it to be fast once it enters the value right because on the Steep surfaces anyways the gradient is large so it's going to move fast but now we have multiplied it by the large learning rate and hence you see that there's this oscillation effect right so we don't really want that it's just increasing the learning rate is not really the solution always right and what we want is something which kind of adapts to the slope if the slope is small then you want a larger learning rate if the slope is large then maybe you want the learning rate to decrease right and this is exactly what we'll see in the advanced optimization algorithms which will be have an Adaptive flavor to them right so but for now I just want to mention that it's not just about increasing the learning rate you can't just set it to be of high value always right so that's not right so that setting the learning rate to a high value is not the right thing and then what do you set the learning rate to right so here are some tips so what we typically try to do is that uh at least so now just let me just kind of step back and contextualize this right so nowadays like for most uh areas that you would work in right suppose you're working in machine translation or say automatic speech recognition not text to speech you would be building up on work which is already being done right so you would already have these Transformer based models someone has trained it for many languages and so on so you would have a fair sense of what were the hyper parameters they used and you would try to follow them and just experiment in a small window around it right but the tips here are for the more generic case where you're looking at something new and you don't really know no one has actually looked at the kind of data that you're looking at or the kind of application that you're looking at now how do you uh set the initial learning rate what is small what is large you don't know that right so that's the context in which I'm saying this but for most practical applications if you're working on these standard problems as I said machine translation speech recognition image recognition and so on then you would have something to refer to in the literature which would give you a ballpark about what the learning rate should be and you would follow that close right so that's the best thing to do so that's the first tip this tip is more for cases where you don't have anything to go by right so what you would do is you will try to try you try different learning rates and on a log scale right point zero zero zero one point zero zero one and so on right and then you will run the training for a few epochs with all of these algorithms you'll not do the full training you just run it for a few epochs and you'll observe the loss uh how the loss behaves right and based on observing this loss curve you will get a sense of which is the best learning rate among these four five values that you have chosen on the log scale and now suppose point one turns out to be the best learning rate that means the loss uh the behavior on the loss function so you could plot how the loss is decreasing from one Epoch to another or from One update to another you can keep losing the loss for some uh learning rates you'll see that the loss will increase right because these are probably very high learning rates and you are quickly overshooting the Minima and then going into high loss regions and for some learning rates it will smoothly decrease right so those would be the good learning rates and then suppose point one is one such good learning rate then you will do like a zoom in around this point wanted so maybe you can do a more linear search around this now so if point one was good maybe try point zero five maybe try point two point three right so all of this is of course just heuristics right there's no clear winner strategy here but what you need to take away from this slide is that it might happen that you just set the learning rate to some value and you see that your algorithm is not converging your loss keeps increasing then you will have to kind of experiment a bit around it and this is a good way of experiment you just try a few different values and then narrow down on what a good value is and then just maybe zoom in a bit around that right so that's why uh the other is uh as you initially when you start off maybe you don't know anything right because the weights are completely random so may you some learning rate even slightly higher might work right but as you have started moving towards the uh Minima you don't want to retain a very high learning rate right because then there's always this chance of overshooting the Minima so they you should do what is known as Anil the learning rate right which means keep reducing the learning rate as the training progresses right so one strategy there is to use what is known as a step Decay and you could use some fixed number of epochs right after every five epochs or ten epochs I'll keep having the learning array right so as you are training is progressing your learning rate is becoming smaller and smaller so you're making more conservative updates especially when you are closer to the Minima you're not making a large update so that you cross the minimum right and your approximation for here I am close to the Minima is just that hey I've been training for five epochs now so maybe let me just reduce the learning rate so you're just using the number of epochs as an approximation for how close you are to the uh Minima that you want to use right reach another strategy is that you keep the learning rate uh you had finished one Epoch you compute the loss over your validation data right so you have the training data using which you are training keep some data aside and now after you have done one Epoch calculate what the validation loss is and let's say the value is some X okay now with the same learning rate run the second Epoch right so now you are you have already computed some values of the weights you have made a lot of updates after one Epoch and you have some value of w just start from there run the second Epoch and keep the same learning rate and at the end of this Epoch again look at the validation error so the validation error is also decrease that means things are going fine right your training error is definitely decreasing and your validation error is also decreasing so maybe this learning rate is not so high you can continue with it but if the validation loss starts increasing right then what would you do in that case uh let me just illustrate this what I mean right so this is a good validation loss right so it from after every Epoch you're lost when you're checking the loss it's decreasing right and suppose you are here now and you so say this was Epoch six and now you ran the seventh Epoch okay and you calculate the loss again and it was actually increased right so what will you do now you you had you are of course saving the weights after every Epoch so you will throw away all the updates that you have done in the last Epoch re-initialize the weights from what they were in the sixth epoch half the learning rate and then run the cpoc again right and then hopefully the loss would decrease it's still possible that the loss still increases that means your learning rate is still high so again throw away all the updates go back to the value of the weights that was there at the end of sixth Epoch half the learning rate again and then continue from there right so this is like more data driven learning rate that okay my validation loss is increasing that means my training is not helping me to generalize well so let me just not make a aggressive updates because my updates are according to the training data not according to the validation data so let me not make aggressive updates and one way of ensuring that is to just halve the learning rate and then run okay right and if it keeps increasing after that then maybe you have just conversed then you should stop training at that point right so that's one strategy for annealing the learning rate another way of annealing the learning rate is to use an exponentially decaying learning rate so you have some initial learning rate and then you keep exponentially decaying it right so what is happening here is that you are having 1 over ETA 0 raised to KT right so at time step 0 suppose your ETA 0 is 1 right so at time step 0 and let's assume that K is also equal to 1. so suppose ETA 0 equal to 1 and K is also equal to 1 so time step 0 this would just be 1 over 1 so your learning rate is 1 and as the time steps keep increasing your learning rate will keep decreasing exponentially right so that's one simple thing to do but here the issue is that now what is the initial learning rate that becomes a hyper parameter that was anyways a hyper parameter but in addition this K and this K controls how quickly it will Decay right so if you use a very large value of K it will Decay very quickly right so you would see something like this if you use a smaller value of K it would Decay more smoothly right so now what is the right value of K that also needs to be determined so this makes it even more complex right so I typically do not uh recommend uh this to be used and there's another way of doing this exponential uh learning rate uh which is to use the 1 by t d k right which is again similarly you had some initial learning rate and then you divide it by the number of time steps that you have done so far and again K helps you decide how fast the DK will happen right so again you have this K to decide which makes it a bit uh tricky right so again this any kind of this exponential decay which introduces this parameter K which controls how fast the DK will happen is again tricky to fix it because you could have different values of K so my personal choice is always to go by the validation loss and decrease the learning rate if the validation loss is increasing right so that's the first method that we had looked at right now similarly you could have adjust the momentum right and for momentum there was this method suggested in uh this paper and this looks very uh complex equation but it is not really very complex so let's try to decode what it is right so there's a log here so let's and this T here the T stands for time step so at time step 0 you would have log of 0 Plus 1. and log of 1 is 0 so this term would disappear so we'll just have 1 minus 2 raised to minus 1 right which would just be 0.5 right and this says minimum of 0.5 and beta Max so beta Max is typically one of these values uh so it would be uh or even 0 0 means there is no momentum of course so beta Max would be one of these values so now in this case it would be minimum of say 0.5 and 0.9 so your momentum would be around 0.5 okay and as you keep increasing now at time step t equal to 250 uh this would evaluate to log of 1 plus 1 which would be log of 2 so this would become 1 so you will have 2 raised to minus 1 minus 1 which would be 2 raised to minus 2 which would become 0.25 so this would be 1 minus 0.25 which is equal to 0.75 so it would be minimum of 0.75 and beta Max so again beta max if it is something in the range of 0.9 then this would be selected right and now you can keep substituting the values of T so now if T is equal to 750 then this would be log of uh 3 plus 1 which would be log of 4 right and that would be 2 so this will become 2 raised to minus 3 which would be 0.125 and then this would become 0.875 so as you can see you are slowly increasing the momentum uh term the beta term right which is the amount that you should give to the history right beta tells you how much weight is to give to the history so as you are training is progressing you are planning to rely more and more on the history and less on the current update and that makes sense right because now if you're close to the Minima and then one faulty update will take you away from the Minima right but whereas if your history is uh pointing in a certain direction you would like to rely on that because over the large number of updates you have reached in this region so you want to give more weightage to your history as opposed to the current update so what this is doing is as your training progresses your beta value increases right and as the beta value increases you give more and more weightage to the history right and in the initial phase you don't want to give lot of weightage to the history because your history is still building up right in your history is as unreliable as the current update right as the training progresses you want to give more value to the history right so that's the tip for adjusting the momentum so this is uh currently all I have for tips for learning rate and momentum as I said I'll revisit tips for learning rate towards the end of this lecture again okay so the next thing I want to do is talk about line search is again a simple idea now the whole issue that we have is that if you choose one learning rate and you're kind of married to it either learning rate is good then you would progress well if that learning rate is too high or too low then either you will keep oscillating if it's too high or if it's too low then you will not be making Fast movements right so instead of sticking to one learning rate why not try a bunch of learning reads right so that's what we are trying to do here that you're trying different learning rates okay now you compute the derivative and your w t plus 1 is equal to WT minus ETA times the derivative right now the derivative of course does not change but you can plug in different values of ETA you can plug in the value 0.1 you can plug in the value 0.5 plug in the value 1 to 10 all of these values right and for each of these you will get a new value for 2 w t plus 1 right so this would be w t plus 1 corresponding to Eta 1 another WT plus 1 corresponding to ETA two and so on so now we have found a new value for weight and not just one new value you have found a bunch of new values each corresponding to a particular ETA now plug in all these values in the loss function right so all of these values you could plug in into the loss function all the different W's that you have computed and now whichever W gives you the minimum loss you pick that up so what you have done effectively is that you have tried different learning rates and you have made an update so you got a bunch of updated values now you're looking at each of those values and Computing the loss and whichever update to updated value gives the minimum loss you're retaining that and throwing away all of that and then again doing the same in the next iteration so the derivative only gets computed once because that does not change but you just use different learning rates to come up with different updated values and then select the best updated value based on the loss right so that's what you do in line search you have a bunch of learning rates and you don't get married to one learning rate but just try all of them at every stage of course there's a complexity here involved here that you are trying 10 different learning rates then at every step you're kind of computing 10 values so you have to do 10 times uh the work and just in that update equation and then compute the loss again and then select the best one right so that's an additional complexity that you have but as you can imagine this would definitely be good right so in the flat surfaces you might end up choosing the larger learning rates and in the valley regions where already the slope is steep or when you're entering the valley in those regions if you have a high learning rate you know that your loss would increase because you would overshoot the Minima so in those cases the smaller learning rate would get selected right so you're kind of in some sense making it a bit adaptive based on which region you are in right the flip side of course is that you are doing a lot more computations okay so let's see what happens when we do line search so you see what happened right so the gradient descent was moving at a certain speed it's taking more time to converge but the line search you can see that in the flat regions it was able to move very quickly and it also did not overshoot right it did not go out of the valley because in the Steep regions a smaller learning rate would have worked and it would have not selected the larger learning rate which would have taken it out of the value right so it kind of works very nicely and it of course converges much faster than the gradient descent which was used with a fixed learning rate of one in this case right so I think that's the that advantage of line search is clear so that's all I have for uh today uh we are just going going over the slides the convergence is much faster we see some oscillations but these are not as bad as uh what we had in momentum and nag and overall the line search worked better right so that's where I'll end uh for today and in the next week we'll see uh some uh variations of gradient descent algorithm which use an Adaptive learning array okay so I'll see you next week thank you