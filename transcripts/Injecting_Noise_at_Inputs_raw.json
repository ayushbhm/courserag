[
  {
    "text": "foreign",
    "start": 0.299,
    "duration": 3.0
  },
  {
    "text": "[Music]",
    "start": 6.62,
    "duration": 16.419
  },
  {
    "text": "technique that we're going to see is",
    "start": 21.14,
    "duration": 4.42
  },
  {
    "text": "about adding noise to the inputs so",
    "start": 23.039,
    "duration": 4.201
  },
  {
    "text": "earlier I used to have a different",
    "start": 25.56,
    "duration": 3.539
  },
  {
    "text": "sequence in the course where I used to",
    "start": 27.24,
    "duration": 3.6
  },
  {
    "text": "First teach Auto encoders and then do",
    "start": 29.099,
    "duration": 3.361
  },
  {
    "text": "that but do this lecture but now I've",
    "start": 30.84,
    "duration": 3.66
  },
  {
    "text": "changed that so I'll just make some",
    "start": 32.46,
    "duration": 5.04
  },
  {
    "text": "changes on this slide accordingly so we",
    "start": 34.5,
    "duration": 4.739
  },
  {
    "text": "will see this in the auto encoder but",
    "start": 37.5,
    "duration": 3.18
  },
  {
    "text": "for now let's assume you have the",
    "start": 39.239,
    "duration": 4.561
  },
  {
    "text": "following setup that you are given a",
    "start": 40.68,
    "duration": 4.62
  },
  {
    "text": "certain input",
    "start": 43.8,
    "duration": 3.599
  },
  {
    "text": "and you have say a one layer Network",
    "start": 45.3,
    "duration": 4.259
  },
  {
    "text": "just ignore this for now right I'll come",
    "start": 47.399,
    "duration": 4.201
  },
  {
    "text": "back to this soon so this is your inputs",
    "start": 49.559,
    "duration": 3.961
  },
  {
    "text": "assume this layer is not there this",
    "start": 51.6,
    "duration": 4.2
  },
  {
    "text": "layer is directly feeding into this and",
    "start": 53.52,
    "duration": 3.78
  },
  {
    "text": "then you have the output right so this",
    "start": 55.8,
    "duration": 3.899
  },
  {
    "text": "is what your normal neural network would",
    "start": 57.3,
    "duration": 6.0
  },
  {
    "text": "look like now what weight uh adding",
    "start": 59.699,
    "duration": 6.42
  },
  {
    "text": "weight uh noise to the weights what this",
    "start": 63.3,
    "duration": 4.859
  },
  {
    "text": "method does is you take your inputs",
    "start": 66.119,
    "duration": 4.261
  },
  {
    "text": "let's assume your inputs were say binary",
    "start": 68.159,
    "duration": 5.401
  },
  {
    "text": "for the sake of simplicity right now",
    "start": 70.38,
    "duration": 5.64
  },
  {
    "text": "what you do is you add a noise process",
    "start": 73.56,
    "duration": 6.18
  },
  {
    "text": "such that for every input",
    "start": 76.02,
    "duration": 6.84
  },
  {
    "text": "say with probability 80 percent it will",
    "start": 79.74,
    "duration": 5.04
  },
  {
    "text": "keep the input as it is and with",
    "start": 82.86,
    "duration": 3.78
  },
  {
    "text": "probability 20 percent it will flip the",
    "start": 84.78,
    "duration": 3.36
  },
  {
    "text": "input right that is a very simple noise",
    "start": 86.64,
    "duration": 4.38
  },
  {
    "text": "process so if you have like 100 uh",
    "start": 88.14,
    "duration": 5.46
  },
  {
    "text": "digits as input or an input belongs to R",
    "start": 91.02,
    "duration": 6.36
  },
  {
    "text": "100 or in this case uh 0 comma 1 raised",
    "start": 93.6,
    "duration": 5.4
  },
  {
    "text": "to 100 because there are only binary",
    "start": 97.38,
    "duration": 2.699
  },
  {
    "text": "inputs",
    "start": 99.0,
    "duration": 4.5
  },
  {
    "text": "then uh with probability eighty percent",
    "start": 100.079,
    "duration": 5.641
  },
  {
    "text": "it will keep each of those hundred",
    "start": 103.5,
    "duration": 4.56
  },
  {
    "text": "values as they were and with probability",
    "start": 105.72,
    "duration": 4.8
  },
  {
    "text": "20 it will flip it so in effect what you",
    "start": 108.06,
    "duration": 4.44
  },
  {
    "text": "would expect is that twenty percent of",
    "start": 110.52,
    "duration": 3.66
  },
  {
    "text": "your inputs has been corrupted right",
    "start": 112.5,
    "duration": 3.6
  },
  {
    "text": "because twenty percent of it will get a",
    "start": 114.18,
    "duration": 3.66
  },
  {
    "text": "change right so now you have added noise",
    "start": 116.1,
    "duration": 4.32
  },
  {
    "text": "to the input and now once you have added",
    "start": 117.84,
    "duration": 4.62
  },
  {
    "text": "noise to the input what is a deep neural",
    "start": 120.42,
    "duration": 5.1
  },
  {
    "text": "network good at it is good at mapping x",
    "start": 122.46,
    "duration": 5.28
  },
  {
    "text": "to the true y right that means it's very",
    "start": 125.52,
    "duration": 5.519
  },
  {
    "text": "good at reducing the training error but",
    "start": 127.74,
    "duration": 5.94
  },
  {
    "text": "now from this x you have given created a",
    "start": 131.039,
    "duration": 4.92
  },
  {
    "text": "random X like a modified X or a",
    "start": 133.68,
    "duration": 3.9
  },
  {
    "text": "corrupted X sorry not a random X but a",
    "start": 135.959,
    "duration": 3.721
  },
  {
    "text": "corrupted X and now it is trying to map",
    "start": 137.58,
    "duration": 5.34
  },
  {
    "text": "this corrupted x to the input right and",
    "start": 139.68,
    "duration": 4.8
  },
  {
    "text": "now every time you see this training",
    "start": 142.92,
    "duration": 3.24
  },
  {
    "text": "instance this corruption would be",
    "start": 144.48,
    "duration": 4.02
  },
  {
    "text": "slightly different so across epochs as",
    "start": 146.16,
    "duration": 4.32
  },
  {
    "text": "you are modifying the every time you are",
    "start": 148.5,
    "duration": 3.9
  },
  {
    "text": "applying this noise process you are",
    "start": 150.48,
    "duration": 3.479
  },
  {
    "text": "seeing a slightly different corrupted",
    "start": 152.4,
    "duration": 3.479
  },
  {
    "text": "version of the original input and every",
    "start": 153.959,
    "duration": 4.321
  },
  {
    "text": "time it has to map that to the same y so",
    "start": 155.879,
    "duration": 4.5
  },
  {
    "text": "now again the job of the network has",
    "start": 158.28,
    "duration": 4.319
  },
  {
    "text": "become harder because it's it's in a way",
    "start": 160.379,
    "duration": 4.041
  },
  {
    "text": "similar to what you did with the",
    "start": 162.599,
    "duration": 4.021
  },
  {
    "text": "augmentation of the data set right so",
    "start": 164.42,
    "duration": 4.899
  },
  {
    "text": "you had an original two and then you",
    "start": 166.62,
    "duration": 5.94
  },
  {
    "text": "passed it uh shifted to or rotated two",
    "start": 169.319,
    "duration": 5.521
  },
  {
    "text": "and now both of these it needs to map to",
    "start": 172.56,
    "duration": 4.08
  },
  {
    "text": "the label two right so now it has a more",
    "start": 174.84,
    "duration": 3.24
  },
  {
    "text": "to learn and same thing you're doing",
    "start": 176.64,
    "duration": 4.2
  },
  {
    "text": "here you had an original X you corrupted",
    "start": 178.08,
    "duration": 5.64
  },
  {
    "text": "it and it has to map it to Y next Epoch",
    "start": 180.84,
    "duration": 4.44
  },
  {
    "text": "you again corrupted it but this time the",
    "start": 183.72,
    "duration": 3.06
  },
  {
    "text": "corruption would be different maybe in",
    "start": 185.28,
    "duration": 4.08
  },
  {
    "text": "the first Epoch uh the say the first 20",
    "start": 186.78,
    "duration": 4.679
  },
  {
    "text": "bits were corrupted now maybe the bits",
    "start": 189.36,
    "duration": 4.019
  },
  {
    "text": "from 20 to 40 are corrupted and so on",
    "start": 191.459,
    "duration": 3.541
  },
  {
    "text": "it's every time it's seeing a different",
    "start": 193.379,
    "duration": 4.681
  },
  {
    "text": "corrupted version of the input right and",
    "start": 195.0,
    "duration": 5.159
  },
  {
    "text": "this this index here is the epoch or",
    "start": 198.06,
    "duration": 4.2
  },
  {
    "text": "that I'm looking at and it has to map",
    "start": 200.159,
    "duration": 3.481
  },
  {
    "text": "all of those two wire right so now",
    "start": 202.26,
    "duration": 3.899
  },
  {
    "text": "memorizing the input becomes or this",
    "start": 203.64,
    "duration": 4.379
  },
  {
    "text": "taking the input memorizing it and",
    "start": 206.159,
    "duration": 3.601
  },
  {
    "text": "mapping to the Y becomes input because",
    "start": 208.019,
    "duration": 3.3
  },
  {
    "text": "now your input is every time a bit",
    "start": 209.76,
    "duration": 3.6
  },
  {
    "text": "corrupted so it has to deal with these",
    "start": 211.319,
    "duration": 4.92
  },
  {
    "text": "Corruptions also",
    "start": 213.36,
    "duration": 7.08
  },
  {
    "text": "and now what we can actually show right",
    "start": 216.239,
    "duration": 7.5
  },
  {
    "text": "that for a simple input output Network",
    "start": 220.44,
    "duration": 6.18
  },
  {
    "text": "right that means there is no uh hidden",
    "start": 223.739,
    "duration": 6.801
  },
  {
    "text": "layer so you have a uh",
    "start": 226.62,
    "duration": 3.92
  },
  {
    "text": "so I have a bunch of inputs and then you",
    "start": 230.64,
    "duration": 3.659
  },
  {
    "text": "directly have the output right so there",
    "start": 232.86,
    "duration": 4.32
  },
  {
    "text": "is no in no input output layer so your",
    "start": 234.299,
    "duration": 5.101
  },
  {
    "text": "inputs are say X1 to x n",
    "start": 237.18,
    "duration": 5.1
  },
  {
    "text": "and now if you add some noise to all of",
    "start": 239.4,
    "duration": 4.5
  },
  {
    "text": "your inputs",
    "start": 242.28,
    "duration": 3.959
  },
  {
    "text": "right",
    "start": 243.9,
    "duration": 4.44
  },
  {
    "text": "and if that noise is a gaussian noise",
    "start": 246.239,
    "duration": 4.261
  },
  {
    "text": "that means say that noise is coming",
    "start": 248.34,
    "duration": 5.88
  },
  {
    "text": "from a gaussian distribution zero mean",
    "start": 250.5,
    "duration": 4.92
  },
  {
    "text": "and some",
    "start": 254.22,
    "duration": 4.32
  },
  {
    "text": "variance then you can show that this is",
    "start": 255.42,
    "duration": 5.099
  },
  {
    "text": "actually equal to L2 regularization",
    "start": 258.54,
    "duration": 3.78
  },
  {
    "text": "right and we will see that on the next",
    "start": 260.519,
    "duration": 4.68
  },
  {
    "text": "slide so this is the setup that we are",
    "start": 262.32,
    "duration": 5.48
  },
  {
    "text": "considering",
    "start": 265.199,
    "duration": 2.601
  },
  {
    "text": "this is exactly what I drew on the",
    "start": 269.699,
    "duration": 3.78
  },
  {
    "text": "previous slide that you have these n",
    "start": 271.32,
    "duration": 4.56
  },
  {
    "text": "inputs and to each of these inputs you",
    "start": 273.479,
    "duration": 5.28
  },
  {
    "text": "have added some gaussian noise okay and",
    "start": 275.88,
    "duration": 4.379
  },
  {
    "text": "the noise added to each input is",
    "start": 278.759,
    "duration": 3.781
  },
  {
    "text": "independent of the other inputs and then",
    "start": 280.259,
    "duration": 5.521
  },
  {
    "text": "you're trying to predict a y okay and",
    "start": 282.54,
    "duration": 5.82
  },
  {
    "text": "the noise is coming from zero mean and",
    "start": 285.78,
    "duration": 5.6
  },
  {
    "text": "some variance",
    "start": 288.36,
    "duration": 3.02
  },
  {
    "text": "so now your X tilde that the corrupted X",
    "start": 292.8,
    "duration": 5.7
  },
  {
    "text": "is the original X plus this noise and",
    "start": 295.5,
    "duration": 5.28
  },
  {
    "text": "now your original y hat right without",
    "start": 298.5,
    "duration": 4.5
  },
  {
    "text": "the corruption your this is what your y",
    "start": 300.78,
    "duration": 3.84
  },
  {
    "text": "hat should have looked like right",
    "start": 303.0,
    "duration": 3.3
  },
  {
    "text": "there's no surprising here no surprising",
    "start": 304.62,
    "duration": 4.019
  },
  {
    "text": "I have not used any non-linearity this",
    "start": 306.3,
    "duration": 4.26
  },
  {
    "text": "is just like a linear transformation",
    "start": 308.639,
    "duration": 4.021
  },
  {
    "text": "right so your model is simply Y is equal",
    "start": 310.56,
    "duration": 5.639
  },
  {
    "text": "to W transpose X this is a linear model",
    "start": 312.66,
    "duration": 6.72
  },
  {
    "text": "that you're using here right and so this",
    "start": 316.199,
    "duration": 5.461
  },
  {
    "text": "is what your y hat should be but now",
    "start": 319.38,
    "duration": 3.659
  },
  {
    "text": "instead of Y hat you are actually",
    "start": 321.66,
    "duration": 4.56
  },
  {
    "text": "Computing y tilde and why do I say y",
    "start": 323.039,
    "duration": 5.401
  },
  {
    "text": "tilde because now you don't have X's you",
    "start": 326.22,
    "duration": 3.6
  },
  {
    "text": "have X tildas right you have the",
    "start": 328.44,
    "duration": 4.259
  },
  {
    "text": "corrupted axis now for the X if I",
    "start": 329.82,
    "duration": 6.84
  },
  {
    "text": "substitute the value of x tilde as",
    "start": 332.699,
    "duration": 7.741
  },
  {
    "text": "X Plus Epsilon then I can just rewrite",
    "start": 336.66,
    "duration": 7.379
  },
  {
    "text": "this summation as follows",
    "start": 340.44,
    "duration": 5.599
  },
  {
    "text": "this is what will happen right so it is",
    "start": 344.039,
    "duration": 5.281
  },
  {
    "text": "x i x i is equal to X Plus Epsilon so",
    "start": 346.039,
    "duration": 4.901
  },
  {
    "text": "that summation now splits into two parts",
    "start": 349.32,
    "duration": 3.84
  },
  {
    "text": "and the first part of course is the same",
    "start": 350.94,
    "duration": 5.4
  },
  {
    "text": "as your y hat so I can write y tilde as",
    "start": 353.16,
    "duration": 6.479
  },
  {
    "text": "y hat plus W I uh plus summation w i",
    "start": 356.34,
    "duration": 4.919
  },
  {
    "text": "Epsilon I okay",
    "start": 359.639,
    "duration": 3.78
  },
  {
    "text": "now what are we interested in we are",
    "start": 361.259,
    "duration": 4.141
  },
  {
    "text": "interested in this expected error now",
    "start": 363.419,
    "duration": 4.081
  },
  {
    "text": "the expected error what is it that I am",
    "start": 365.4,
    "duration": 6.12
  },
  {
    "text": "Computing this is the output based on",
    "start": 367.5,
    "duration": 6.06
  },
  {
    "text": "the corrupted input and this is the true",
    "start": 371.52,
    "duration": 3.78
  },
  {
    "text": "output right this is not y hat remember",
    "start": 373.56,
    "duration": 3.3
  },
  {
    "text": "this is not y hat this is the true",
    "start": 375.3,
    "duration": 4.44
  },
  {
    "text": "output the true label that was given to",
    "start": 376.86,
    "duration": 4.74
  },
  {
    "text": "me right and we are interested in this",
    "start": 379.74,
    "duration": 3.72
  },
  {
    "text": "expected error this is what we have been",
    "start": 381.6,
    "duration": 3.42
  },
  {
    "text": "doing throughout when we are looking at",
    "start": 383.46,
    "duration": 3.9
  },
  {
    "text": "bias variance trade-off right so this is",
    "start": 385.02,
    "duration": 3.959
  },
  {
    "text": "the quantity that I am interested in so",
    "start": 387.36,
    "duration": 3.72
  },
  {
    "text": "let me try to find out what that",
    "start": 388.979,
    "duration": 4.861
  },
  {
    "text": "quantity is",
    "start": 391.08,
    "duration": 5.28
  },
  {
    "text": "so I'm just going to now the rest of it",
    "start": 393.84,
    "duration": 5.1
  },
  {
    "text": "is just now going to be a set of steps",
    "start": 396.36,
    "duration": 4.26
  },
  {
    "text": "so I'll just maybe write down everything",
    "start": 398.94,
    "duration": 4.44
  },
  {
    "text": "first yeah so I'll just now go over it",
    "start": 400.62,
    "duration": 5.34
  },
  {
    "text": "one by one this will be easier to do it",
    "start": 403.38,
    "duration": 5.7
  },
  {
    "text": "that way so I had y tilde okay so now",
    "start": 405.96,
    "duration": 4.98
  },
  {
    "text": "what I have done is I have written y",
    "start": 409.08,
    "duration": 6.239
  },
  {
    "text": "tilde as y hat plus this quantity so no",
    "start": 410.94,
    "duration": 7.02
  },
  {
    "text": "uh no issues there then I have three",
    "start": 415.319,
    "duration": 5.401
  },
  {
    "text": "quantities here A B and C so I have",
    "start": 417.96,
    "duration": 5.4
  },
  {
    "text": "grouped them so I have a minus B plus",
    "start": 420.72,
    "duration": 5.34
  },
  {
    "text": "sorry A minus C plus this B quantity and",
    "start": 423.36,
    "duration": 3.839
  },
  {
    "text": "of course there was the whole Square",
    "start": 426.06,
    "duration": 4.079
  },
  {
    "text": "outside always okay so now this now",
    "start": 427.199,
    "duration": 7.081
  },
  {
    "text": "Becomes of the form let me just say p",
    "start": 430.139,
    "duration": 6.361
  },
  {
    "text": "plus Q the whole Square so it is going",
    "start": 434.28,
    "duration": 6.24
  },
  {
    "text": "to be p square plus Q squared plus 2 p q",
    "start": 436.5,
    "duration": 6.06
  },
  {
    "text": "so it is going to be the expectation of",
    "start": 440.52,
    "duration": 4.2
  },
  {
    "text": "p square plus Q squared plus 2 PQ this",
    "start": 442.56,
    "duration": 4.02
  },
  {
    "text": "is an expectation of a sum so I can",
    "start": 444.72,
    "duration": 3.72
  },
  {
    "text": "write it as the sum of expectations so",
    "start": 446.58,
    "duration": 4.44
  },
  {
    "text": "expectation of P Square expectation of",
    "start": 448.44,
    "duration": 5.34
  },
  {
    "text": "2pq and expectation of our Q square",
    "start": 451.02,
    "duration": 4.04
  },
  {
    "text": "right",
    "start": 453.78,
    "duration": 4.62
  },
  {
    "text": "now let's make a few observations so",
    "start": 455.06,
    "duration": 6.16
  },
  {
    "text": "this quantity here there are n terms",
    "start": 458.4,
    "duration": 4.32
  },
  {
    "text": "here right so you could think of it as a",
    "start": 461.22,
    "duration": 4.099
  },
  {
    "text": "1 plus",
    "start": 462.72,
    "duration": 2.599
  },
  {
    "text": "a two",
    "start": 465.96,
    "duration": 5.459
  },
  {
    "text": "plus plus all the way up to a n square",
    "start": 468.479,
    "duration": 5.16
  },
  {
    "text": "right so now when you expand this what",
    "start": 471.419,
    "duration": 3.481
  },
  {
    "text": "are the kind of terms that you are going",
    "start": 473.639,
    "duration": 3.18
  },
  {
    "text": "to get you are going to get the squares",
    "start": 474.9,
    "duration": 3.66
  },
  {
    "text": "of all of these guys",
    "start": 476.819,
    "duration": 4.44
  },
  {
    "text": "A1 square plus a 2 square",
    "start": 478.56,
    "duration": 5.34
  },
  {
    "text": "all the way up to a n square and then",
    "start": 481.259,
    "duration": 5.641
  },
  {
    "text": "you are going to get these uh and choose",
    "start": 483.9,
    "duration": 7.56
  },
  {
    "text": "two terms where you will have a 1 a 2",
    "start": 486.9,
    "duration": 6.9
  },
  {
    "text": "of course multiplied by something plus",
    "start": 491.46,
    "duration": 5.1
  },
  {
    "text": "ah A2 A3",
    "start": 493.8,
    "duration": 5.28
  },
  {
    "text": "again multiplied by something and so on",
    "start": 496.56,
    "duration": 4.68
  },
  {
    "text": "right and so this is going to be a very",
    "start": 499.08,
    "duration": 3.899
  },
  {
    "text": "long sum and you are taking the",
    "start": 501.24,
    "duration": 3.359
  },
  {
    "text": "expectation of that sum so it's going to",
    "start": 502.979,
    "duration": 4.141
  },
  {
    "text": "be a sum of the expectations so this is",
    "start": 504.599,
    "duration": 5.401
  },
  {
    "text": "what it would look like right",
    "start": 507.12,
    "duration": 5.82
  },
  {
    "text": "and my a a one a two here is of course W",
    "start": 510.0,
    "duration": 5.76
  },
  {
    "text": "1 Epsilon 1 W 2 Epsilon 2 and so on",
    "start": 512.94,
    "duration": 5.94
  },
  {
    "text": "right now wherever you encounter A1 A2",
    "start": 515.76,
    "duration": 4.86
  },
  {
    "text": "remember that a one a two here is",
    "start": 518.88,
    "duration": 5.219
  },
  {
    "text": "Epsilon some Epsilon I Epsilon J and",
    "start": 520.62,
    "duration": 6.18
  },
  {
    "text": "since the epsilons are independent then",
    "start": 524.099,
    "duration": 5.101
  },
  {
    "text": "all these except all these could be",
    "start": 526.8,
    "duration": 6.44
  },
  {
    "text": "written as expectation of",
    "start": 529.2,
    "duration": 4.04
  },
  {
    "text": "Epsilon I into expectation of",
    "start": 533.82,
    "duration": 4.88
  },
  {
    "text": "Epsilon J and of course some other",
    "start": 540.36,
    "duration": 3.84
  },
  {
    "text": "quantities here but the main thing here",
    "start": 542.22,
    "duration": 3.78
  },
  {
    "text": "is that Epsilon expectation of Epsilon",
    "start": 544.2,
    "duration": 4.56
  },
  {
    "text": "is zero because Epsilon is a zero mean",
    "start": 546.0,
    "duration": 5.16
  },
  {
    "text": "noise so all those terms which contain",
    "start": 548.76,
    "duration": 5.04
  },
  {
    "text": "A1 A2 are going to be disappearing why",
    "start": 551.16,
    "duration": 4.26
  },
  {
    "text": "will they disappear because you are",
    "start": 553.8,
    "duration": 3.84
  },
  {
    "text": "taking the expectation of a product and",
    "start": 555.42,
    "duration": 3.84
  },
  {
    "text": "the two random variables in the product",
    "start": 557.64,
    "duration": 3.78
  },
  {
    "text": "are independent so that expectation can",
    "start": 559.26,
    "duration": 3.3
  },
  {
    "text": "be written as the product of",
    "start": 561.42,
    "duration": 3.539
  },
  {
    "text": "expectations and in the individual terms",
    "start": 562.56,
    "duration": 4.74
  },
  {
    "text": "are there now become zero so all these",
    "start": 564.959,
    "duration": 4.44
  },
  {
    "text": "terms are going to be disappearing and",
    "start": 567.3,
    "duration": 4.8
  },
  {
    "text": "so you will only be left with the uh",
    "start": 569.399,
    "duration": 4.44
  },
  {
    "text": "with the quantities which contain the",
    "start": 572.1,
    "duration": 3.72
  },
  {
    "text": "squares so those are these quantities",
    "start": 573.839,
    "duration": 4.801
  },
  {
    "text": "right so w i square plus Epsilon I into",
    "start": 575.82,
    "duration": 4.98
  },
  {
    "text": "Epsilon I square and you'll have n such",
    "start": 578.64,
    "duration": 3.9
  },
  {
    "text": "terms so that's why you have n terms",
    "start": 580.8,
    "duration": 4.86
  },
  {
    "text": "here right so that's that's a pretty",
    "start": 582.54,
    "duration": 5.58
  },
  {
    "text": "long ah",
    "start": 585.66,
    "duration": 4.08
  },
  {
    "text": "um yeah I mean long set of explanation",
    "start": 588.12,
    "duration": 4.08
  },
  {
    "text": "for what how I went from",
    "start": 589.74,
    "duration": 5.46
  },
  {
    "text": "here to here right and again I have said",
    "start": 592.2,
    "duration": 5.34
  },
  {
    "text": "that this quantity also becomes zero so",
    "start": 595.2,
    "duration": 4.62
  },
  {
    "text": "why does that quantity become zero so",
    "start": 597.54,
    "duration": 6.06
  },
  {
    "text": "this is y hat minus y okay",
    "start": 599.82,
    "duration": 6.9
  },
  {
    "text": "so here you are a random variable is y",
    "start": 603.6,
    "duration": 6.72
  },
  {
    "text": "hat and this is w i Epsilon I so Y is of",
    "start": 606.72,
    "duration": 5.46
  },
  {
    "text": "course not a random variable w i is also",
    "start": 610.32,
    "duration": 3.78
  },
  {
    "text": "not a random variable so what is the",
    "start": 612.18,
    "duration": 3.839
  },
  {
    "text": "random variable y hat and Epsilon I",
    "start": 614.1,
    "duration": 3.6
  },
  {
    "text": "right so this is again the product",
    "start": 616.019,
    "duration": 3.661
  },
  {
    "text": "expectation of the product of two random",
    "start": 617.7,
    "duration": 4.5
  },
  {
    "text": "variables and now again y hat and",
    "start": 619.68,
    "duration": 5.52
  },
  {
    "text": "Epsilon I are independent because y hat",
    "start": 622.2,
    "duration": 4.74
  },
  {
    "text": "had nothing to do with Epsilon that was",
    "start": 625.2,
    "duration": 4.199
  },
  {
    "text": "the uncorrupted output whereas Epsilon",
    "start": 626.94,
    "duration": 3.959
  },
  {
    "text": "is the noise that you have added and the",
    "start": 629.399,
    "duration": 3.361
  },
  {
    "text": "noise that you have added had nothing to",
    "start": 630.899,
    "duration": 3.481
  },
  {
    "text": "do with the uncorrupted output so these",
    "start": 632.76,
    "duration": 3.72
  },
  {
    "text": "two are independent random variables so",
    "start": 634.38,
    "duration": 4.32
  },
  {
    "text": "this expectation you can also show that",
    "start": 636.48,
    "duration": 4.62
  },
  {
    "text": "will go down to 0 right so then the only",
    "start": 638.7,
    "duration": 4.8
  },
  {
    "text": "thing that you are left with is this and",
    "start": 641.1,
    "duration": 3.78
  },
  {
    "text": "this quantity",
    "start": 643.5,
    "duration": 3.54
  },
  {
    "text": "uh so let's see from there where do we",
    "start": 644.88,
    "duration": 4.34
  },
  {
    "text": "go",
    "start": 647.04,
    "duration": 2.18
  },
  {
    "text": "so this becomes the expected value of",
    "start": 655.2,
    "duration": 8.04
  },
  {
    "text": "this error right plus ah the the",
    "start": 658.86,
    "duration": 6.78
  },
  {
    "text": "summation w i square is not the random",
    "start": 663.24,
    "duration": 5.219
  },
  {
    "text": "variable so expectation of Epsilon",
    "start": 665.64,
    "duration": 5.18
  },
  {
    "text": "Square",
    "start": 668.459,
    "duration": 2.361
  },
  {
    "text": "into this sum right this sum here",
    "start": 670.86,
    "duration": 5.94
  },
  {
    "text": "and the expectation of Epsilon square is",
    "start": 674.82,
    "duration": 4.019
  },
  {
    "text": "just Sigma Square so what you get",
    "start": 676.8,
    "duration": 5.159
  },
  {
    "text": "effectively is your loss term right",
    "start": 678.839,
    "duration": 5.641
  },
  {
    "text": "which this was the training error right",
    "start": 681.959,
    "duration": 4.081
  },
  {
    "text": "so if you estimate this expectation from",
    "start": 684.48,
    "duration": 3.0
  },
  {
    "text": "the training error from the training",
    "start": 686.04,
    "duration": 2.52
  },
  {
    "text": "data that is what you are going to do",
    "start": 687.48,
    "duration": 3.18
  },
  {
    "text": "because you only have the training data",
    "start": 688.56,
    "duration": 6.24
  },
  {
    "text": "at training time so this is your L Theta",
    "start": 690.66,
    "duration": 6.9
  },
  {
    "text": "and this is your Omega Theta",
    "start": 694.8,
    "duration": 4.86
  },
  {
    "text": "and this is actually the same as the L2",
    "start": 697.56,
    "duration": 3.719
  },
  {
    "text": "loss because you are minimizing the sum",
    "start": 699.66,
    "duration": 3.78
  },
  {
    "text": "of the squares of the weights which is",
    "start": 701.279,
    "duration": 4.62
  },
  {
    "text": "the same as the L2 Norm penalty right so",
    "start": 703.44,
    "duration": 4.139
  },
  {
    "text": "in the simple input output Network",
    "start": 705.899,
    "duration": 4.921
  },
  {
    "text": "without any non-linearity uh adding",
    "start": 707.579,
    "duration": 5.7
  },
  {
    "text": "noise to the inputs is the same as using",
    "start": 710.82,
    "duration": 5.519
  },
  {
    "text": "a weight DK right so this is the L2 Norm",
    "start": 713.279,
    "duration": 4.8
  },
  {
    "text": "penalty is also called weight Decay",
    "start": 716.339,
    "duration": 3.961
  },
  {
    "text": "because as we saw it decays the weights",
    "start": 718.079,
    "duration": 4.801
  },
  {
    "text": "right by this Factor Lambda by Lambda",
    "start": 720.3,
    "duration": 5.46
  },
  {
    "text": "Lambda plus Alpha okay so that's this is",
    "start": 722.88,
    "duration": 4.5
  },
  {
    "text": "another regularization technique and we",
    "start": 725.76,
    "duration": 4.38
  },
  {
    "text": "have seen its relation to uh weight DK",
    "start": 727.38,
    "duration": 4.94
  },
  {
    "text": "in the simple input output Network",
    "start": 730.14,
    "duration": 6.3
  },
  {
    "text": "without any non-linearity okay uh silent",
    "start": 732.32,
    "duration": 6.66
  },
  {
    "text": "this here",
    "start": 736.44,
    "duration": 2.54
  }
]