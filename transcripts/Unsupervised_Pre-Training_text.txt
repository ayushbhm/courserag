foreign [Music] ing so the main question is right what has changed now right what has happened in 2006 which has allowed us to train these deep neural networks and why has big deep learning become so popular that's the main question so far right uh so if we look at this seminal work in 2006 which made uh training deep neural networks are more uh possible Right so the original paper I was actually talks about something known as rbms we have not done ibms yet and we'll not do it in this part of the course uh I will try to explain it in the context of Auto encoders again we have not done Auto encoders now I've also Auto encoders will also not be a part of this course because we have replaced it by other more advanced optimization algorithms as well as discussion on Transformers so we did not have place to put in autoencoders given the number of lectures that we had so but you could refer to my older lectures and auto encoders if you want and whatever we need I'll anyways cover in the next few slides right so I'll not have you have not had a detailed discussion or to encoders but I'll just quickly brush up on whatever I need in the next few slides right so two points here one is the original paper talks in the context of rbms I am going to talk about this idea in the context of Auto encoders we have not done Auto encoders in this offering of the course but I'll just quickly cover the concepts that I require right so now consider this deep neural network where there is like a 4 layer Network plus the input and the output layer and as I was saying before 2006 it was hard to train networks which are four five six layers and so on it they did not converge well right now let us focus on the first two layers right now what I'm trying to do is I'm going to try to explain the idea of unsupervised pre-training right so now I forget about training the entire network so what is my input that might be some x's that I have right and this x belongs to some r n so it's an N dimensional input and I have taken the simple case when I'm just trying to predict one output right so my y belongs to R right now I'm not focusing on this entire and I decided that I want to use like a very complex deep neural network as my function approximation that this is the relation between Y and ah X and Y right and now I am focusing on this first layer where I have the input and then the first hidden layer H1 right now what we do in unsupervised pre-training or at least as it was introduced in this paper now today unsupervised pre-training still still exist but in a much different form which is conceptually similar but with a lot of moving Parts having changed right this is in the context of feed forward neural networks today we typically talk about it in the context of Transformers and the loss functions that evolved none of that matters at this point but I'm just saying that when I'm talking about unsupervised pre-tuning right now I'm talking in the context of this work in 2006 right ah ok so what we will do is we will take X as the input okay and we will focus on a very simple problem first right so this x is the input I have just taken the first hidden layer so I have taken the hidden layer as it is and now instead of feeding this hidden layer to the next layer I just disconnected the network and what I have done is I am now trying to predict X again right so think of this this way that I had say some 1 0 2 4 dimensional input then I have a hidden layer in between which is say 256 dimensional and then again an output layer which is one zero two four and my goal is to do the following right first compute this 256 dimensional hidden representation and then again reconstruct the output from it right and I my goal would be that if I call this x hat and this says X then since I am reconstructing my X hat should be as close to X right and that is what this loss function is calculating so my X was n dimensional so along each of these n Dimensions I want to reduce the error between the prediction and the construction and I want to do this for all the M training examples and I want to consider the average right so that's the objective function this is clear now what what am I trying to do here right what is happening here right so let us try to understand this conceptually that suppose I'm able to do this suppose I'm able to train a network which is able to reconstruct X hat with zero error that means I am taking an X I am doing a w x y that is a transformation I do then I pass it through a sigmoid function I am ignoring the biases okay so I get some hidden layer H1 right and then from the hidden layer I am reconstructing X hat as say W Times H1 okay this is what I am doing in this network right my input layer I am doing first a linear transformation followed by a non-linearity and then whatever H1 I get I just reconstructed the X hat from there if you want I can just add the bias also here and I can add the bias here also right so you if you want that's that makes you more comfortable then that is what it is right now suppose I am able to do this in a way that I am able to reconstruct X hat from X perfectly that means my error is zero what does that tell you about H1 so so it tells you that H1 actually character captures all the information that was there in X right because I have done a compression I have gone from one zero to four dimensions to 256. now we know that in many applications our input has a lot of redundancy right so I would have captured weight height and BMI all three are not needed from the weight and height I can know the BMI right similarly I would have captured several correlated things I would have captured weight and centimeter oh sorry weight in kilograms maybe I would have captured weight in pounds also or weight in grams also similarly height in centimeters process data is flowing in from multiple channels so I do not know even for example I would have calculated the salary I would have salary as one of the inputs and I might also have the income tax as one of the inputs right now these two are completely correlated so in that case I did not have both these inputs right so my data has lot of redundancy so I am doing some sort of a compression where I am reducing it to 256 values and then I'm trying to reconstruct the input from these 256 values so if I am able to do this perfectly that means this hidden layer that I had is capturing all the important characteristics of my input right and that is enough for me to reconstruct the input right that's what typically happens in compression so that's exactly what I am trying to do here and this is the idea in an auto encoder right I want to learn a more compact representation of the input and the way I do it is that I use this bottleneck layer right and then I try to reconstruct the loss and if I'm able to do this then I have captured all the important information in this 1024 dimensional data it was by just using 256 Dimensions right and we can show that under certain conditions this is actually equivalent to principle component analysis which is again a data dimensional ID reduction technique right and the same thing you are doing here you're using the dimensions of the input data right so that's all that we want to know about Auto encoders this is what an auto encoder tries to do and this is what I am trying to do here right so while doing so I am actually Computing ending up Computing a abstract representation of the input in this layer right so my this layer is now Computing a good representation of the input it's capturing all the vital characteristics of the input which are enough to reconstruct the inputs right so that is what is happening here and this is the objective that I am going to work with now notice that this is a single layer network network right so I had a problem I had difficulties in training a deep neural network so I've ignored that problem I've said okay I'll worry about that later right now let me just focus on this right so if I am able to train this entire network what does that mean that this layer is producing good outputs this layer is producing good outputs this layer is producing good outputs and this layer is good in producing good outputs and finally the final output is good right so this entire problem was becoming difficult for me I was not able to train the entire network so I'm saying let me just focus on one layer now and for this layer what is the definition of good that it should capture all the characteristics of the input that is how I have defined goodness and I have designed this objective function accordingly and I've reduced the problem to training a network containing just one hidden layer so input hidden and output and this is a shallow Network and shallow Network training was not a challenge right so I could train a shallow neural network so I've reduced my problem to training a shallow neural network now how do I go from here again because eventually I want to train the Deep inner Network that is not clear now but the first step is to just learn layer 1 effectively is that clear no no this could be W1 and W2 yeah so you when you compute the loss you are using that right so excited you are Computing the difference between X hat and X so there you are using that information right what was my original input so loss is defined in terms of what your original input was right so that is getting used there so it will be the same depends upon the input layers right no so this is n dimensional and then you are reconstructing the n-dimensional input yeah right yeah yeah okay so ah so this is what we have done now once we have understood this we're just going to repeat this process again right and let's see what I mean by repeat this process again yeah this is all written in words whatever I had said and yeah and one important thing is where is the word unsupervised coming in here right so remember that in this problem that I have I'm currently interested in solving there is no y There Is No Label here hence it is in unsupervised I am just having the inputs and my loss function completely depends on the input so I don't care right even if you had not given me y I don't care so there is no label or supervision being used here and this is whatever I am doing right now is unsupervised later on of course I will move to a supervised objective but right now whatever I am doing is unsupervised ok now once I have done this I am going to repeat this process so what I'm going to do now is that I was happy that I had learned H1 well right from the previous training so I did that round of training and I kept training that my training loss reduce and my H1 was a good representation now I am happy with H1 right so now H1 is some say d dimensional input now I'm going to plug in H2 okay and then again try to reconstruct H1 hat right and I'm not going to touch these parameters so you can think of the entire training data that was given me the M training samples that were given to me for each of those training samples I have computed h okay I have done that sorry H one I have done that right now my training data becomes H1 I pass it through a network a layer called H2 right so this was maybe D dimensional this could be D dimensional or some D1 dimensional and then I again try to reconstruct H1 from there so it's the same training objective right so now remember that the H is while we think of them as hidden layers or outputs they are also the inputs to the net say to the next layer right so just as X is H 0 and my first problem that I had solved was for its 0 now I am solving the same problem for H1 given an H1 I want to reconstruct it through a single layered Network right so again once again I am training a shallow Network one input layer which is H1 which is fixed I have computed all the H1s using the x that was given to me and the training that I had done in the first iteration I had computed all the W's I was happy with whatever WS I have computed and using those W's I have computed H1 now as W times x plus C or B whatever we had used into that right so this computation I have done now I'm thinking of H I's as H1s as my input passing it through a hidden layer and then reconstructing H1 hat and again using the same objective function with X replaced by H1 right so nothing new that I am doing so again I'm just training one layer at a time right this is the only layer that is getting trained which means this is the only layer that I am trying to reconstruct right and now what am I doing I had said that H1 captures all the characteristics of X similarly now H2 is capturing all the important information of H1 so it's yet another level of abstract representation of the original input right so this was already an abstract representation of the input which had discarded all the unimportant information and totally everything that you need to know about X and I can fully reconstruct X from here now H2 is an abstract representation of H1 which kind of captures every information in H1 and it's enough to cap reconstruct H1 from there so H1 is an abstract representation of x and it's to in turn is an abstract representation of H 1 so H2 is like a deeper abstract representation of X right so that is what you are doing and that's what the idea and a feed forward neural network is right every layer captures a more and more abstract representation of the input right so now again you have focused on layer H2 and made sure that this computes good representations that means you have cap and ensure that these weights that are sitting here are now some good or well initialized ways right so that's what you have done and now you will continue this process in the next iteration now you will freeze H1 and H2 now H2 becomes your input and now we will throw in H3 right and then you will try to learn these weights such that from H3 you are able to reconstruct H2 perfectly right and you keep doing this till all the L layers that you have so you are learning one layer at a time and each layer is trying to learn some weights which are an abstract representation which give you allow you to compute an abstract representation of the input right so now this is what you are going to do so at the end right what have we achieved that all our layers have been trained to compute a better representation of the input right and now I return back to my original problem my original problem was that I was given some X and some y right and I wanted to learn the relation between them and this was what my f x is now individual components and f x was itself a composite function right I was first Computing this then passing it then Computing this and so on so all these individual components of f of x now I have learned well right so I'll whatever weights I learned in those individual pre-training steps I'll just retain those I'll start from there I'll not start from random initialization I'll start from those right and I will plug in these weights randomly because these weights I did not learn so I'll plug in these weights randomly and now I'll go back to my original training objective which dependent on y hat and f of x right or yeah sorry not y hat Y and f of x right or this is what my objective function was so now I'll train for this objective function and when I'm doing this I will of course update these weights I'll do the full back propagation I'll update these weights I'll update all of these weights right but when I updating these weights remember that I have not randomly initialized them I have started from whatever my best configuration was while doing those individual unsupervised pre-training right so this is what I have done now why does this work what is the implication all of that we will discuss right but we have understood the procedure that we are training one layer at a time it's unsupervised because we are not using the final label once you have done the full unsupervised pre-training we plug in the supervised objective and we train for that supervised objective so I can think of this as L of Omega right this is what my L of Omega is right this is what was the unsupervised training objective and when they did this they showed that it's possible to Now train the entire Duke neural network effectively a thing which was difficult earlier and they trained quite a few I mean quite a bit deep neural network I have shown still in modern terms this is still a shallow network but they train quite a bit of a deep neural network right so what have we done right so in effect what we have done is we have initialized the weights of the network using that greedy unsupervised object right where at F why am I calling it greedy because at every layer I did not care about what is happening in the other layers I just wanted to make sure that that layer is trained properly that's why it was greedy and it was unsupervised and whatever was the result of that greedy and supervised training that is the initialization that exists in my network right so now why does this work better is the question and I'll give you two options is it due to better optimization or is it due to better regularization right now the first thing that I want to ask is whether you understand the difference between these two questions so what do we mean by optimization optimization deals with Dash data training data or test data training data so when you are doing optimization when you are minimizing the loss function right remember that you are taking the average whatever is your loss function over your Computing with respect to some um y i and F hat of X I right and this loss function depends on the training data these X I's and Y i's are your training data so optimization you only have access to training data you don't have access to test it but during regularization what do you mean by regularization regularization is used for better generalization So when you say better generalization it means that of course I know you will do well on the training data you will be able to drive the error to zero but what I care about is generalization which means on test data your performance should be better right so what is happening here is it that IFD did not do unsupervised pre-training you are not able to do better optimization itself that means even for the training uh data for which I have been assuming in all our discussions hey training data we can easily drive to zero we just improve the complexity of the model and we can drive it to zero but before 2006 is it that even on the training data I was not able to drive the error to zero or was it that because of unsupervised pre-training I was able to get better performance on the test data right so which of these is the reason for it to work better was it acting as a regularizer or was it acting as a better Optimizer right so now I comment that I want to make here right so this is I'm talking about the work which happened in the uh period of 2006 to 2009 right so this work 2006 happened this unsuper SP training idea came out everybody was excited that now we can train deep neural networks and then people started inspecting right why is this working is it optimization regularization and so on and not many clear answers emerged right but what got reinforced that hey indeed something is happening and now it is possible to train the Deep neural networks and it could be because of optimization it could be because of regularization so why don't we design better methods of optimization why don't we design method methods of regularization and so on and that's the effect that we saw from 2009 onwards our 2011-12 onwards we saw a series of better optimization rhythms right we saw all of that converging into Adam and then Adam and then again a few variants of that right so this sparked interest so whatever happened in this period maybe people did not have correct answers because these were again early days but these investigations suggested that hey maybe there is uh there is Merit in going after better optimization algorithms hey maybe there is better Merit in going after better regularization methods and we saw that one of the regularization methods that came out drop out around 2012 to 2014 that is still very popular right so because of these investigations people got excited and said okay it could be because of optimization it could be because of regularization if that is the case then maybe unsupervised pre-training is not the only method which leads to better optimization I could come up with better optimizers or maybe unsupervised pre-training is not the only method which leads to better regularization I could come up with better regularizers then early stopping came drop Dropout came and all of these right so then all of these got used in the context of deep neural networks and then people also thought maybe there are other things maybe you could initialize the weights better because looks like unsupervised pre-training is doing some kind of initialization of the baits so why don't I come up with better initialization methods then people said okay maybe there are something to do with activation functions because we're talking about gradients and maybe something happens and if you change the activation functions we might get better gradients and maybe things would improve right so all of that whatever work happened in this 2006 to 2009 period which I'm going to talk about for the next 15-20 minutes none of this I will be able to give you very conclusive answers hey it was definitely due to optimization or definitely due to regulation but that does not matter what matters is it opened up these possibilities and following this work we saw a lot of other advances half of which we have already seen we have seen regularization methods we have seen optimization methods and today we are going to see the remaining half of this once I go over this period of 2006 to 2009 okay so these are the two possibilities we don't know what it was and I'll show you some Works which hinted at both of these and then from there on we'll continue the discussion