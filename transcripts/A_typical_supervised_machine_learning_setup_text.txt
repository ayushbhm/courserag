[Music] hi uh so welcome back uh so we'll now talk about a typical supervised machine learning setup and this in my opinion is the most important module of the course of course as we go along i'll say this for many modules but i think this is the most important one right so please pay attention uh so this is what we have right so we looked at the sigmoid neuron and we looked at one particular function within this family which is the logistic function now what next right so we have seen this right so what what was our pattern when we had introduced uh perceptrons we saw the perceptron model and then what did we do where did it go from there we first looked at the algorithm for learning the weights right so we want the same thing now i've defined this but now how do i learn the weights that's not clear right so i want to have an algorithm which can learn these weights but before i had done the perceptron learning algorithm i had taken a slight detour and spoken about errors right because that was important to understand the error because the whole point of the algorithm was that whenever you make an error you do some correction right and that's why understanding error was important here also there is something similar so i'm going to revisit the concept of error again and then from there start working towards the algorithm right so but uh in this video we'll not do the algorithm we'll just do the machine learning setup right so let's look at that so coming going back to the perceptron algorithms and seen these kind of data distributions there and i had said that this is not linearly separable of course it is not and we had said that a single perceptron cannot deal with this data right or cannot deal with linearly separable not linearly separable data but what do i mean by cannot deal right what would happen if i apply perceptron algorithm suppose i blindly go and say okay i want to just apply the perceptron algorithm here what would it do can you tell me what would happen in this case it'll make errors for some points what's the point of a perceptron algorithm the idea of a perceptron algorithm is that you'll find some separation boundary right now we know that if the data is not linearly separable this it will not converge right because we'll keep toggling some points will be here and there but if i just do okay i'll just do it for some thousand iterations for a fixed k i'll do it so what do you expect would happen at the end it could draw some line right now there many lines possible you could draw this draw this or this many things right so what do you think is a line a possible line here that it would end up with if i just run the perceptron algorithm just think about it okay i don't i mean it's hard for you to tell me what you're thinking but just think about it and then when i show you the answer just see whether you are in agreement with that sorry somewhere in the middle of the data and uh we all understand what he means by middle of the data right so let's see so this is what it would do in the upper case right where most points are i mean some there are errors i mean there's that's a hard problem given it cannot really separate by a linear boundary but it'll draw some boundary right in the second case also it will draw some boundary and here the situation is better as you can see it's making an error on some three orange points which are getting classified as blue and maybe a couple of blue points which are getting classified as orange right and in most real-world applications we could deal with this kind of an error right so there are like maybe uh 10 uh blue points here of its two are wrong and 10 orange points of which two or three are wrong so 20 error we could deal with unless this is like a mission critical uh application in which case it might be difficult but in most real world applications we might be okay with it right for example if you're predicting whether this person is likely to vote for one party or the other and if you make some error in that prediction like 20 of the people you predict wrongly it won't make much of a difference right so it would still give you some rough idea of how the election is going right and in many cases of course unless it's a very closely fought election but in most cases if the error is around fighting person you can live with it right so from now on we are going to live with this idea of error that error may not always go to zero and our goal would be to just minimize the error as much as possible right so if i were to actually have a zero error here i would need something very complex right so i would want a decision boundary uh which perhaps i don't know looks something like this right and now even that is not enough uh yeah i just want an island here right so it's very difficult right i mean like a very complex boundary so that all the blue points are separated from the uh orange points and we'll be okay if at least i can find some boundary right where the error is as small as it can be and i can live with that little error right so that's what i'm going to do i'm going to now start using the term minimize the error instead of saying that the error should be zero right so that's one switch i'm going to make right and now with this background we are ready to discuss what a typical supervised machine learning setup looks like not machine learning but supervised machine learning right so always given some data okay what is this data this is sum r n right these are vectors belonging to rn okay and this is some let's for the simplicity assume that it's just a real value it could again be a vector right it could be the case that given the data about uh movie i am trying to predict the uh box office collection of the movie i am also trying to predict the imdb rating of the move right so i could be predicting two things here right but for now i'll just assume that we're just dealing with a real valued output and not a vector okay now we have already seen what this data also could look like right so uh and this is where the most important part comes in let me just quickly go ahead okay this is not what i want to do right so this we have seen application right so let me just define all of these right so these are my x's okay this is a vector which belongs to r let me just call it m right because i'm using n for something else and i have n such data points right so in my uh just i have n such data points so in my oil mining case uh i'm assuming that there are already n drilling stations set up somewhere and i have all the data about them right what was the pressure what was the salinity these end points by which i am defining a location or characterizing a location and i also know the y for them right so i have a m dimensional input i have a single dimensional output which is the amount of oil in mind for them and i have given some n such training points right so this is what a typical machine learning setup looks like similarly if i look at the other example where i had the credit card or maybe i had the bank interest rate that i wanted to decide right so i have the past history of the person and this history is being characterized by various things what is the salary of the person what is the education level of the person what is the family size of the person does he have any past loans what was the interest rate on the past loans how soon did he dispose of that loan and so on right so all of those are the past history and based on that for my existing customers i know what was the rate at which it was suitable to give them right and now this training data is given to me and there are uh n such training points each of which is m dimensional and i'm trying to predict a real valued output right and now you can think of on and on of so many such problems right so all the machine learning supervised machine learning problems have this form i'll give one more which is the movie protection problem or the box office collection problem right so i have want to predict the box office collection of a movie i have data about the movie right what was the budget of the movie how many superstars are there in the movie right how good who is the music director of the movie who is the cinematographer all of this i will have and based on past movies i know what what is the box office collection what is the genre of the movie all of this is there right and i know this so the form i've given such many such movies from past and such movies i'm characterizing each movie by an m-dimensional vector which is some inputs about the movie and i want to predict the box connection right so this is what the data part looks like and the main point here is that across all supervised machine learning setups this is what it looks like every machine learning problem you can cast it into this matrix where you are given the x's and the y's and you are given many such x comma y pairs okay now this is where now uh thinks uh the challenge is right this is what the crux of machine learning is so we have a y right and we have a reason to believe that this y depends on the input x right so what is the y here the box office collection and it depends on the characteristics of the movie right this depends this equation is still not complete y is equal to x is not what i want to write i want to write something else but i'll come to that right i'm saying that y depends on x then similarly in the interest rate y depends on that all the inputs that i'm taking and even in the first example of oil it depends so what do you what's the mathematical way of saying that something depends on something y is equal to a function of x right so i would say that y is equal to f of x right now if i knew this f there's no problem in the world right if i knew what is the function such that i plug in the values of salinity pressure density all of these factors and just tells me what the y would be if i had such a function all of us would be billionaires right we will just look at different locations plug in those values and wherever we get the highest mining we'll go and set up drilling stations there right but that function is not known right so this is the beauty of the problem we know that a function exists the output has to depend on certain inputs right these are the inputs and you could argue about oh but maybe you have not considered all the x's i would argue by saying okay consider all the x's if you have forgotten to consider the parent salary okay put it in you might say that it would depend on the parent salary you would say that you depend on the children's education okay put all of that in right and construct as comprehensive and x as you can and then i would say that the y depends on this x so y is a function of x so that is known that y is a function of x but what is not known is what is this function so now what do you do in this situation right so you want to now your goal is to come up with this function so that for new x's so for a new location which i say the shell company has hired you and said okay this is the location i'm considering can you tell me what is the oil that i could mine from there so you want to plug in that here and tell the company that this is what the quantity of oil i estimate right so you want to do that so what do you do in this case and this is the crux of machine learning that you assume some function okay you assume there is a function x parameterized by some parameters w or more generically we call it theta also at times so i'll just use theta maybe okay so you assume some form and that assumption is up to you right you assume that there is a function f hat which relates the inputs to the outputs it has certain parameters and now your job is to learn these parameters from the given data okay now let's look at a simple k so suppose you assume that y is equal to w x plus b this is a function okay and you have assumed that y depends on x it's capturing that and you have some parameters now how would you estimate the values of w and b if i give you two points maybe i should use a different form which is y is equal to mx plus c and now you would remember from my school that how do you estimate m and c if you're given two points you can get these two simultaneous equations and then you can find the values of m and c right so that is how we could do now in real-world applications it won't be like i mean i've taken a very simplistic example but what would happen is that you'll be given many such data points the key takeaway from the example is that if you're given data points which was two x comma y pairs right i have n x comma y pairs here if i just had 2 x comma y plus then i could predict the values of w and p right i could find out the values right and from that i just want you to extrapolate your belief and say that if you have many data points and many parameters you could come up with algorithms to find the values of these parameters okay in this case our algorithm was simple let's just construct a simultaneous equation and solve that simultaneous equation right but you could extrapolate this idea and you could say that if you have many data points given to you where the values of y and x are known and now you have some parameters to find you could estimate these parameters from the data okay so that's the game in machine learning there are few more details i'll now erase this whatever i have here and go into those details okay okay so our approximation of the relation between x and y is called the model right so when i say that i have a machine learning model what does a model mean model means your belief of what is the relation between y and x right and it could be anything it could be this function we just saw this that why it does it satisfy the criteria that i have y is a function of x it also has some parameters okay what is this have you seen this before in machine learning in machine learning what is this called it's called logistic regression right this is the logistic regression model what is this linear regression you are assuming there is a linear relationship between y and x this is you are assuming there is a quadratic relation right any of this assumption is equally good or bad right now in deep learning you are going to we'll see that later on again you assume some f right and as the name suggests this f is going to be very deep what it means in mathematical terms is going to be a very complex composite function right and we'll get there but again in deep learning there's nothing different it's just that as you had certain forms of f hat here deep learning has a certain form and that form we will see later as we go on okay now one question so why are parameters important here why can't i just assume that y hat is equal to 1 over 1 plus e raised to minus x why do i need the parameter this is also a function it y hat depends on x because this is a function of x why can't i just use this why am i complicating it by adding parameters different different weightages to different features okay but something more fundamental than that right let me okay so this doing this is akin to saying that y is equal to 3x plus 2. i have fixed my parameters right here i'm just saying that the parameter is 1 right what is the problem with this i'm not learning this i just said okay y is equal to 3x plus 2 i just cooked it up now who tells me whether 3 and 2 are the right values i have to learn that from the data right so if i don't have any parameters i have nothing to learn i just told you y hat is equal to 1 plus e raised to minus x now throw away all the data that you have for any new x that you get just plug in here and you'll get the value and live with whatever value and that's not what you want to do right you want to have certain parameters so that those parameters can be learned right so what would happen in the sigmoid case for example right this is what a sigmoid function looks like right and it will look like this s-shaped but depending on the values of w and b it will decide whether this is something like this something like this or is it something like this right so all of this will depend on your values of them so you can have a function form but you can adjust that form of the function by or adjust the shape of the function by using these parameters right so that's why if you don't have parameters and all your data is useless right if you just say my equation is this you have not even looked at the two points how do you know that those two points will satisfy this equation right so to look at the points and then come up with this equation right then you have to find the values of w and b so that's the same idea here that's why you need these parameters okay now learning algorithm right so once you have set up the model you have the data now you need an algorithm so that you can learn these parameters template in the case of y is equal to mx plus c our algorithm was simple just have two points plug them in get two simultaneous equations solve that right so the algorithm is the algorithm for solving the simultaneous equation and we are done right but in large parameters large data we need something better something more principled and we have already seen one example which is the perceptron learning algorithm and now we are going to see gradient descent in some time right so that's what we need now what should the goal of this learning algorithm be so when would you say that the parameters that i have learnt are good right so in the case of perceptron algorithm we had this loop which said while not convergence to this right and there we had assumed that the data is linearly separable so i will keep running the algorithm till no point moves right or still the w the new value of w does not move because all the points are on the correct side of the line or the play right that was fine but that was that means you were going for zero error right but now there is no idea of zero error as i said in most available applications we'll have to deal with minimum error right so then what should your learning algorithm do it should have a certain objective right in the case of perceptron the objective was to separate the data that means no point misclassified that means zero error now your objective function which is going to guide the learning algorithm has to be something about minimizing the error right how to do that what is error all of that we'll see in the subsequent slides right but that should what the goal be right and let's see yeah so the learning algorithm should aim to minimize the loss function right there is more to be said here but i'll not say those things in this slide we are going to come back to this slide again in a different form and then i'll say a bit more right so right now i think what should be clear is the data set up those three examples that i showed the model which is our approximation of the relation between x and y the learning algorithm which whole point is to learn w any learning has to be driven by an objective right so that the objective is to minimize the error function and that's what the objective is now how do you come up with the learning algorithm how do you define the objective function right so up till this point i have defined everything mathematically right but now objective function have objective function i have not defined so i will have to tell you what the objective function is but we will come back to that okay so now consider our movie example so this is the movie data given to me right x i is equal to movie i'm just using a shortcut when i say x is equal to movie i i mean that entire vector right all the actor information budget information number of superstars blah blah and y i is equal to 0 comma 1 right so that's what it is our approximation of the relation between x and y so our approximation was that y hat is equal to the sigmoid function of x right with the parameters being w okay then learning algorithm is gradient decent we don't know that but the idea of gradient descent is to find the w right and what is the objective function what should my objective function be right we can let's try to arrive at an objective function so i am given some data okay x comma y and now i have this approximation at the end of learning what would you want you would want that this y hat should be as close to y right that means the difference between y hat and y should be as small as possible okay for all the training examples that i have maybe n right if i sum up this difference okay and i'll not i'll just call it as difference right so difference between y hat and y and i can now define the difference the function the way i want to right so the difference between y hat and y sum across all the training examples should be as small as possible right that's the same as saying that minimize this difference right so this is my loss function now okay and i want to minimize this okay and i could choose different ways of defining this distance or the d function right and i could choose the squared error loss for example so what is this saying that this is my loss function which is i look at all the training examples i look at the difference between y hat and y and i take the square of the difference why do we take the square of the difference so that the positive errors don't cancel the negative errors right so now suppose i wanted the value to be 1 okay and it predicted it as 0.5 then my error is minus 0.5 okay yeah this was y hat this was y so y hat minus y is minus 0.5 but there was another example where i wanted y and y hat was predicted as 1.5 so now my difference would be 0.5 plus 0.5 so if i just take the sum of the differences then this minus 0.5 will cancel this 0.5 and it will look like i have zero error whereas actually i have made two errors and two horrible errors right both by off by 0.5 so the moment you square it that sign disappears right so you could take the square and the other you could have argued that why not just take the norm right it's just the absolute value right but the problem with the absolute value is that it's not a smooth differentiable function whereas a square function is a smooth differentiable function and we want uh smooth differentiable functions because later on the hero of the course is going to be calculus where differentiability would be important right so that's the area so now i have defined an objective function and the learning algorithm should find w's such that when i plug in these values of w this loss value that i get should be as small as possible what does that mean there are infinite possible values of w right so w is an rn vector right it's an n dimensional real vector right m okay sorry m dimensional real vector and these are real values ah that's okay m plus one right that's okay not a problem uh so order m we can say right so m plus one because w naught is also there so this is uh m plus one dimensional vector which can take real values each value can go from minus infinity to infinity right so there are infinite possibilities here of those i want one such w which if i plug in if i were able to plug in all these infinite values of w into this equation right this is the equation that i care about and i want that w which will give me the smallest value for the loss function that's what my goal is right so that's the objective of training now the other thing that i want to say here right i just want to talk a bit more about this learning algorithm and the loss function right so any kind of learning as i said is always driven by some objective right and i like to give this analogy let's suppose in high school you're learning trigonometry right so when you're learning the chapter what are you doing you're reading the chapter because you're allowed to read this is not a test right you're allowed to read the textbook and your goal would be to ensure that all the formulae which are given in the chapter you don't make any errors on that is that correct that's what your goal would be that is akin to saying that for all the training points that i am given i should not make any error or i should make minimum errors the minimum possible errors right so that's what training is then at the end of the chapter you have exercises right that's your validation set okay because now you you you have not seen this formula you have just learned the formula in the training data but using that you should be able to solve this exercise and you might make some mistakes here so you're again allowed to go back and relearn the chapter right you could say oh i'm not able to figure this out maybe go back and look at this right so that's your validation set and then you have a test set which is your exam so now you have done the training you have done the validation set again toggle between training and validation and maybe you have some confidence now once you go to the test set once you go to write the exam you're not again allowed to do the training right so you have a training error you have a validation error and you have a test error during training what we are talking about is the training error which means the error on the training data right which is the error on the chapter that you have read right the contents of the chapter you should know all everything well or you have minimum errors right so that's the analogy you should keep in mind okay uh yeah so i'll end this uh module here and we'll come back and talk about and ways of learning these parameters right so let's let's do that