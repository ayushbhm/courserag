foreign [Music] let's go ahead with our original goal right which was to find that Delta Theta which is good now what do we mean by good is something that we discover now right so for ease of notation let's just call that Delta Theta by U I don't want to write this Delta Theta every time so then from Taylor series we have the following right that we have uh L of theta plus and it's this is where that Epsilon comes into play right I was saying that we want the difference to be small right so I am at some point Theta and this is some point Theta Nu right this is what this point is and I'm saying that it's just a small distance away and this is where this ETA is important right it makes sure that the distance is small because we know that the approximations are good in the small neighborhood okay now this is L Theta now what are these other terms here right this ETA is fine right that's our small uh that multiplication will keep happening everywhere now this here is that seems to be the dot product uh between two quantities right now you I have already defined here right U is the change that we want to make so that's nothing much to explain there but what is this other quantity that you see here and let me just underline it with a different color so this quantity so we'll try to figure out what that quantity is so let me clear up the slide now what that is is the gradient right and that's where the name gradient descent comes from but let's try to understand what that gradient is right so now if you have a function right let's say x square okay I have y is equal to x square then I know that d y d x this is called the derivative all of you know this from high school which is 2x right so this is fine this everyone knows right but now suppose I have a function y is equal to W square plus b square right now this is a function of two variables so now I can say and node is a change in notation right it's not D now it's do is 2W and dou Y by dou B it is 2 b and what have I done here this is known as the partial derivative so I have taken the partial derivative of this function once with respect to W the other time with respect to B because these are the two variables on which the function depends right so these are the partial derivatives so this is derivative when you have a single variable function these are partial derivatives when you have a multi variable function and you're just taking the derivative with one variable treating the other as constant right that's why the derivative here disappears because you are taking the derivative of the b square part with w and it does not depend on W so hence the derivative will be so that is the partial derivative now the question is what is the gradient then the gradient is nothing but just the collection of the partial derivatives right so that gradient in this case would be 2W 2B right so it's the collection of all the partial derivatives is called the gradient right and in this case I have only two variables so I'll just have two partial derivatives so I'll collect them and I'll get the gradient vector and the gradient Vector is a two dimensional Vector in this case right so that's what this quantity is you have the loss function Theta and you are taking the gradient of theta of the loss function with respect to Theta and we know that Theta is nothing but W comma B and this Theta is also W comma B so this is just a vectorial way of writing it that you're taking the partial derivatives with respect to W and B you put those partial derivatives in a vector that Vector is called the gradient and this is the quantity that we are using to denote that gradient and now it makes sense because you're taking the gradient of a function which is a function of a vector with respect to that Vector right that's what that's how you should read right so this is what this quantity is right now for this discussion I think I can stop here because this is where I am going to draw a line I am going to cut the formula at the linear approximation but let me not do that let me just go a bit ahead and also try to tell you what this quantity is Right which is right now here if I ask you what's the second order derivative that means I'm going to take the first derivative and again take the derivative with respect to X again and that's going to be uh 2 right so this is the second order derivator now what this is is the gradient of the gradient right that's a bit uh confusing to understand so this is what your gradient looks like it's a vector containing the partial derivatives now again you are taking a derivative of this Vector with respect to your parameters which is nothing but taking the gradient with respect to Theta right so what would this look like so you have ah two elements in this Vector right so for each element you will take a derivative with respect to W you will take a valuator with respect to B for the second element also you will take a derivative with respect to W and you'll also take a derivative with respect to B so what you will get is dou Square l by dou W square right so you had the first partial derivative you are taking the derivative of that again with respect to W so that's what you will get now the same partial derivative you will be taking a derivative with respect to B now so you'll have dou dou b dou w and similarly you could fill the remaining two entries here right so this would be dou b square and this would be dou w dou b right so the way you should remember this is the following right so when you are taking the derivative of a vector okay with respect to some another vector okay what are you trying to do you're trying to say that if this value changes how much does this value change how much does this value change right and if this value changes how much does this value change how much does this value change right so the derivative of a vector with respect to a vector would thus be a matrix right and what would the dimension of the Matrix be if this was M dimensional and this was n dimensional then this would be an M cross n Matrix right so if you had for example three elements in this vector okay and you're taking the derivative of that Vector with respect to two elements so what would happen is that each of these elements suppose these uh two elements that you have here are your parameters W and B right so each of these elements would be a function of w comma B and hence you can take that derivative so when you're changing W you want to see how much does this value change because it's a value function of w comma B so how much does this value change how much does this value change how much does this value change right so you're asking for three calculating these three changes and then we change the value of B again you want to change how much does this change how much does this change how much does this change right so there are six values that you're trying to compute so then set what we are three cross two or two cross three depending on how your uh uh seeing it right so it could uh so it that's what it would be right so that's what and this second order derivative is called the Hessian uh uh Matrix and then similarly you could imagine what would be here there would be a third order uh derivative here and you can again imagine that you have a matrix and now you're taking the derivative of every element in that Matrix with respect to a vector and so on it but that that I know I won't go that far I'll just stop here although even this we don't need for the current lecture okay so I hope that is clear so uh partial derivatives derivatives sorry derivatives partial derivatives collection of partial derivatives is the gradient the gradient of the gradient is the Hessian right and here are a few things to note now right so if you have a scalar quantity right so if I have a function which is Y is equal to x square okay then the derivative would be 2x so if I were to compute this at a particular value of x then I'll get a square right so derivative of a scalar with respect to a single variable is a scalar but now if you have a vector or if you have a quantity uh x square okay all this is x square plus Z square right then I can take the derivative with respect to X and I can also take the derivative with respect to Z so then I'll get a vector right so the derivative of this would be a vector which will be basically the gradient right so that's that's what uh we are uh understanding now and this is where I'm going to draw the line right so my argument for that would be that ETA is small so ETA square is going to be even smaller hence I can ignore this ETA Q would be even smaller so all of this I can ignore right so since ETA is small I'm just going to cut the derivative or cut the formula here and I'll just use the linear approximation and we have just seen previously that when ETA is small a linear approximation is good enough right so I have reason at least I have shown you geometrically that I can do that okay so this is what I'm going to do okay now ah this move right this is the move that I have made I was comfortably at some value of theta there was a certain loss there and I decided to make this move now this move would be favorable only if what is the condition that I would want I have moved and I would call the move to be favorable only if so only if this value is less than this value right otherwise it's not favorable I was at certain loss now I have moved and if the loss increases then that's not a favorable move right why I should have why would a better State there right so I would like uh you only if uh the new loss is less than the previous loss right so that's the condition that I want so what I want is that if I do the subtraction If I subtract the new loss from the old loss then I should get a value less than 0 which is a simpler I mean it's just another way of saying that the new loss is less than the Old Law so that's all I'm seeing right and now if I just look at this equation here what is this quantity so I just take L Theta to the other side and I am left with this right so what I am saying is that this quantity should be less than zero that's what I'm effectively saying right so I'll just delete some stuff so this is the quantity that I want to be less than 0 if I take L Theta this side then that is the quantity that I get and that is just equal to this quantity right so if I want this quantity to be less than equal to 0 that means essentially I want this quantity to be less than zero right and I have omitted the ETA here because ETA is a positive scale right that's uh you we don't take a negative scalar there so ETA is positive so that will not affect so I can ignore ETA here and this quantity should be less than zero okay so that is what I have arrived at from the uh Taylor series and why is this why am I interested in this because this is a condition which depends on you right so now I'm what is being told to me that you have to select a u such that U transpose the dot product of U with the gradient Vector would be less than zero only then your U would be good so this is a condition that has been imposed on my U Now using this condition I want to find a good U which not only satisfies this condition but satisfies this condition in the best possible way right and I'll tell you what best possible way it means right so what is the range of this right so this is the dot product uh between uh two vectors I think this should not be there this is the dot product so what is the range of this right so let's try to understand that so let beta be the angle between U transpose and the gradient vector then we know this right this is the COS of the angle this is just the formula for the COS of the angle and this quantity which I was interested in luckily shows up in this formula hence I am interested in it right so this is what uh cos beta is and the good thing is that cos beta is bounded right so that means this quantity is also bounded okay good so if I multiply throughout by this the denominator that you have here I'm just calling it K so that I don't have to write this large quantity every time so this is what I get right so the quantity that I am interested in I know that it lies between minus K and K right and I don't care about uh the positive values of this quantity right I want this quality quantity to be less than 0 right so I just care about the negative side because I want my condition was that U transpose into this gradient should be less than 0 that's the condition that I have right so I am interested in the values which are less than 0. so now if I'm interested in values less than 0 I should ask this question right how less can I be and the more or less the better right because what is what is this quantity this quantity is the difference between the new loss and the current loss right and I the more negative this difference the better right that means my new loss is as low as it can be from the current loss right and when would this be when would this difference be maximum when uh this quantity is as low as it can be right because this quantity can be as negative as it can be and this is that quantity it can be as this is how negative it can be and when will be that negative when the angle or the cosine of the angle is minus 1 because this condition is directly been derived from here right so if the cosine of the angle is minus 1 that's when I will get the most negative value for this quantity which is my quantity of Interest right and when would the cosine be minus 1 when the angle between the two vectors is 180 degrees which two vectors the vector U and the gradient vector so that's where I get my U now I want you to be at 180 degrees with the gradient Vector that means I Want U to be opposite to the gradient Vector hence in gradient descent and this is something you would have heard a hundred times I move in the direction oppose it to the gradient right so this is how that formula or how that rule comes we started off with the Taylor series that gave us a certain condition on what a good use should be then we've pushed that condition to be to its limit right we wanted it to be less than zero but we said let it be as less as newer as it can be and we found that that happens when this happens okay and that happens when beta is equal to 180 degrees and beta is the angle between these two vectors so that happens when U is exactly opposite to the gradient Vector right so that's why you move in the direction oppose it to the gradient vector let me just delete this is more negative is the most negative right not just more negative it's the most negative when cos beta is equal to minus 1 that is when beta is equal to 180 degrees