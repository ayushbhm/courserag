foreign [Music] so welcome back so we were talking about activation functions and we looked at a few popular ones starting with the logistic function then the tan H function uh then the relu and a few of its parameters like the Leaky relu the parametric uh relu and then the exponential uh a linear unit right and in all of these cases we made some comments about how do the gradients behave and then what can we uh do to uh how these activation functions evolved to take care of certain drawbacks of the earlier activation functions right so tan H was preferred because sigmoid had certain problems it was not zero centered so moments only in few directions were possible and relu is better than tanh and sigmoid because it's simple to compute and it does not saturate in the positive region then the variance of relu are better because they allow some gradients to power flow even when the in the negative region right and so on so we did all that and now we look at continue our journey on a more activation functions we'll do around three to four more uh starting with the max out activation function right so we'll motivate that uh starting with Dropout and then try to connect it to how there is some uh kind of I wouldn't say relationship but some analogy that you could draw from Dropout okay so we had discussed about this model averaging where you have a data set and you create sub data sets from here by sampling with replacement what do I mean by that so I have say a thousand data points okay I want to create another data set of thousand uh data points uh as how I will do that is I'll pick one training example from the original data set put it in this bucket right and then keep the training example here also it's not being removed so it's not that now you have 999 samples here you have the entire thousand samples I took one from there sample randomly one from there created a copy and put it in this bucket and I still have thousand here again I send them sample one randomly and put it in this bucket and I keep doing this till this bucket has thousand entries right so I'm create I'm sampling with replacement and I'm creating multiple such uh sub multiple such training sets from the original training set and each of these training sets will then be used to train a model and those models would have their own parameters like W1 to WK so here W just think of it as T direct it's a collection of all the parameters in the models I'm calling it W uh here all the parameters in the model and here W1 W2 correspond to the parameters of these K different models each trained on a different version of the training set and each training set has the same size but it contains uh sampling with replacement right so what would happen in that case is that it is shown that if you do this sampling with replacement right so this bucket that you had the first bucket that you created that was used to train the model f hat1x which had a collection of parameters W1 so that bucket around 46 percent of the samples there would be duplicated and does make sense right because you're sampling with replacement so all roughly half the samples would get duplicated in this set so it won't be that all these thousand would be unique that should be obvious and there's also some analysis that roughly half of the samples are actually duplicates so we always expected duplicates there's a study which says exactly how many duplicates you can expect right so now you have 1000 data points but there are duplicates in that so now the model has a better chance on overfitting on that right because now you have fewer samples than the original training data and you're seeing the same samples again and again some other model gets a chance to adjust on the same sample more times now right and hence in these models uh each of these models F1 hat to F2 had would like really better overfit to the bucket of training data on which it was a trained because that bucket is containing duplicates and it's each model is seeing the same training examples multiple times and then when you do inference you do some kind of model averaging it could be arithritic mean or geometric mean uh any of these are possible that we have seen it so we take the prediction from all the K models and then we take the average is 1 possibility or you could take the max that is another possibility you could even take voting all of those possibilities exist right so this is what happens in uh model averaging and then in deep neural networks the way we had done that was using uh Dropout right so we had uh we knew that it's difficult to train multiple models so Dropout was a substitute for uh uh for getting the effect of model average okay now uh the same thing I'll just repeat right so the model weights get optimized for a specific set of sample each of those buckets corresponding to one of the models the model is over trained on that bucket so it overfits but in dropouts we don't have a similar luxury right so in dropouts what is happening is that you have these multiple sub models each sub model is getting sampled rarely right because there are an exponentially High number of sub models so each sub model is getting sampled rarely so each sub model is not getting the chance to overfit on specific portions of the data because hardly it will see the data once I mean forget about seeing it twice it may not even see it once right so this kind of uh phenomenon which happens in model averaging or in bagging where the each model gets each sub model or each different model gets a chance to overfit on the training data Dropout does not really get that chance right so now uh in the case of bagging the model is getting to update the weights again and again on the same training sample but in the case of Dropout it's not getting that chance so whenever it sees a sample we should try to do a larger update right because this if this data point is sensitive we should try to do a larger update but then how do you do a larger update maybe you could increase the learning rate but if you do that there could be problems right we have seen several problems in with increasing learning rate and the case of dropouts since these parameters are shared across all these sub models now you increase the learning rate it could have effects on the other sub models right so that's the situation where we are in we drop we motivated dropouts from model averaging but now we are observing that something which happens in model averaging where every model sub model gets to overfit on the specific training data that effect does not really happen in Dropout and in Dropout still we do model averaging right so now the way of model averaging was again that each of these neurons you consider their out port and you multiply it by a fraction P which is the number of times this neuron was on right so we are just assuming that all neurons were equally participating and equally sensitive to all the training examples and hence they were all on only a fraction of times P so we'll take all of their weight as P assign a weight P to all of them and then do the model averaging right but this Gap is still not being addressed that in bagging actually the model overfits on specific samples whereas in Dropout the concept of overfitting is not really happening on any specific training examples because each sub model is rarely seeing the training data right so now how do we close this Gap can we do something so that's where MaxOut gets motivated from so this is what Dropout does right so drop out at every time step now you have four neurons in the hidden layer H one one H one two H one three h one four so we'll apply a mask right with probability P so some of these would be on some of these would be off the ones which are off will not participate in the computation so in particular if I am Computing a to 1 only h11 and h14 will participate with the corresponding weights w11 and W one four if I am Computing a22 then again only H 1 1 and H2 h14 will participate with the corresponding weights w21 and W 2 4 right uh and now what would happen uh yeah so now now let's consider a scenario right where uh uh these two outputs a21 a22 have the following relationship they're both greater than zero because I'm taking them greater than zero because it's a relu activation function so I want both of them to be uh active and not dead so say both of them are greater than zero but a two one is less than a to 2 right so what does that actually mean uh let's try to understand that in terms of how neurons react to training samples right so if a21 is actually uh less than a to 2 it means that 8 to 2 is reacting more positively to this training sample right it's firing for this training sample even better because its output is high right so now if it related to our earlier discussions on MP neurons and so on we had the situation that if the inputs are of a certain configuration then this neuron fires right now this neuron is firing More Than This neuron which is firing weakly right so now that means this neuron is more uh sensitive to this training data and maybe I should respect that right so when I'm updating can I update this better as opposed to updating this right because this is reacting weekly right so can I do that so one option of doing that is to take the yeah so this is the effect that we want right that we want to make these we want to acknowledge the fact that these neurons are sensitive to Turning certain training samples one neuron is more sensitive than the other and hence I should perhaps try to get this effect which I had in bagging where the neurons were adapting to the specific bucket of training data and now since this neuron has shown such some preference for this training data can I give it more preference can I make its updates better so as opposed to the relative updates of the other neuron right I don't want that other neuron to specialize for this training sample because it has not shown interest in this training sample right so one way of doing that is now I could take the max of these two so max would turn out to be a22 right and then when the gradients flow back right so now what is uh h21 it's the max of a to 2 and a21 which is equal to a 2 2 right so now if I take the derivative of h21 with respect to a21 and the derivative of h21 with respect to a22 then this would be 0 and this would be 1 so the gradient will only flow to this part it will not flow to this part right and that's what you wanted to achieve that you wanted to make this neuron specialized by giving it the signal and ignore this neuron because it was not really showing much enthusiasm for this input so let it not fire and I'll kind of ignore it and just try to make this other neuron specialize on this training sample and if you do that then in some sense your different neurons are uh kind of getting adapted to specific training samples and you are getting the same uh effect as you expect in model averaging or in bagging right where certain neurons are certain sub models are specializing for certain training samples right so that's the effect that you're trying to achieve and hence you do this Max now what was a21 a21 was actually this and a22 was this so you can think of these as there are two linear Transformations happening here and you're selecting the max of those linear Transformations and by restricted 2 right so you could even have K linear Transformations and you could select the Max from that right so let's let's just delve a bit more into this over the next few slides to get this picture uh clear of what I mean by K linear Transformations right so this is what happens in Dropout right we're still trying to compare Dropout and see what was happening there so in Dropout what happens is uh I can divide this nodes in this hidden layer right uh this was the hidden layer I am dividing nodes into three parts one is the black nodes which have been dropped out so they are completely not participating in the uh uh in the output right they are not participating in the computation at all and then there are two types of nodes one are strongly responding nodes and the others are weakly responding notes and now in the case of Dropout irrespective whether you're strongly responding or weakly responding the gradients do flow back to you right and the gradients will of course flow back in proportion but you're still all of you are being responsible for the output and the certain nodes may not maybe get spatialized for the specific input right so that's what is happening in the case of Dropout now if you look at the sub model that we have in the case of max out what is happening here is the following right so this is what is happening in max out now I have considered a max out layer and because I can't show many uh neurons here this is One max out neuron okay this max out neuron in turn has three nodes each of this has some uh linear transformation right so this is W1 transpose X this is W2 transpose X this is W3 transpose X and then I'm only taking the max of these guys and allowing it to pass forward right so in essence these two nodes have been dropped out because of the max operation so you are getting the same effect as Dropout similarly you have these two nodes here three this max out neuron here which has inside three linear Transformations happening okay let me just call them as W1 maybe call it w tilde transpose x w 2 tilde transpose X and W 3 tilde transpose X see here again I had three linear Transformations then I just selected the max of those and dropped out these neurons right so now as opposed to Dropout where after dropping out all all the neurons participate and even during inference we take equal weightage to all the participating neurons now we are ensuring that the neurons which participate Only The Strongest Ones of those are actually active and we are further dropping out the weak one okay so this is uh what max out looks like so you have Max of multiple affine Transformations I've been saying linear but they would be a fine because there's a plus b also possible there right yeah so these are in multiple uh neuron multiple uh affine Transformations inside I have shown n of those and then you're just selecting the max of those two right and uh you you could even think of max out as a generalization of the relu function right so now you could think of uh a relu function uh any of the relu functions right relu or leaky value or parametric relu as a generalization of uh or as a special case of the max out neuron uh such that there are two max out I mean two neurons inside the max out neuron and for one of them the weight and the bias is zero and then for the other one you have W2 X plus b now in the case of uh relu now W2 is again just equal to 1 and B is equal to zero so then you're just left with Max of uh this quantity is 0 and the other quantity is just X right now in the case of the earlier leaky value that we had seen this was 0.1 x so you could think of right as again Max of uh zero comma 0.1 x plus the bias again is zero right so this is also a special case of the max out neuron so you can think of max out neuron as generalizing relu and all its variance and uh again it gives you more uh Power more non-linearity so this is what if you have these two max out neurons right so if one of them learns the the value of W1 as 0.5 x and the other one learns the value of W2 is minus 0.5 x then effectively you are getting this v-shaped a non-linearity right which is uh the same as the absolute function and then you can also show there are certain configurations possible so suppose you have uh four uh affine Transformations within a max out neuron right so I'm talking about a max out neuron this is what a max out neuron looks like it has four affine Transformations and I'm going to take the max of those right and if those are fine Transformations happen to be these these are the four refined Transformations if I take the max of this then I almost can approximate the x square function right so it's uh it's giving me a higher degree of a non-linearity and of course it has the other benefits there is uh no saturation no death now because it will flow through the max path and the max at least one of the neurons would be great as long as it is greater than zero you would have some gradients flowing and for multiple affine Transformations the more you have there is a proportional increase in the number of parameters you could think of that as a disadvantage but there is a proof which also shows that two max out neurons with sufficient number of affine Transformations right so just have two of these but you have a large number of affine Transformations inside them right then these can act as a universal approximate so you just need like two max out neurons to approximate any function so that's a uh kind of a testimony for the uh non-linearity or the representation power that max out neurons brings in August makes out neurons uh despite whatever I have explained are still not very popular I think their special case which is relu or any of its variants they are still more popular but it's good to know about them it's good to see the analogy with Dropout it's also good to see how they generalize relu and other functions is also good to know that just two max out neurons are uh can act as a universal approximately so this all helps you build a better understanding of some of the concepts in deep learning right so so that's all I had to say about the max out neuron um I'll end this video here and then I'll come back and talk about some other activation functions