foreign [Music] okay so I'll just demonstrate that algorithm in a toy setup right now whatever we did right so this is a function that is given to us and as you can see that this function has multiple minimally that's one here there's one here there's one here and I'm just going to try to follow the gradient descent rule right which is wherever I am currently which is w I'm just going to do W minus ETA W right so that's my going to be my new value so right now I want a value of w which is 1.2 okay I have done the computation there I have calculated the derivative okay so remember that derivative of x square for example right is 2X but now if I compute the uh this value at x equal to 1.2 then I get some scalar number right so that's what I'm going to do here so my w is equal to 1.2 so whatever is the derivative in that formula I'm going to plug in W equal to 1.2 and I'm going to get some answer for what the derivative is right and then my ETA is set to 1 so that will give me what n n into derivative should be and that value is what I'll uh keep changing okay so let's start and I'm not going to do this in um great detail as you can see this is like set up as a game for you to practice and try to reach at the Minima so I'll just show you a few steps of how to do it so now my 1.2 is what my value was I have calculated the derivative and that ETA into DW turns out to be 0.31 right so I'll have to move in the direction oppose it to the gradient so I'll do 1.2 minus 0.31 so I'll just enter that in this uh box here right so 1.2 minus 0.31 is going to be 0.89 okay so this is where I end up right so I have moved and looks like I have moved in a good direction because I'm headed towards one of the Minima right uh so zero point uh now uh at this point I have 0.89 is my current value I've again computed a derivative and my ETA into DW is 1.25 so I'm again just going to ah 0.89 minus 1.25 is what I'm going to do and that would be around minus 0.36 right so I'm going just going to set the value as minus 0.36 and this is where I get right so as you can see I have moved a bit away right I should have I would have liked to end at the Minima but now I've gone in the opposite direction right and why this is happening what could you do to make sure that this doesn't happen is something for all of us to figure out in the next couple of lectures right now just keep trying this right I've shown you what to do you just follow this and as I said it's like a setup as a game you could just keep trying this and see right and now you can notice it uh so far I was moving in this direction right I started here then I went to a point here then I went to a point here and now it looks like I have to come in the back Direction I have to come back and so on so you just play with this and you just keep following the update Rule and see that you'll slowly start moving towards the uh one of the minimas that are there in this function right and you could also initialize the W from a different point right you could initialize it from say this point here and then you will see that it will start going towards this Minima if you initialize it to a point here it will start going towards this Minima right so what I've done is I'd initialize it at this point right which was on this side of the slope so that's why it went there if I had initialize it here at this value then it would have gone into this minimal so just play around with this try different values of w and keep following the formula and see whether you are able to reach the Minima I'm sure you will not be easily able to reach the Minima and one of the problems there is that ETA is a bit large so it's not helping you to control ETA into DW here I wanted the ETA to be small which so that I could have reached the Minima instead of Crossing it I've crossed the minimine going in the upper Direction so all of this is something that we'll do in detailer and at this point I just want you to kind of break your heads with this and try to understand the problems that show up right I don't want you to fully understand this nor do I want you to get the solution but I just wanted to see what kind of problems you face and how would you change them I already gave you a few hints right that uh you might think that oh this is the global Minima but I started from some point here 1.2 and I'm not being able to reach there right then what if I had initialized it a bit differently would I be able to do that so what is the effect of initialization what is the effect of ETA as you make ETA very large what happens if you make ETA very small what happens right so just try to experiment with those things and just get your hands a bit dirty with this okay yeah so now we have the gradient descent rule that the direction U that we intend to move in should be at 180 degrees with respect to the gradient in other words move in the direction opposite to the gradient so this phrase I'm sure you have heard a million times but now you know where this phrase comes from uh and this is what my update would look like whatever is my current value of w uh sorry whatever is my current value of w I just take the gradient or the derivative right and then move in the direction opposite to that because of the minus here and by a small conservative step because of ETA and this ETA comes from the fact that Taylor series works well in a small neighborhood hence we are using a small ETA there right now this year if I put it in a vector this is nothing but Theta t plus 1 okay maybe not the best choice of colors here if I put this in a vector this is Theta t and if I put this quantity in a vector then this is the gradient of the loss function with respect to Theta right okay at time step T right at the time step T right so now let's try to again uh clarify the notation so this are the entire thing I can write in Vector form that's what I've just shown now some more clarification so what does this quantity Delta WT mean right so Delta WT is the partial derivative of the loss function which is a function of two variables W and B with respect to W and then evaluated at w is equal to WT and B is equal to BT what does that mean so now if I have the function is W square plus b square then the formula would be 2W 2B right this is what the formulaic representation of the gradient would be but now I can evaluate this at the current value of my w right so I'll just substitute the value of w and if I do that then I'll get a two real numbers so I'll get a real valued Vector right as opposed to a formula I'll get a vector so this is always this that you have the formula for the derivative then you can evaluate the derivative at a specific point by putting it those uh points uh the that point into the formula so that's what I mean by evaluated at w is equal to WT right so that's what this quantity is signifying that it's the partial derivative evaluated at that point and that's exactly what we are doing in the previous slide we are getting a real number at the end which we could add and subtract and so on right so that's the idea yeah so now we have a more principled way of moving in the WB plane we are no longer doing our guesswork we know that if we do we just saw a proof or we arrived with the formula mathematically that if we keep moving in the direction opposite to the gradient we are guaranteed that the loss at every step will uh decrease not that it will just decrease it will also decrease by uh the largest amount right now one thing you should have noticed on the previous slide in my last update actually you could go back and check whether the loss had increased or not and if the loss had increased what could have been the reason for that and the answer there is that the learning rate or the ETA was quite high but all of these are things that we'll come back to so don't worry about okay so this is the algorithm that we have created uh we'll start at time step 0. we'll set up some Max iterations we'll initialize W and B randomly and well while we are less than the max iterations we'll just keep doing this uh repeatedly right whatever is the current value of w we're just going to get a new value of w from that by following the gradient descent rule right and we keep doing this for the max number of iterations and by then uh the we should be at a point which is very close to the Minima right that's what's the hope is okay now uh everything in this algorithm is known right I could have actually run this algorithm it's just that I don't know what is Delta W and Delta B is right for so let's see what I've given you the definitions of them right but what is that formula how do I actually compute this the partial derivative of w with respect to the loss function because I have not even told you very clearly what the loss function is in so far in the discussion if you're just working with a generic function L of w so we now need to look at the what the actual loss function is right so here's coming back to our original example where we had two parameters W and B this was our function okay and our loss function was defined as this right that let's assume there is only one point there's only one data point so a loss function was summed over all the points and then take in the average but now I assume that there's only one data point so there's no summation here and summed over what it was the prediction minus the true and the square of that right so that's what this formula is f of x is our approximation Y is the true value so I am taking the difference between the two and squaring it right and there's one by two I've just kept for some convenience it does not uh I could use any multiple here right it does not change because I'm looking for the lowest value of the loss whatever is the lowest value if I If I multiply all values by half that value of w comma B which at which I get the lowest value does not change right but it just makes it a bit convenient for me from a mathematical perspective I'll become clear why how okay so this is uh what our loss function is now I come to the definition of delta W which was there on the previous slide is the partial derivation of derivative of the loss function with respect to W which is the partial derivative of this function with respect to W so this is the quantity that I want to compute now right uh so this is the partial derivative now this is easy right so this I can just I know that this is a function of w comma B right this is my sigmoid function which has the parameters W and B so this is a function of w and B so I'll just take the derivative and then push the derivative inside it so this is the derivative of uh of fun of the square of a function of w so it will just be 2 times that function into the derivative of the function right you just you this chain rule of derivative that you know so this is some function which depends on W then you have taken the square of that function and now you are taking the derivative the first thing would be 2 times the function and then you push the derivative inside so you get the derivative of the function with respect to W okay now this is of course a constant right because this is the value True Value which is given to us it does not depend on wnb I can choose whatever W and B I want the True Value will not change so that the derivative with respect to that will be zero so the only thing that I am read is the partial derivative of the function with respect to uh uh the W right and you can see why I had chosen this half here because this half N2 got canceled it just makes my life easier so and now if I just substitute the value of f of x so this is the value and this is the derivative that I want to compute so let's try to compute right right so this is the derivative of again of the inverse of a function of w right so this is 1 over something which is a function of w so the derivative would be minus 1 over that function square and then the derivative pushed inside so derivative of this should have been 1 plus that e raised to minus W X plus b but 1 is a constant so it's anyway is going to the derivative will be 0 so I have not written that right so now derivative of e raised to minus W X plus b so that would be e raised to minus W X plus b into the derivative of minus W X plus b and now again B is a constant so that would just give me minus one so oh sorry uh minus X sorry derivative of w x with respect to W would be minus X so I have these two negatives minus 1 and minus X so that will become a positive okay so this is what I get now what is this this is just my original f of x right so this is f of x so I can just write f of x and you can go back and check this this is essentially 1 minus f of x right so you can go back and work it out so if you just take 1 minus 1 over this formula right then you will sorry 1 minus this formula then you will get this right so I can just write it as f of x into 1 minus f x right so now I'm going to substitute this value back in my original equation so this is what I get I had this term already from earlier and now this entire quantity is this as I have just derived right so now I exactly know what Delta W looks like and now if I give if you give me a value of w and B I can substitute that in this formula and I can get a real numbered value right so I know the formula that I was looking for okay so if you have only one point then we have the Delta W is equal to this if we add more than one points then it will just be a sum of all those right so this is uh the derivative of uh the loss function with respect to W when there was only one one point right so in that case LW itself was uh just f of x minus y the whole square right but now if I have many points then I'll have a summation here and I'll Index this by I I'll Index this also by I right so I have a summation so I have told you the derivative for one term in this summation if there are such n terms in the summation then the the derivative will also get added up right so the derivative of a sum is just the sum of the derivatives right so that's what is happening here so I have just taken the sum now so if there are two points I'll have this the sum here so I have this right now similarly you can compute the derivative of B and you can see that all of this is same the only thing extra here is this x i and that is coming from the fact that you had W X plus b so when you take the derivative with respect to W this x is what you get but when you take the derivative with respect to B you don't get this x that you just get 1 here that's why you are having this uh into 1 here and into X there right so now you have the formula for Delta uh for the uh partial derivative of the loss function with respect to W and the partial derivative of the loss function with respect to B right so you have both of these and now we can construct an algorithm out of this okay so let's see what that algorithm is so I started off wow so this I hope you can see it so these were the two points given to me these are the same two points that we have been looking at since the last lecture so x equal to 0.5 where the value of the function was 2.5 and x equal to 0.2 where the value of the function was 0.9 okay now I want to do gradient descent to find the right W's and B's so I've set W to minus 2 my initialization is minus 2 B is also minus 2 I have kept ETA is 1 and I have set the max epox as 1000 right so this is what my initializes are now for I in range of Max epox that means for thousand iterations I have initialized the derivatives to zero and for X Y in my data points right so all the data points and iterate over all the data points I'll compute the gradient with respect to W or the derivative partial derivative with respect to W I'd also compute so let's see now I want to compute the partial derivative with respect to W how will I do that so I have this function uh here and I know how to do this right so I can this is the formula I just computed this on the previous slide f of x minus y into f of x into 1 minus f of x into X right and what is my X here I am looking at the first point here so my X is going to be 0.5 so I can just substitute that here and what is my f of x let's see what f of x is so this is how I'll compute f of x right so f of x is I'll just substitute the value of x in this formula and I'll just substitute the current values of w and B right which are 2. so I can compute this and I'll get some real number and that is what I'll put here right so now I can compute that quantity similarly I can compute the grad of the partial derivative with respect to B again I have a function written for that and the same idea that I want to compute this f of x which I'll compute from this function here by substituting the current values of w b and X that I am dealing with right okay so far so good let me just erase it okay and then I'm going to sum this over all the points right because I visited the first point which was x equal to 0.5 and Y is equal to 2.5 then the loop will go to the second point this Loop will go over all points and I'm just collecting all the uh I'm just adding up all the derivatives because as I said the this derivative of a sum is just the sum of the derivatives right once I've computed the derivatives I'm just going to apply the gradient descent formula which is W is equal to W minus ETA into W did the DW and B is equal to B minus ETA into d w DB right so this is I'll just keep doing this in the loop and I'll keep moving along the error surface so this is what my error surface is so I have this is what my error surface looks like and how have I plotted the error surface I have plotted it using something like this right so uh yeah so this is how I plotted for all possible values of w comma B actually I've just computed the error and then I have plotted it right so don't worry too much about what is happening here this is just a formula for computing the loss function which is f of x minus y the whole square right so I've just computed that and I've plotted this uh so now if I just keep changing the values of w and B as shown in this algorithm following the gradient recent rule then no matter where I start from I start moving in a principled way and at every point the loss will just keep decreasing and I'll reach the minimum that is what is going to happen and now let me try to see if I can demonstrate that right I'm just going to go here okay okay so this is what my loss function looks like this is actually the same as the loss on the previous slide just scaled a bit differently and what I know is that I want to reach somewhere here because in this surface it's clear that the error is minimum there but right now I am way far I want to reach somewhere here but I am very far my initialization was randomly done right so now what I'm going to do is I'm going to run this algorithm and you just observe how the things change both on the loss surface you should see that the loss at every step should keep decreasing and the W should keep W comma B the point on the yeah on the W comma B plane right so this here is the W comma B plane so the W comma B plane I should keep moving till I reach this nice optimal value here at which the loss is minimum okay so let's see if I can run this so the algorithm is running it's initially quite slow you can see that the yellow dots are moving right it's slowly slowly moving it has finished some 27 iterations it's the loss is still a bit high it's 0.81 as you can see here and it's still running running running but it seems to be going in the right direction at no point am I seeing that the loss is increasing and it keeps going I'll Just Fall Down good the loss has decreased quite a bit and I'm very happy that I'm moving in the right direction again it has slowed down a bit why is it slowing down in certain regions why is it not going fast in other regions is something that we'll figure out but now it has started moving and you can see that the loss is around 0.02 I just run it for 100 iterations I've stopped it now I could keep running it a bit more of the side set to 200 so let me just make it 500 and I can keep running this you can again experiment with this at your own Leisure right so now you can see that it's moving further and it'll keep going patiently it'll keep going but it'll go in the right direction right I'm not worried that it will eventually lease the loss function right even 500 iterations does not seem to be enough in this case uh but if I just land it for a thousand two thousand iterations then it will reach there right but the key thing that you need to at least be happy about right now is that unlike a random gas guess algorithm here you are not making a mistake at any point at every time step your loss is definitely decrease right so that's that's what is happening here so this is a demonstration of the gradient descent algorithm on the toy example that we had using the code that I had on the previous slide which was in turn based on the gradient descent update right um so later on in this course we look at gradient descent in much more detail and we look at a lot of its variance right so for now it suffices to know that we have an algorithm for learning the parameters of a sigma material and I've just shown you the algorithm I have shown you the Mac behind it I have shown you the visual interpretation of that and I've also shown you how to code it and then run it so that you move on the loss function in a principle way right so I'll uh end this video here before just telling you quickly where do we head from here right so now the next thing to do we have done this completed this cycle that we introduced sigmoid neuron just as we had introduced perceptron then we introduce the learning algorithm just as we had introduced The perceptron Learning algorithm then we discussed the error and we ran the algorithms in both cases in perceptron as well as in the sigmoid neuron and we saw that the learning algorithm actually learns well and it keeps moving in the right direction so all of that we have seen then in the perceptron case we had moved on to the representation of the power of the perceptron perceptron and now we want to talk about the representation power of the sigmoid neuron right so that's what we are going to do uh next so I'll end this video here and in the next class we'll continue with the representation power of Sig Point here