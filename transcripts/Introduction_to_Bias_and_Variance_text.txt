foreign [Music] so welcome to lecture six of the course and in this lecture we'll be talking about regularization right and different types of regularization ah which includes L2 regulation early topic and a bunch of other things but before I talk about the types of regularization that you use in the context of deep learning of course some of them are also in the context of machine learning I'll first tell you give you intuition for why we need regularization and that's where we'll focus on the discussion on the bias various trade-off right so that's where we'll start we'll make a case for regularization understand what regularization is and then look at different types of regularization okay so here are some acknowledgments I have referred to several sources for preparing the this lecture this includes a deep learning book Ali goat sees video lectures and regularization in the context of deep learning then this paper on dropout right so all of these I have referred to so let's first look at what the problem is right so so far we have focused on minimizing the objective function using a variety of optimization algorithms right so we had this loss function and all our Focus was to how to minimize this loss how to minimize it faster how to make sure that we don't overshoot uh the Minima and land in the right Minima and so on that's what all our Focus has been on right but now the issue is that uh deep learning models uh typically have billions of parameters right I wouldn't say typically have billions but I would say typically have like hundreds of millions of parameters and the training data may have only a few millions of samples right so the main point here instead of focusing on billions and millions is that deep learning models are often over parameterized right that means they have a large number of parameters which are often more than the training points that you have right and in such over parameterized models it's a well-known uh fact right that they are prone to overfitting right this is true for machine learning that you have a large number of parameters and only a few points then you can easily over fit on the training data that means you can drive the training error to zero uh for all the training points right now that may be good but what happens is and that's what we will see in the bias variance trade-off is that if you try to overfit the data on the training data right so you're trying to kind of memorize everything that you see in the training data then you may not be able to generalize well on the test data because that is unknown data so you have focused so much on uh they fixated so much on what was given to you that you are now not going to be able to generalize on some unknown data right and we will see all of this in detail in this lecture and that's where the concept of bias and variance comes in and its relation to the capacity of the model and what I'm trying to say on this slide and which you all know is that deep learning models have a very high capacity because they have a large number of parameters okay so that was the context and with that context I'll start the discussion on bias and variance so let's look at this right so we look at an example where uh we want to fit a curve right so what do I mean by that right so I have been given some data points the data points have actually come from the sinusoidal function that means I know what the true f of x is in this case right so I have X and my true relation between X and Y which is given by f of x for a change for once in my life I know what that is that is the sinusoidal function because I've actually picked up the data points from there I know this right but I am going to assume that I do not know this I have just been given some points and now I'm going to try to fit a model to this points what does that mean that now I am going to do the following I'm trying to going to come up with an approximation of what the relation is I'll completely ignore the fact that I actually know what the true relationship is because in real world I wouldn't know this right just for illustration I have taken points from sinusoidal functions so that's it's easy for me to illustrate what the true function is and how good or bad my approximation is right so now in a typical deep learning machine learning setup I am going to talk about different approximations right so I will take one very simple approximation and then one slightly complex approximation and then I'll try to make some comments based on the approximations that I have made right so let's ah see how that goes okay yeah so we consider two models so one is a simple model as I said degree one model where I assume that Y is related to X using a linear function right so I just assumed that Y is equal to MX plus C or Y is equal to W and X plus W naught right so I have only two parameters here clearly not an over parameterized model and the relationship that I have assumed is very simple the other I am going to assume is a slightly complex model which is a degree 25 ah polynomial right so what does that mean that ah I am saying that my ah Y is related to X by the following relationship W 25 x raised to 25 plus W 24 x raised to 24 all the way up to WX then W naught right ah so w One X plus W naught right so clearly I have 26 parameters here and my function is also not linear it's a polynomial so this is clearly a complex function at least in relation to the ah first function where I have just assumed a linear relationship so here I have only two parameters here I have 26 parameters so I clearly have more capacity here as compared to the simple model right and if I take this to the extreme if I had approximated this relationship by a deep learning model extremely deep 10 layer deep model with many neurons per layer then I would have had that many more parameters but I am not going there I am just going to stop at this level of complexity where I have some 26 parameters and a degree 25 polynomial as an approximation of the relationship right so this is what my approximation of the relationship between ah F and also between X and Y is right this is what my f hat of X is okay ah ok now in both cases we are making assumption right we have no idea about a true relationship again of course in this case I know other two relationship is but if you had given me this problem I wouldn't know so I would have just assumed something so in both cases we are making an approximation ah now ah the training data that is given to me it contains some 500 points right so I have been given some 500 x comma y pairs which I have been given some 500 of these X comma y Pairs and using these I have my job is to learn W1 W naught or these 26 parameters depending on which model I am going to choose right so that's the setup so now we are going to uh sample sum actually not 500 I think it should have been 100 points or here so I was maybe given okay let's assume a bit differently let's assume that I was given some 500 points and I'm going to sample randomly pick up some 400 or 300 points from this and train a simple and a complex Point model I am going to repeat this process K times what does that mean that this is what I mean by that right so in this model let us try to understand what my full procedure looks like right so I have my loss as I equal to 1 to M where as m is the number of training points and in this case I am going to Define my loss as y i which is a true y that was given to me minus F hat of x i which is my function that I have chosen right and the parameters here are all the W's that I have right it's either so this is a minimization problem with respect to the W's so the W's are either W 1 and W naught or they are W 25 all the way up to W 29 right and this you know now how to solve this or how to ah find this Minima using the gradient descent or any of the variance of the gradient descent algorithm right now let us consider the simple model which was W 1 x 1 plus W naught right so at the end of training suppose I I took some ah 400 points and I do just do not want to take all the 500 points because then I cannot repeat this process K times right because if I have the same 500 points and I repeat the process K times then I am going to get very similar Solutions so I am just going to take a different random sample right so I have 500 points total and I'm just going to take some random 400 points from there and try to solve this optimization problem one which will result in some W one and W naught then again I will take a separate 400 points again try to solve this optimization problem and I might get a different W one and W naught right so that is the idea that's why I am not taking the entire training data but just taking like a a significantly large sample of it but in every each of these K times and I'm going to try to solve this optimization problem my m points are going to be different and hence the solution that I lend up for W1 and W naught would be slightly different right so that is the idea that's what I am trying to do here right and now let us look at one of these right so the first time I took the 400 points and solved this using gradient descent or any of the other optimization algorithms then I have come up with this equation that Y is equal to W 1 x 1 plus W naught and I could plot that equation right so the blue line that I have here that is for a given value of w 1 and W 9 8 so that is the same as MX plus C so I have the x axis I have the X and I have the y axis and I have just drawn the line which is given by this our equation right and now if I repeat it K times every time I will get a different line and I will keep drawing all those K lines right so that's what I am going to show you in the animation here so every time a new line let's just see what happens here oops um okay so this is okay I'll come back to this animation later let's see yeah so this is what happens so this is what I'm going to do now right so this optimization problem I am going to solve for the simple model which is y equal to W 1 x 1 plus W naught and I am going to do that a k number of times right and every time I solve that optimization problem I get a slightly different value of w and W naught and I will keep plotting those lines okay so I am plotting all those different lines which I get right and here iteration you can think of iteration not as the iteration in the case of gradient descent but this is the kth so now I have repeated the experiment 25 times 27 times 28 times 29 times 30 times right so I have repeated the experiment a total of 30 times from 0 to 29 and every time I got certain value of w 1 and W naught and I just plotted those ah values right I just plotted those lines okay similarly I can do the same thing I can solve the same equation or I can try to find this minimum except that now my F at X I is going to be that degree 25 polynomial which I show right so that does not change anything I'll just have the gradient computed accordingly and I could still use the gradient descent based algorithms to find the W's right so now I need to find 26 different values and once I find the values I can plug in those values in this equation and then for every value of x on the x axis I can find what F hat would be and I can plot that right and now again this I am going to repeat some 30 different times each time I am going to take a different 400 samples from the training data right a different sample of size 400 from the training data and I am just going to plot that curve right so let's see what that curve looks like so every time you can see I am getting a different curve right you can see all the different curves that I am getting here okay I am done now right so you understood the procedure now let's try to make some observations from these plots so simple methods trained on different samples of the data do not differ from each other right so I had a total of 500 training points given to me and I took different random samples of 400 multiple times I took a different sample of 400 and each of these lines corresponds to one of those sample training data sets and I found the values of w and W naught and plotted this and you can see that all these lines are very close to each other right they are not really giving me different solutions right but the same thing when I do with the complex function you can see that all of these are quite different right so you have something which is going like this you have something which is going like this you have something which is going like this and so on right so all these functions which I am getting and these functions are plotted by ah substituting values for the following equation right so whatever I solve whatever Minima I get that will give me the value of the parameters I just plug in those parameters and plot it and every time I use a different sample of 400 my my uh the the the function which I get is different right it's quite all these I'm getting a lot of variety here a lot of variance here as opposed to in the simple model right so that's the observation that we are making so simple models do not differ from each other but they are far from the true sinusoidal curve right they should have been very close to the red curve but I mean the moment I chose a simple model I was just going to get a line right and my actual function happened to be a sinusoidal curve so I know that my model is going to be very bad no matter how well I try to fit it it's just trying to pass it like through the center if you are I mean some sort of ah pass it through the average uh it's getting some sort of a line which is kind of balancing the positive and negative points right so that's all I would get right and it's very far off from the ah True Value so what do I mean that mean by that is that suppose I substitute the value of x here right then my my predicted value is this whereas my true value is this right and there is a clear gap between the predicted and the True Value this is happening for the simple models but for the complex models while there is a huge variance in them you can see that on average the gap between the True Value and the predicted value is much smaller if you look at on average across the entire x axis then if you plug in different values of X and if you have to compute the error for all the values of X it's much smaller here as compared to the simple model that's visually clear right I mean the complex model is at least able to give me a sinusoidal shape whereas the simple model was not even able to do that right okay so these are just observations that you are making and then we will try to formalize these observations right yeah so simple models very close to each other not much variance between them complex models they're far from each other that means there's High variance but simple models tend to underfit they are not even able to give me a zero error on the training data itself whereas complex models are able to overfit they are giving me close to zero error on the training data at least some of them on average are giving me close to zero error on the training data right so this is what is happening now so now what I have drawn here I have the red curve which is my true sinusoidal function then the green curve that you see that is the that is the average value of x hat for the simple model so what do I mean by that what do I mean by that so I have computed 25 different models right I have each of these models now I plug in a value of x into each of these models okay and I get y's from each of these models right now I take the average value of that Y and I plot it so if I plug in x equal to 0 I compute ah sorry there were 30 models not 25 right so I compute ah F hat of x from all the 30 models and then take the average and plot it similarly I plug in the value as 0.1 pass it through all the 30 value or 30 models I substitute x equal to 0.1 I get 30 different y's I take the average of that and I plot it right so what I am plotting here is the average value of f hat X of the simple for the 30 simple models similarly the blue curve is the average value of f hat X for the complex model right so ah this is the what what I am trying to do here is the average value and you know that the average I can also call it as the expected value right so the mean is the same as the expected value so that is what I am drawing here empirically right I'm just trying to draw the expected value for the green curve as well as the for the simple model which is the green line and for the complex model which is the blue curve right and now I can define a quantity called bias which is the difference between the average value and the True Value right so it's for the simple model its difference between the Green curve or the green line and the red curve right and how do I compute that difference I can just compute it by summing it up over all the points right so for every Point Let's assume you just have 100 points on this axis then for all the hundred points I can compute what the average value is going to be right that is the green value minus the red value and the square of that right so that is what my ah average error is going to be but what I am defining as the bias is that whatever is the average value right that divided by sorry that minus the True Value right so that's what the bias is so the bias is defined as the expected value of the prediction minus the True Value that you would have had right so that's what the bias is so in simple terms this quantity here is the green ah value and this is the red value right so that is what you are defining as the ah expected uh as the bias okay now what is clear is that for the simple model the average value is very far from the True Value that means the bias is going to be very high for a simple model ah whereas for the complex model the bias is going to be low because the average value which is the blue curve is very close to the red curve right so bias is the difference between the average value or the expected value of the model ah so why is there an expectation here because where is the randomness coming from you are taking different random samples of the training data right so you might get if I give you one lakh samples for training I I might just have gotten this random sample from somewhere and giving it to you right so I might be able to depending on what random sample of the training data I have given you you would get different uh F hat X which means you will get different values for the parameters so across all these different ah values of the parameters if I take the expected value and then try to find the difference from the True Value then that's what the bias is and you can see that the green curve is ah much farther from the red curve so the bias is high whereas the blue curve is closer to the red curve so the bias is low right so informally we are seeing that simple models have a high bias and complex models have a low bias right so let us continue with the discussion and now we will Define one more quantity which is the variance right and variance is something that I think most of you know so variance is just the expectation of the of how far is a given value away from the expected value right so what does that mean so you have this ah suppose you take any one blue line from here and then you had that green line or the green curve which was the average right maybe I should have used the right colors let me just use the right colors yeah so suppose I take any one of these blue lines from here and then I had the green curve which was the average right and it looks something like this then ah for every blue line I can find the difference from the green line right that is what I am trying to do and I can take the square of that difference and then I can do this for all the blue lines that I had and that's where the expectation is coming from so that's the variance right so it's the difference between uh the predicted value minus sorry it's the difference between the given model and the expected value of the model the square of that difference and the expectation of that right so this is very similar to I mean this is the definition of variance that you know from statistic right so you could look at it as suppose a fat of X you can think of it as a random variable Z then this is essentially expected value of Z minus expected value of Z the whole Square and this is essentially the definition of variance so all you have is here the Z is the F hat X which is a random variable because it is random depending on the training samples that you have you will get different blue lines and hence there is a Randomness there right so this is the standard definition nothing much to say here but this is what the bias looks like now what do we off uh see that all the blue lines are actually very close to the ah green line right which was there on the previous slide that means they are not very far away from the average and hence the variance is going to be small for the simple models right whereas for the complex models you can see that some of the blue lines are actually very far off from the average that we had right so the blue curve sorry not the blue lines so the here you have quite a bit of variance that you have right you can see that visually so you for the same input X there's a quite a bit of difference between the predicted value based on the different models that you have trained right there's quite a bit of gaps one model is predicting the value here the other model is predicting a value here similarly here if you look at for this point one model is predicting the value here there's another model which is predicting value here so there is quite a bit of variance in the values that are you are obtaining for f hat of X right and hence the variance so for the complex models the variance is going to be high right so that's that's what we have observed so in summary informally what have we observed that simple models have high bias low variance complex models have low bias High variance and now there is always a trade-off between the bias and the variance right so now I can't say that let's always choose a complex model because I know that if I choose a complex model I'll have a low bias right which means I'll be able to overfit the training data but I also have a high variance that means that depending on the training data that I had gone my models would be quite different from each other and that's not what I want right because if my models depending on the training data that I've got if my models are largely different from each other then I don't know how they'll perform on a test data so let's let's look at what I mean by that right so suppose my model has a very high variance so this is one training data this was the other training data right and I predicted some f hat of X using this training data or estimated some effect of X and now again using this if these two are very different from each other right so now let us assume this was the actual training data given to me then this is what my model would have been right but now if I get a test instance which belongs here then this model will do a bad job on that right because if I had been given this as the training data then my F at X would have been quite different which means the current F at X would not have been very similar to this F hat X and that means if I had a test instance from here this model would perform very bad right whereas if my model has a low variance then irrespective of what training data I have all my f hat X's would be very close to each other so now if I had used this as a training data and then my test data comes from any of these other remaining data then I do not have a problem because my f hat X would have been similar right but at the same time it should not be the case that this low variance is coming with high bias because if there is high bias then I know that all my f hat X's would be close to each other but then they will be far away from the true function which is again useless to me right so there has to be this balance that you want like you want a low bias by the same time you don't want a high variance or you do other way of looking at it is that you want low variance but at the same time you don't want a high bias in the model right so you want like reasonable variance reasonable bias so that your different models are not far off from each other at the same time your model is not far off from the true uh function that you have it so that's why this trade-off is there that you want medium variance and medium bias right and turns out ah that both bias and variants actually contribute to the mean square error right so let's see what the mean square error is of course we have seen it a million times but let us see again in the context of bias and variance right so I'll end this video here and then we'll talk about uh mean square error in the next video