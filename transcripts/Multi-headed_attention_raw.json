[
  {
    "text": "foreign",
    "start": 0.299,
    "duration": 3.0
  },
  {
    "text": "[Music]",
    "start": 6.6,
    "duration": 14.41
  },
  {
    "text": "block within the Transformer",
    "start": 24.74,
    "duration": 6.939
  },
  {
    "text": "architecture and we saw that the entire",
    "start": 27.48,
    "duration": 7.68
  },
  {
    "text": "self-attention can be done in parallel",
    "start": 31.679,
    "duration": 6.201
  },
  {
    "text": "for all the capital T tokens",
    "start": 35.16,
    "duration": 5.76
  },
  {
    "text": "and it all happens to these Matrix",
    "start": 37.88,
    "duration": 5.019
  },
  {
    "text": "multiplications right so in effect what",
    "start": 40.92,
    "duration": 4.26
  },
  {
    "text": "is happening is the following right so",
    "start": 42.899,
    "duration": 4.801
  },
  {
    "text": "this is what is known as a scaled dot",
    "start": 45.18,
    "duration": 4.14
  },
  {
    "text": "product self-attention and this is",
    "start": 47.7,
    "duration": 3.72
  },
  {
    "text": "called one head and soon we'll see",
    "start": 49.32,
    "duration": 4.259
  },
  {
    "text": "multiple such heads but we'll get there",
    "start": 51.42,
    "duration": 3.54
  },
  {
    "text": "when we get there but for now just",
    "start": 53.579,
    "duration": 4.081
  },
  {
    "text": "remember this is called cell scaled dot",
    "start": 54.96,
    "duration": 5.04
  },
  {
    "text": "product based self attention so what",
    "start": 57.66,
    "duration": 6.48
  },
  {
    "text": "exactly is happening here uh so this",
    "start": 60.0,
    "duration": 8.76
  },
  {
    "text": "so this purple box here right",
    "start": 64.14,
    "duration": 6.36
  },
  {
    "text": "this is",
    "start": 68.76,
    "duration": 4.08
  },
  {
    "text": "a scale dot product unit right so this",
    "start": 70.5,
    "duration": 4.32
  },
  {
    "text": "is what is lying inside this purple",
    "start": 72.84,
    "duration": 4.5
  },
  {
    "text": "block Here and Now what is the input to",
    "start": 74.82,
    "duration": 6.78
  },
  {
    "text": "the Box let's see uh so you get the key",
    "start": 77.34,
    "duration": 6.779
  },
  {
    "text": "uh query and the value matrices how are",
    "start": 81.6,
    "duration": 4.62
  },
  {
    "text": "these constructed originally remember at",
    "start": 84.119,
    "duration": 5.521
  },
  {
    "text": "the input all you had were these H1 to",
    "start": 86.22,
    "duration": 5.64
  },
  {
    "text": "HT right so you had these word",
    "start": 89.64,
    "duration": 5.159
  },
  {
    "text": "representations for the keywords and we",
    "start": 91.86,
    "duration": 5.399
  },
  {
    "text": "were calling them as H1 H2 and so on",
    "start": 94.799,
    "duration": 5.881
  },
  {
    "text": "right now from the H1 H2 what happens uh",
    "start": 97.259,
    "duration": 5.701
  },
  {
    "text": "you pass them through the linear",
    "start": 100.68,
    "duration": 5.52
  },
  {
    "text": "projection right through the WQ W K and",
    "start": 102.96,
    "duration": 6.06
  },
  {
    "text": "W V matrices to get the Q K and V",
    "start": 106.2,
    "duration": 4.279
  },
  {
    "text": "matrices right so this is just",
    "start": 109.02,
    "duration": 6.0
  },
  {
    "text": "multiplying WQ by these vectors and you",
    "start": 110.479,
    "duration": 6.161
  },
  {
    "text": "just stack up these vectors into a",
    "start": 115.02,
    "duration": 4.02
  },
  {
    "text": "matrix so that you can use this 2W key",
    "start": 116.64,
    "duration": 4.68
  },
  {
    "text": "multiplied by that H Matrix right let's",
    "start": 119.04,
    "duration": 4.56
  },
  {
    "text": "just call it h then you get the Q Matrix",
    "start": 121.32,
    "duration": 4.439
  },
  {
    "text": "similarly w k multiplied by this gives",
    "start": 123.6,
    "duration": 5.1
  },
  {
    "text": "you the K Matrix and WV multiplied by",
    "start": 125.759,
    "duration": 4.741
  },
  {
    "text": "this gives you the V Matrix right all of",
    "start": 128.7,
    "duration": 4.02
  },
  {
    "text": "this happening in parallel as uh three",
    "start": 130.5,
    "duration": 4.26
  },
  {
    "text": "Matrix operations then you get the qkv",
    "start": 132.72,
    "duration": 4.94
  },
  {
    "text": "and then this is what happens inside the",
    "start": 134.76,
    "duration": 5.94
  },
  {
    "text": "self-attention head and at the output",
    "start": 137.66,
    "duration": 8.56
  },
  {
    "text": "what do you get you get a Z1 you get Z1",
    "start": 140.7,
    "duration": 7.14
  },
  {
    "text": "Z2",
    "start": 146.22,
    "duration": 4.379
  },
  {
    "text": "all the way up to ZT right so this is",
    "start": 147.84,
    "duration": 5.22
  },
  {
    "text": "what we had seen uh when we ended the",
    "start": 150.599,
    "duration": 3.661
  },
  {
    "text": "last lecture",
    "start": 153.06,
    "duration": 4.44
  },
  {
    "text": "now this is called one head so what what",
    "start": 154.26,
    "duration": 6.6
  },
  {
    "text": "I mean by a head here so this is a one",
    "start": 157.5,
    "duration": 5.879
  },
  {
    "text": "such unit which takes the inputs H1 to",
    "start": 160.86,
    "duration": 6.239
  },
  {
    "text": "H2 and gives you the elements Z1 to Z2",
    "start": 163.379,
    "duration": 5.701
  },
  {
    "text": "right or the refined representation Z1",
    "start": 167.099,
    "duration": 4.441
  },
  {
    "text": "to ZT which also take care of the",
    "start": 169.08,
    "duration": 4.5
  },
  {
    "text": "contextual information because they",
    "start": 171.54,
    "duration": 3.54
  },
  {
    "text": "depend on the key they depend on the",
    "start": 173.58,
    "duration": 3.36
  },
  {
    "text": "value and they depend on the query right",
    "start": 175.08,
    "duration": 3.42
  },
  {
    "text": "so they take care of the contextual",
    "start": 176.94,
    "duration": 2.579
  },
  {
    "text": "information",
    "start": 178.5,
    "duration": 3.48
  },
  {
    "text": "now you could have one more such block",
    "start": 179.519,
    "duration": 4.141
  },
  {
    "text": "right so you could have the same block",
    "start": 181.98,
    "duration": 4.22
  },
  {
    "text": "repeated so let me just call this",
    "start": 183.66,
    "duration": 6.12
  },
  {
    "text": "z11z21 and z uh one t right so this is",
    "start": 186.2,
    "duration": 5.98
  },
  {
    "text": "the output of the first attention head",
    "start": 189.78,
    "duration": 3.959
  },
  {
    "text": "similarly you could have the same block",
    "start": 192.18,
    "duration": 3.839
  },
  {
    "text": "repeated where you have another set of",
    "start": 193.739,
    "duration": 3.541
  },
  {
    "text": "parameters right so let me just call",
    "start": 196.019,
    "duration": 3.961
  },
  {
    "text": "these uh W1 right these are the first",
    "start": 197.28,
    "duration": 5.099
  },
  {
    "text": "set of eight matrices you have similarly",
    "start": 199.98,
    "duration": 4.14
  },
  {
    "text": "you could have another's repeated block",
    "start": 202.379,
    "duration": 3.181
  },
  {
    "text": "right and let me just show it on the",
    "start": 204.12,
    "duration": 2.46
  },
  {
    "text": "next slide",
    "start": 205.56,
    "duration": 3.0
  },
  {
    "text": "we just repeat these two blocks right",
    "start": 206.58,
    "duration": 4.739
  },
  {
    "text": "and now you have head one head two and",
    "start": 208.56,
    "duration": 5.36
  },
  {
    "text": "head one is giving you representations",
    "start": 211.319,
    "duration": 5.28
  },
  {
    "text": "Z1 and this is giving you",
    "start": 213.92,
    "duration": 6.399
  },
  {
    "text": "representations Z2 Now by several",
    "start": 216.599,
    "duration": 4.92
  },
  {
    "text": "questions here right why would you have",
    "start": 220.319,
    "duration": 2.761
  },
  {
    "text": "two heads and then if you are getting",
    "start": 221.519,
    "duration": 3.72
  },
  {
    "text": "these two representations which one do",
    "start": 223.08,
    "duration": 3.48
  },
  {
    "text": "you consider right so we'll answer those",
    "start": 225.239,
    "duration": 3.661
  },
  {
    "text": "two questions but first let us motivate",
    "start": 226.56,
    "duration": 4.319
  },
  {
    "text": "right why would you need multiple heads",
    "start": 228.9,
    "duration": 4.08
  },
  {
    "text": "and we have already seen this in a",
    "start": 230.879,
    "duration": 3.661
  },
  {
    "text": "different context before right so we",
    "start": 232.98,
    "duration": 4.679
  },
  {
    "text": "want to motivate multi multiple heads in",
    "start": 234.54,
    "duration": 6.66
  },
  {
    "text": "attention right so one head is uh one uh",
    "start": 237.659,
    "duration": 6.901
  },
  {
    "text": "one one scale dot product unit which",
    "start": 241.2,
    "duration": 5.16
  },
  {
    "text": "gives you Z one to Z T right the",
    "start": 244.56,
    "duration": 3.539
  },
  {
    "text": "representation Z1 to Z T and I'm making",
    "start": 246.36,
    "duration": 4.079
  },
  {
    "text": "a case for many such heads and so why",
    "start": 248.099,
    "duration": 3.901
  },
  {
    "text": "why is why am I doing this right so",
    "start": 250.439,
    "duration": 3.121
  },
  {
    "text": "we've already seen this in the context",
    "start": 252.0,
    "duration": 3.659
  },
  {
    "text": "of convolutional neural networks right",
    "start": 253.56,
    "duration": 4.919
  },
  {
    "text": "so where we had multiple filters right",
    "start": 255.659,
    "duration": 5.461
  },
  {
    "text": "so these are three different filters uh",
    "start": 258.479,
    "duration": 4.921
  },
  {
    "text": "operating on the same image right and",
    "start": 261.12,
    "duration": 3.6
  },
  {
    "text": "each filter essentially does the same",
    "start": 263.4,
    "duration": 5.579
  },
  {
    "text": "thing it has parameters say W1 W2 W3 it",
    "start": 264.72,
    "duration": 5.699
  },
  {
    "text": "just goes over the image and gives you",
    "start": 268.979,
    "duration": 3.601
  },
  {
    "text": "an output feature map right and the",
    "start": 270.419,
    "duration": 4.021
  },
  {
    "text": "reason we wanted to capture have",
    "start": 272.58,
    "duration": 3.6
  },
  {
    "text": "multiple filters is that we were hoping",
    "start": 274.44,
    "duration": 4.259
  },
  {
    "text": "that each filter May capture a different",
    "start": 276.18,
    "duration": 4.079
  },
  {
    "text": "characteristic from the image right some",
    "start": 278.699,
    "duration": 3.361
  },
  {
    "text": "may detect edges some may detect blurs",
    "start": 280.259,
    "duration": 3.961
  },
  {
    "text": "and so on right so that's why you had",
    "start": 282.06,
    "duration": 5.22
  },
  {
    "text": "multiple filters right and more the",
    "start": 284.22,
    "duration": 4.62
  },
  {
    "text": "filters the more abstract",
    "start": 287.28,
    "duration": 3.479
  },
  {
    "text": "representations you could compute right",
    "start": 288.84,
    "duration": 4.74
  },
  {
    "text": "the same argument holds here if you have",
    "start": 290.759,
    "duration": 5.041
  },
  {
    "text": "one self attention then it will capture",
    "start": 293.58,
    "duration": 4.98
  },
  {
    "text": "uh we'll learn one way of capturing the",
    "start": 295.8,
    "duration": 4.8
  },
  {
    "text": "contextual information right but there",
    "start": 298.56,
    "duration": 3.66
  },
  {
    "text": "might be more than one way of capturing",
    "start": 300.6,
    "duration": 3.18
  },
  {
    "text": "this contextual information right so you",
    "start": 302.22,
    "duration": 3.84
  },
  {
    "text": "might also want to have a situation",
    "start": 303.78,
    "duration": 5.46
  },
  {
    "text": "where it focuses on animal with a very",
    "start": 306.06,
    "duration": 5.28
  },
  {
    "text": "high attention and you might also want",
    "start": 309.24,
    "duration": 4.08
  },
  {
    "text": "it to focus on some verb with a very",
    "start": 311.34,
    "duration": 3.359
  },
  {
    "text": "high attention right and both of these",
    "start": 313.32,
    "duration": 2.939
  },
  {
    "text": "might be important because one is",
    "start": 314.699,
    "duration": 3.481
  },
  {
    "text": "indicating that it is a pronoun for",
    "start": 316.259,
    "duration": 3.901
  },
  {
    "text": "animal and the other might be indicating",
    "start": 318.18,
    "duration": 4.26
  },
  {
    "text": "that it is the object of this verb right",
    "start": 320.16,
    "duration": 4.259
  },
  {
    "text": "and so in both both of these you might",
    "start": 322.44,
    "duration": 3.78
  },
  {
    "text": "want to capture so one head could learn",
    "start": 324.419,
    "duration": 3.961
  },
  {
    "text": "to give more attention to animal the",
    "start": 326.22,
    "duration": 3.66
  },
  {
    "text": "other I had could learn to give more",
    "start": 328.38,
    "duration": 3.24
  },
  {
    "text": "attention to this war right so just as",
    "start": 329.88,
    "duration": 4.14
  },
  {
    "text": "you had multiple free filters to capture",
    "start": 331.62,
    "duration": 4.2
  },
  {
    "text": "multiple characteristics from the image",
    "start": 334.02,
    "duration": 3.54
  },
  {
    "text": "you could have this multiple attention",
    "start": 335.82,
    "duration": 3.599
  },
  {
    "text": "headset and let's let's look at it a bit",
    "start": 337.56,
    "duration": 4.02
  },
  {
    "text": "more carefully right so here's an",
    "start": 339.419,
    "duration": 4.56
  },
  {
    "text": "example so the animal didn't cross the",
    "start": 341.58,
    "duration": 4.86
  },
  {
    "text": "street because it was too tired right",
    "start": 343.979,
    "duration": 4.981
  },
  {
    "text": "and I have the same copy of the",
    "start": 346.44,
    "duration": 4.74
  },
  {
    "text": "sentence here and now I'm trying to",
    "start": 348.96,
    "duration": 4.019
  },
  {
    "text": "learn a contextual representation for it",
    "start": 351.18,
    "duration": 4.92
  },
  {
    "text": "and now I want to focus more on walks",
    "start": 352.979,
    "duration": 5.761
  },
  {
    "text": "right because I want to know was what is",
    "start": 356.1,
    "duration": 4.439
  },
  {
    "text": "the subject of it right so it is the",
    "start": 358.74,
    "duration": 4.2
  },
  {
    "text": "subject here so I want to know that so I",
    "start": 360.539,
    "duration": 4.081
  },
  {
    "text": "want to capture that information by",
    "start": 362.94,
    "duration": 4.62
  },
  {
    "text": "paying more attention to Vos right but I",
    "start": 364.62,
    "duration": 5.82
  },
  {
    "text": "also earlier made a case",
    "start": 367.56,
    "duration": 4.859
  },
  {
    "text": "so what does that mean if I'm learning",
    "start": 370.44,
    "duration": 4.08
  },
  {
    "text": "the alphas right so if I'm learning say",
    "start": 372.419,
    "duration": 4.321
  },
  {
    "text": "let's this is one two three four five",
    "start": 374.52,
    "duration": 4.08
  },
  {
    "text": "six seven eight nine ten this is the",
    "start": 376.74,
    "duration": 4.08
  },
  {
    "text": "tenth word so if I'm learning Alpha 10",
    "start": 378.6,
    "duration": 6.659
  },
  {
    "text": "then this is Alpha 10 1 Alpha 10 2",
    "start": 380.82,
    "duration": 6.84
  },
  {
    "text": "right and this is Alpha 10",
    "start": 385.259,
    "duration": 5.121
  },
  {
    "text": "11 right so this is the uh attention",
    "start": 387.66,
    "duration": 5.34
  },
  {
    "text": "that should be paid on the 11th word",
    "start": 390.38,
    "duration": 4.84
  },
  {
    "text": "when you are Computing a refined",
    "start": 393.0,
    "duration": 4.139
  },
  {
    "text": "representation for the tenth word right",
    "start": 395.22,
    "duration": 4.62
  },
  {
    "text": "and I want this to be high right but I",
    "start": 397.139,
    "duration": 5.041
  },
  {
    "text": "had also earlier made the case that I",
    "start": 399.84,
    "duration": 4.139
  },
  {
    "text": "want the attention on animal to be high",
    "start": 402.18,
    "duration": 5.579
  },
  {
    "text": "because animal is the uh I mean it is",
    "start": 403.979,
    "duration": 5.821
  },
  {
    "text": "referring animal animal is the word for",
    "start": 407.759,
    "duration": 3.841
  },
  {
    "text": "which it is the pronoun in this case",
    "start": 409.8,
    "duration": 4.019
  },
  {
    "text": "right so that means if I were to compute",
    "start": 411.6,
    "duration": 6.84
  },
  {
    "text": "again the weights Alpha 10",
    "start": 413.819,
    "duration": 7.021
  },
  {
    "text": "and so on then I want this to be high so",
    "start": 418.44,
    "duration": 4.14
  },
  {
    "text": "I also have a case for this to be high I",
    "start": 420.84,
    "duration": 3.72
  },
  {
    "text": "also have a case for this to be high so",
    "start": 422.58,
    "duration": 3.42
  },
  {
    "text": "one way of dealing with this would we",
    "start": 424.56,
    "duration": 4.079
  },
  {
    "text": "have two separate attention heads right",
    "start": 426.0,
    "duration": 5.34
  },
  {
    "text": "and compute two Alphas one from one",
    "start": 428.639,
    "duration": 4.56
  },
  {
    "text": "block of self attention another from the",
    "start": 431.34,
    "duration": 3.9
  },
  {
    "text": "other block of self attention and this",
    "start": 433.199,
    "duration": 3.541
  },
  {
    "text": "block could learn to give more",
    "start": 435.24,
    "duration": 3.959
  },
  {
    "text": "importance to this Alpha and the other",
    "start": 436.74,
    "duration": 3.72
  },
  {
    "text": "block could learn to give more",
    "start": 439.199,
    "duration": 3.481
  },
  {
    "text": "importance to this Alpha right now of",
    "start": 440.46,
    "duration": 4.079
  },
  {
    "text": "course this is slightly make believe",
    "start": 442.68,
    "duration": 3.359
  },
  {
    "text": "right we understand that because we have",
    "start": 444.539,
    "duration": 2.821
  },
  {
    "text": "already visited this in the case of",
    "start": 446.039,
    "duration": 3.541
  },
  {
    "text": "recurrent neural networks now there is",
    "start": 447.36,
    "duration": 3.959
  },
  {
    "text": "no signal right we are not telling the",
    "start": 449.58,
    "duration": 3.66
  },
  {
    "text": "model that hey you need to pay more",
    "start": 451.319,
    "duration": 3.6
  },
  {
    "text": "attention to was or hey you need to pay",
    "start": 453.24,
    "duration": 3.72
  },
  {
    "text": "more attention to animal we just hope",
    "start": 454.919,
    "duration": 3.72
  },
  {
    "text": "that when we are looking at the final",
    "start": 456.96,
    "duration": 4.2
  },
  {
    "text": "loss function and if it indeed is",
    "start": 458.639,
    "duration": 5.101
  },
  {
    "text": "beneficial to focus more on Wars right",
    "start": 461.16,
    "duration": 4.14
  },
  {
    "text": "that means have a higher weight for",
    "start": 463.74,
    "duration": 5.16
  },
  {
    "text": "Alpha which in turn will contribute uh",
    "start": 465.3,
    "duration": 5.94
  },
  {
    "text": "accordingly when we try to compute the",
    "start": 468.9,
    "duration": 5.82
  },
  {
    "text": "refined representation for say the tenth",
    "start": 471.24,
    "duration": 4.88
  },
  {
    "text": "word right",
    "start": 474.72,
    "duration": 4.8
  },
  {
    "text": "and that effectively reduces the loss so",
    "start": 476.12,
    "duration": 5.079
  },
  {
    "text": "it would then learn to have a higher",
    "start": 479.52,
    "duration": 4.2
  },
  {
    "text": "weight for wash right similarly if it",
    "start": 481.199,
    "duration": 4.28
  },
  {
    "text": "helps so this is z",
    "start": 483.72,
    "duration": 4.56
  },
  {
    "text": "110 similarly if you had Z coming out",
    "start": 485.479,
    "duration": 5.62
  },
  {
    "text": "from the other attention head and this",
    "start": 488.28,
    "duration": 4.139
  },
  {
    "text": "will also participate in the fuel",
    "start": 491.099,
    "duration": 3.181
  },
  {
    "text": "computation and then participate in the",
    "start": 492.419,
    "duration": 4.381
  },
  {
    "text": "loss so if it helps that now this set of",
    "start": 494.28,
    "duration": 3.539
  },
  {
    "text": "Alphas",
    "start": 496.8,
    "duration": 3.06
  },
  {
    "text": "should be such that it should focus more",
    "start": 497.819,
    "duration": 4.021
  },
  {
    "text": "on the word animal and if the loss",
    "start": 499.86,
    "duration": 3.54
  },
  {
    "text": "dictates that then the machine would",
    "start": 501.84,
    "duration": 3.359
  },
  {
    "text": "learn that or the model would learn that",
    "start": 503.4,
    "duration": 3.419
  },
  {
    "text": "right so that we're not giving it an",
    "start": 505.199,
    "duration": 3.06
  },
  {
    "text": "explicit signal we're just hoping that",
    "start": 506.819,
    "duration": 3.961
  },
  {
    "text": "by Trying to minimize the loss it has",
    "start": 508.259,
    "duration": 4.441
  },
  {
    "text": "more freedom now in some cases it can",
    "start": 510.78,
    "duration": 3.66
  },
  {
    "text": "learn to put a high alpha here in some",
    "start": 512.7,
    "duration": 3.779
  },
  {
    "text": "cases it can put a learn to put a high",
    "start": 514.44,
    "duration": 3.42
  },
  {
    "text": "alpha here right so you're making a",
    "start": 516.479,
    "duration": 4.141
  },
  {
    "text": "better design Choice by allowing it more",
    "start": 517.86,
    "duration": 6.239
  },
  {
    "text": "uh choices right or allowing it more",
    "start": 520.62,
    "duration": 5.94
  },
  {
    "text": "parameters in terms of the W's the",
    "start": 524.099,
    "duration": 4.081
  },
  {
    "text": "projection matrices which in turn result",
    "start": 526.56,
    "duration": 3.42
  },
  {
    "text": "in different Alphas right so just making",
    "start": 528.18,
    "duration": 5.52
  },
  {
    "text": "it a more flexible model which has more",
    "start": 529.98,
    "duration": 6.78
  },
  {
    "text": "choices or more options to how to adjust",
    "start": 533.7,
    "duration": 4.86
  },
  {
    "text": "the alpha in different cases so it might",
    "start": 536.76,
    "duration": 4.74
  },
  {
    "text": "choose to have Alpha was high for one",
    "start": 538.56,
    "duration": 4.8
  },
  {
    "text": "case Alpha animal high in the other case",
    "start": 541.5,
    "duration": 3.66
  },
  {
    "text": "and then do something different in the",
    "start": 543.36,
    "duration": 3.72
  },
  {
    "text": "third head and so on right so that's the",
    "start": 545.16,
    "duration": 4.92
  },
  {
    "text": "motivation for having multiple heads so",
    "start": 547.08,
    "duration": 4.74
  },
  {
    "text": "I just already explained this I'll just",
    "start": 550.08,
    "duration": 3.48
  },
  {
    "text": "skip over this the same thing whatever I",
    "start": 551.82,
    "duration": 3.66
  },
  {
    "text": "explained that in one case it would want",
    "start": 553.56,
    "duration": 3.66
  },
  {
    "text": "to focus on walls the other case it",
    "start": 555.48,
    "duration": 4.02
  },
  {
    "text": "might want to focus question animal and",
    "start": 557.22,
    "duration": 4.32
  },
  {
    "text": "this is actually from a actual train",
    "start": 559.5,
    "duration": 3.839
  },
  {
    "text": "transformer right so we looked at the",
    "start": 561.54,
    "duration": 3.96
  },
  {
    "text": "attention weights there were two heads",
    "start": 563.339,
    "duration": 3.18
  },
  {
    "text": "and we looked at what the attention",
    "start": 565.5,
    "duration": 2.399
  },
  {
    "text": "weights were and we found that in one",
    "start": 566.519,
    "duration": 3.241
  },
  {
    "text": "case it is giving higher in one of the",
    "start": 567.899,
    "duration": 3.301
  },
  {
    "text": "heads that is giving higher attention to",
    "start": 569.76,
    "duration": 2.759
  },
  {
    "text": "animal and the other head it is giving",
    "start": 571.2,
    "duration": 3.48
  },
  {
    "text": "higher attention to Wars right so it",
    "start": 572.519,
    "duration": 4.201
  },
  {
    "text": "does learn to do such things right so",
    "start": 574.68,
    "duration": 3.24
  },
  {
    "text": "this is what a two-headed attention",
    "start": 576.72,
    "duration": 4.04
  },
  {
    "text": "would look like you would have the Q uh",
    "start": 577.92,
    "duration": 5.88
  },
  {
    "text": "query uh sorry you'd have the query key",
    "start": 580.76,
    "duration": 5.98
  },
  {
    "text": "and value vectors right which are coming",
    "start": 583.8,
    "duration": 6.68
  },
  {
    "text": "from your projections",
    "start": 586.74,
    "duration": 3.74
  },
  {
    "text": "say this should have been",
    "start": 592.2,
    "duration": 5.46
  },
  {
    "text": "this is the H Matrix right which is",
    "start": 594.36,
    "duration": 6.659
  },
  {
    "text": "H1 H2 all the way up to h t and you get",
    "start": 597.66,
    "duration": 7.26
  },
  {
    "text": "out here is q k v okay so this is again",
    "start": 601.019,
    "duration": 6.721
  },
  {
    "text": "the H Matrix and what you get out here",
    "start": 604.92,
    "duration": 6.24
  },
  {
    "text": "is q k v right so you just have these",
    "start": 607.74,
    "duration": 5.34
  },
  {
    "text": "two copies now this as I said would",
    "start": 611.16,
    "duration": 4.859
  },
  {
    "text": "release Z1 Z2",
    "start": 613.08,
    "duration": 6.12
  },
  {
    "text": "all the way up to Z T and I'll just",
    "start": 616.019,
    "duration": 6.601
  },
  {
    "text": "call it Z 1 1 and so on and this would",
    "start": 619.2,
    "duration": 5.94
  },
  {
    "text": "give you Z One Z two although we have to",
    "start": 622.62,
    "duration": 6.54
  },
  {
    "text": "Z T and I'll call it z2s right now what",
    "start": 625.14,
    "duration": 5.16
  },
  {
    "text": "do I do with this I have two",
    "start": 629.16,
    "duration": 3.84
  },
  {
    "text": "representations now computed for this",
    "start": 630.3,
    "duration": 5.52
  },
  {
    "text": "word H1 to h t right so now what do I do",
    "start": 633.0,
    "duration": 4.92
  },
  {
    "text": "with these two Z's simple I just",
    "start": 635.82,
    "duration": 4.32
  },
  {
    "text": "concatenate them so that's all I'm going",
    "start": 637.92,
    "duration": 4.26
  },
  {
    "text": "to do",
    "start": 640.14,
    "duration": 4.259
  },
  {
    "text": "so you concatenate it so you get a",
    "start": 642.18,
    "duration": 4.5
  },
  {
    "text": "larger representation",
    "start": 644.399,
    "duration": 4.68
  },
  {
    "text": "and then you'd pass that to a linear",
    "start": 646.68,
    "duration": 4.98
  },
  {
    "text": "transformation right so we'll see that",
    "start": 649.079,
    "duration": 4.801
  },
  {
    "text": "uh soon and then what you get is the",
    "start": 651.66,
    "duration": 3.9
  },
  {
    "text": "final output right so what let's just",
    "start": 653.88,
    "duration": 3.36
  },
  {
    "text": "look at this carefully right what is",
    "start": 655.56,
    "duration": 4.98
  },
  {
    "text": "happening here so again let me just look",
    "start": 657.24,
    "duration": 5.719
  },
  {
    "text": "at some",
    "start": 660.54,
    "duration": 2.419
  },
  {
    "text": "it's important that I get rid of this",
    "start": 663.06,
    "duration": 5.519
  },
  {
    "text": "okay so this is the H here okay and",
    "start": 664.74,
    "duration": 7.08
  },
  {
    "text": "let's just focus on H1 right now H1",
    "start": 668.579,
    "duration": 6.841
  },
  {
    "text": "suppose H1 was uh five and two",
    "start": 671.82,
    "duration": 7.079
  },
  {
    "text": "dimensional vector right so now what I",
    "start": 675.42,
    "duration": 4.859
  },
  {
    "text": "could do is",
    "start": 678.899,
    "duration": 7.861
  },
  {
    "text": "uh I will choose W to be 512 cross 256.",
    "start": 680.279,
    "duration": 9.361
  },
  {
    "text": "okay I'm just giving you some example so",
    "start": 686.76,
    "duration": 5.639
  },
  {
    "text": "that means the projection which comes",
    "start": 689.64,
    "duration": 6.3
  },
  {
    "text": "out right my q k v would be 256",
    "start": 692.399,
    "duration": 4.981
  },
  {
    "text": "dimensional",
    "start": 695.94,
    "duration": 4.26
  },
  {
    "text": "right because it's 5 and 2 multiplied by",
    "start": 697.38,
    "duration": 5.519
  },
  {
    "text": "a 5 and 2 cross 256 Matrix right or",
    "start": 700.2,
    "duration": 4.319
  },
  {
    "text": "rather actually this would be",
    "start": 702.899,
    "duration": 3.361
  },
  {
    "text": "um",
    "start": 704.519,
    "duration": 3.601
  },
  {
    "text": "yeah so you get it it's I'll get I'll",
    "start": 706.26,
    "duration": 3.96
  },
  {
    "text": "just project it down so this will be 256",
    "start": 708.12,
    "duration": 4.74
  },
  {
    "text": "dimensional right so at the output again",
    "start": 710.22,
    "duration": 5.1
  },
  {
    "text": "I'll get 256 dimensional Z's in both the",
    "start": 712.86,
    "duration": 4.68
  },
  {
    "text": "cases now when they concatenate I again",
    "start": 715.32,
    "duration": 4.32
  },
  {
    "text": "get a five and two dimensional output",
    "start": 717.54,
    "duration": 4.2
  },
  {
    "text": "right and this I could again pass it",
    "start": 719.64,
    "duration": 4.199
  },
  {
    "text": "through whatever uh transformation I",
    "start": 721.74,
    "duration": 3.599
  },
  {
    "text": "want right for example I could choose a",
    "start": 723.839,
    "duration": 4.68
  },
  {
    "text": "512 cross 1024 I could choose a 512 plus",
    "start": 725.339,
    "duration": 6.601
  },
  {
    "text": "256 or I could choose a 512 cross 512",
    "start": 728.519,
    "duration": 5.701
  },
  {
    "text": "right and depending on that I will know",
    "start": 731.94,
    "duration": 4.079
  },
  {
    "text": "what my output Dimension would be if I",
    "start": 734.22,
    "duration": 4.2
  },
  {
    "text": "choose this then my Z final Z is coming",
    "start": 736.019,
    "duration": 4.981
  },
  {
    "text": "out of here would be 5 and 2 dimensional",
    "start": 738.42,
    "duration": 4.56
  },
  {
    "text": "right so let's just understand it",
    "start": 741.0,
    "duration": 5.279
  },
  {
    "text": "correctly so this H1 gave me a 256",
    "start": 742.98,
    "duration": 7.08
  },
  {
    "text": "dimensional Z1 this through this network",
    "start": 746.279,
    "duration": 5.521
  },
  {
    "text": "or through this self-attention it I got",
    "start": 750.06,
    "duration": 4.14
  },
  {
    "text": "another 256 dimensional H1 and then I",
    "start": 751.8,
    "duration": 6.0
  },
  {
    "text": "got 512 dimensional uh output here which",
    "start": 754.2,
    "duration": 5.34
  },
  {
    "text": "then again I pass it through a linear",
    "start": 757.8,
    "duration": 3.12
  },
  {
    "text": "transformation right so it's because",
    "start": 759.54,
    "duration": 3.72
  },
  {
    "text": "you're going to concatenate it makes",
    "start": 760.92,
    "duration": 5.099
  },
  {
    "text": "sense that you the output of each of",
    "start": 763.26,
    "duration": 4.44
  },
  {
    "text": "these is small right because if each of",
    "start": 766.019,
    "duration": 3.06
  },
  {
    "text": "these is five and two dimensional then",
    "start": 767.7,
    "duration": 2.879
  },
  {
    "text": "you concatenate you will keep going",
    "start": 769.079,
    "duration": 3.361
  },
  {
    "text": "larger right and typically you use eight",
    "start": 770.579,
    "duration": 4.141
  },
  {
    "text": "heads so now if each of this is five and",
    "start": 772.44,
    "duration": 3.42
  },
  {
    "text": "two dimensional",
    "start": 774.72,
    "duration": 2.88
  },
  {
    "text": "and then you concat it in them then",
    "start": 775.86,
    "duration": 3.0
  },
  {
    "text": "you'll get a four zero nine six",
    "start": 777.6,
    "duration": 3.179
  },
  {
    "text": "dimensional output here which is two",
    "start": 778.86,
    "duration": 3.479
  },
  {
    "text": "larger because it increases the size of",
    "start": 780.779,
    "duration": 3.0
  },
  {
    "text": "the parameters that will go through a",
    "start": 782.339,
    "duration": 3.661
  },
  {
    "text": "linear transformation and so on right so",
    "start": 783.779,
    "duration": 3.721
  },
  {
    "text": "typically what you do is if you want",
    "start": 786.0,
    "duration": 4.62
  },
  {
    "text": "five and two dimensional size here right",
    "start": 787.5,
    "duration": 4.92
  },
  {
    "text": "then you make sure that your each of",
    "start": 790.62,
    "duration": 3.54
  },
  {
    "text": "your eight heads gives you a 64",
    "start": 792.42,
    "duration": 3.479
  },
  {
    "text": "dimensional output so when you",
    "start": 794.16,
    "duration": 3.239
  },
  {
    "text": "concatenate then you get a five and two",
    "start": 795.899,
    "duration": 3.12
  },
  {
    "text": "dimensional output so you start with the",
    "start": 797.399,
    "duration": 3.361
  },
  {
    "text": "five and two dimensional output you",
    "start": 799.019,
    "duration": 3.661
  },
  {
    "text": "adjust these Dimensions such that you",
    "start": 800.76,
    "duration": 3.96
  },
  {
    "text": "get a 64 dimensional output at each of",
    "start": 802.68,
    "duration": 4.26
  },
  {
    "text": "these heads you have eight such heads so",
    "start": 804.72,
    "duration": 3.6
  },
  {
    "text": "when you concatenate them you'll again",
    "start": 806.94,
    "duration": 2.699
  },
  {
    "text": "get a five and two dimensional output",
    "start": 808.32,
    "duration": 3.0
  },
  {
    "text": "then you do an appropriate linear",
    "start": 809.639,
    "duration": 3.241
  },
  {
    "text": "transformation you could choose this one",
    "start": 811.32,
    "duration": 3.6
  },
  {
    "text": "so that your final z's are also five and",
    "start": 812.88,
    "duration": 3.78
  },
  {
    "text": "two Dimension right so that's what you",
    "start": 814.92,
    "duration": 4.44
  },
  {
    "text": "could do right so this is what a",
    "start": 816.66,
    "duration": 4.619
  },
  {
    "text": "two-headed attention would look like and",
    "start": 819.36,
    "duration": 3.479
  },
  {
    "text": "I've already told you how to extend it",
    "start": 821.279,
    "duration": 3.661
  },
  {
    "text": "to multi heads you will just have the",
    "start": 822.839,
    "duration": 5.521
  },
  {
    "text": "same block repeated as many times as you",
    "start": 824.94,
    "duration": 5.88
  },
  {
    "text": "want and then finally you would just",
    "start": 828.36,
    "duration": 4.919
  },
  {
    "text": "adjust all these",
    "start": 830.82,
    "duration": 4.92
  },
  {
    "text": "Transformations right so as I said I",
    "start": 833.279,
    "duration": 5.581
  },
  {
    "text": "could uh let's just look at it again if",
    "start": 835.74,
    "duration": 4.98
  },
  {
    "text": "my edges are five and two dimensional",
    "start": 838.86,
    "duration": 5.24
  },
  {
    "text": "these are H's",
    "start": 840.72,
    "duration": 3.38
  },
  {
    "text": "then I pass them through I multiply them",
    "start": 844.26,
    "duration": 6.36
  },
  {
    "text": "by a 64 cross 5 and 2 Matrix so I get 64",
    "start": 847.079,
    "duration": 5.641
  },
  {
    "text": "dimensional outputs here 64 dimensional",
    "start": 850.62,
    "duration": 4.44
  },
  {
    "text": "outputs here same happens in all the",
    "start": 852.72,
    "duration": 4.559
  },
  {
    "text": "eight heads so when I concatenate them I",
    "start": 855.06,
    "duration": 3.48
  },
  {
    "text": "get a five and two dimensional output",
    "start": 857.279,
    "duration": 3.18
  },
  {
    "text": "right so whatever I started with I get",
    "start": 858.54,
    "duration": 3.299
  },
  {
    "text": "the same so I can just adjust the",
    "start": 860.459,
    "duration": 3.301
  },
  {
    "text": "parameters accordingly and then I do a",
    "start": 861.839,
    "duration": 5.041
  },
  {
    "text": "linear transformation to get my final Z1",
    "start": 863.76,
    "duration": 5.639
  },
  {
    "text": "to ZT right",
    "start": 866.88,
    "duration": 4.259
  },
  {
    "text": "so remember this concatenation is",
    "start": 869.399,
    "duration": 4.38
  },
  {
    "text": "happening per word right that means uh",
    "start": 871.139,
    "duration": 4.681
  },
  {
    "text": "the Z1 representations coming out of",
    "start": 873.779,
    "duration": 4.381
  },
  {
    "text": "each of these are getting concatenated",
    "start": 875.82,
    "duration": 4.86
  },
  {
    "text": "here then the Z2 representations coming",
    "start": 878.16,
    "duration": 4.679
  },
  {
    "text": "out of each of these are getting",
    "start": 880.68,
    "duration": 4.56
  },
  {
    "text": "concatenated here right uh so it's per",
    "start": 882.839,
    "duration": 4.86
  },
  {
    "text": "word so the input is a set of words you",
    "start": 885.24,
    "duration": 4.68
  },
  {
    "text": "have capital t word embeddings and the",
    "start": 887.699,
    "duration": 4.921
  },
  {
    "text": "output at this layer or at every layer",
    "start": 889.92,
    "duration": 4.68
  },
  {
    "text": "right here here",
    "start": 892.62,
    "duration": 4.62
  },
  {
    "text": "here at all these layers the output is",
    "start": 894.6,
    "duration": 5.58
  },
  {
    "text": "again capital T embeddings right so",
    "start": 897.24,
    "duration": 5.039
  },
  {
    "text": "that's you should remember that",
    "start": 900.18,
    "duration": 4.82
  },
  {
    "text": "so we are done so we have the",
    "start": 902.279,
    "duration": 6.141
  },
  {
    "text": "multi-headed attention",
    "start": 905.0,
    "duration": 3.42
  },
  {
    "text": "okay so we are back to the basic block",
    "start": 909.24,
    "duration": 4.32
  },
  {
    "text": "that we had so this is what we had we",
    "start": 911.579,
    "duration": 6.06
  },
  {
    "text": "had these uh inputs coming in here right",
    "start": 913.56,
    "duration": 6.06
  },
  {
    "text": "and then now we have seen this self",
    "start": 917.639,
    "duration": 4.32
  },
  {
    "text": "attention in detail which could be a",
    "start": 919.62,
    "duration": 4.32
  },
  {
    "text": "multi-headed self attention and I gave",
    "start": 921.959,
    "duration": 5.641
  },
  {
    "text": "it inputs H1 H2 h t and then through all",
    "start": 923.94,
    "duration": 5.94
  },
  {
    "text": "the processing that happens inside I get",
    "start": 927.6,
    "duration": 4.859
  },
  {
    "text": "outputs I think I was calling these as",
    "start": 929.88,
    "duration": 6.18
  },
  {
    "text": "S1 S2 all the way up to s t right so",
    "start": 932.459,
    "duration": 5.341
  },
  {
    "text": "once I have got this now I need to",
    "start": 936.06,
    "duration": 3.06
  },
  {
    "text": "understand what happens in the feed",
    "start": 937.8,
    "duration": 3.779
  },
  {
    "text": "forward neural network right so let's uh",
    "start": 939.12,
    "duration": 5.219
  },
  {
    "text": "focus on that now right and this encoder",
    "start": 941.579,
    "duration": 4.801
  },
  {
    "text": "is typically a stacked encoder so you'll",
    "start": 944.339,
    "duration": 4.261
  },
  {
    "text": "have six such blocks here that's why I'm",
    "start": 946.38,
    "duration": 4.319
  },
  {
    "text": "calling this a basic building block this",
    "start": 948.6,
    "duration": 5.099
  },
  {
    "text": "is one layer right so you passed in H1",
    "start": 950.699,
    "duration": 6.421
  },
  {
    "text": "to h t you got out Z1 to ZT now this Z1",
    "start": 953.699,
    "duration": 5.58
  },
  {
    "text": "to ZT becomes input to another such",
    "start": 957.12,
    "duration": 4.32
  },
  {
    "text": "layer and again you get a new set of",
    "start": 959.279,
    "duration": 4.261
  },
  {
    "text": "representations out from your capital T",
    "start": 961.44,
    "duration": 3.959
  },
  {
    "text": "representations out right this way I've",
    "start": 963.54,
    "duration": 3.9
  },
  {
    "text": "seen that the output of one layer acts",
    "start": 965.399,
    "duration": 3.541
  },
  {
    "text": "as the input to the next layer right so",
    "start": 967.44,
    "duration": 3.959
  },
  {
    "text": "all of this this looks identical in all",
    "start": 968.94,
    "duration": 4.74
  },
  {
    "text": "these blocks and there could be 6 8 12",
    "start": 971.399,
    "duration": 3.781
  },
  {
    "text": "such blocks depending on the transform",
    "start": 973.68,
    "duration": 3.779
  },
  {
    "text": "architecture that you are looking at now",
    "start": 975.18,
    "duration": 3.42
  },
  {
    "text": "let's see what happens in the feed",
    "start": 977.459,
    "duration": 5.88
  },
  {
    "text": "forward Network so now you had uh",
    "start": 978.6,
    "duration": 7.679
  },
  {
    "text": "you so these are what the final output",
    "start": 983.339,
    "duration": 5.94
  },
  {
    "text": "is of the feed forward network is z this",
    "start": 986.279,
    "duration": 4.68
  },
  {
    "text": "intermediate output coming out of the",
    "start": 989.279,
    "duration": 3.781
  },
  {
    "text": "self attention I should have called it s",
    "start": 990.959,
    "duration": 5.641
  },
  {
    "text": "and this is the input H1 right so now",
    "start": 993.06,
    "duration": 5.16
  },
  {
    "text": "what exactly happens in the feed forward",
    "start": 996.6,
    "duration": 4.14
  },
  {
    "text": "neural network right nothing it's quite",
    "start": 998.22,
    "duration": 4.919
  },
  {
    "text": "simple so remember that each of these",
    "start": 1000.74,
    "duration": 4.519
  },
  {
    "text": "guys here is a five and two dimensional",
    "start": 1003.139,
    "duration": 4.44
  },
  {
    "text": "representation or some D dimensional",
    "start": 1005.259,
    "duration": 4.241
  },
  {
    "text": "representation it is going to pass",
    "start": 1007.579,
    "duration": 3.361
  },
  {
    "text": "through a feed forward neutral Network",
    "start": 1009.5,
    "duration": 3.3
  },
  {
    "text": "and again give you a d dimensional",
    "start": 1010.94,
    "duration": 3.3
  },
  {
    "text": "representation at the output right",
    "start": 1012.8,
    "duration": 3.06
  },
  {
    "text": "that's all that is happening here so",
    "start": 1014.24,
    "duration": 3.06
  },
  {
    "text": "feed forward neural network is only",
    "start": 1015.86,
    "duration": 4.8
  },
  {
    "text": "acting as a projection layer here right",
    "start": 1017.3,
    "duration": 6.779
  },
  {
    "text": "so uh",
    "start": 1020.66,
    "duration": 3.419
  },
  {
    "text": "so this is the input",
    "start": 1024.799,
    "duration": 5.04
  },
  {
    "text": "S1 okay there's some intermediate being",
    "start": 1026.839,
    "duration": 6.48
  },
  {
    "text": "computed let me just call it uh say m",
    "start": 1029.839,
    "duration": 7.201
  },
  {
    "text": "okay right and then you get Z1 at the",
    "start": 1033.319,
    "duration": 6.12
  },
  {
    "text": "output right so this could again be five",
    "start": 1037.04,
    "duration": 4.379
  },
  {
    "text": "and two dimensional input one zero two",
    "start": 1039.439,
    "duration": 3.36
  },
  {
    "text": "four dimensional projection and then",
    "start": 1041.419,
    "duration": 3.361
  },
  {
    "text": "again five into dimensional output and",
    "start": 1042.799,
    "duration": 3.421
  },
  {
    "text": "of course there would be a non-linearity",
    "start": 1044.78,
    "duration": 4.2
  },
  {
    "text": "here you could use any non-linearity",
    "start": 1046.22,
    "duration": 6.36
  },
  {
    "text": "that you want right and typically it is",
    "start": 1048.98,
    "duration": 6.78
  },
  {
    "text": "one of the relu based either gelu or one",
    "start": 1052.58,
    "duration": 6.12
  },
  {
    "text": "of those normal non-linearities",
    "start": 1055.76,
    "duration": 5.48
  },
  {
    "text": "okay",
    "start": 1058.7,
    "duration": 2.54
  },
  {
    "text": "and the same set of parameters right so",
    "start": 1061.7,
    "duration": 5.16
  },
  {
    "text": "this here would have some parameters",
    "start": 1064.28,
    "duration": 4.38
  },
  {
    "text": "right so you'll have some W's here and",
    "start": 1066.86,
    "duration": 4.5
  },
  {
    "text": "then some another set of W's here right",
    "start": 1068.66,
    "duration": 6.0
  },
  {
    "text": "so let me just call them W Feed forward",
    "start": 1071.36,
    "duration": 5.4
  },
  {
    "text": "Network and let me call this W1 because",
    "start": 1074.66,
    "duration": 4.56
  },
  {
    "text": "it's layer 1 and W2 Layer Two right so",
    "start": 1076.76,
    "duration": 4.74
  },
  {
    "text": "the same set of parameters will be used",
    "start": 1079.22,
    "duration": 5.76
  },
  {
    "text": "everywhere right so each of these s1s or",
    "start": 1081.5,
    "duration": 6.419
  },
  {
    "text": "sis will pass to the same transition and",
    "start": 1084.98,
    "duration": 4.92
  },
  {
    "text": "give you the corresponding zi right so",
    "start": 1087.919,
    "duration": 3.901
  },
  {
    "text": "that's what I'm going to show with the",
    "start": 1089.9,
    "duration": 4.68
  },
  {
    "text": "animation that the same network is",
    "start": 1091.82,
    "duration": 6.44
  },
  {
    "text": "essentially being used everywhere",
    "start": 1094.58,
    "duration": 3.68
  },
  {
    "text": "right so you get this",
    "start": 1098.84,
    "duration": 8.339
  },
  {
    "text": "same output everywhere right so this uh",
    "start": 1101.299,
    "duration": 5.88
  },
  {
    "text": "yeah so you have the same network for",
    "start": 1107.48,
    "duration": 5.939
  },
  {
    "text": "each position and uh you use this uh as",
    "start": 1108.98,
    "duration": 6.68
  },
  {
    "text": "the",
    "start": 1113.419,
    "duration": 2.241
  },
  {
    "text": "this is the non-linearity that you're",
    "start": 1116.36,
    "duration": 5.04
  },
  {
    "text": "going to uh use right uh",
    "start": 1117.86,
    "duration": 5.1
  },
  {
    "text": "so nothing great happening within the",
    "start": 1121.4,
    "duration": 2.639
  },
  {
    "text": "feed forward neural network whatever",
    "start": 1122.96,
    "duration": 3.42
  },
  {
    "text": "output the multi-headed attention gives",
    "start": 1124.039,
    "duration": 5.64
  },
  {
    "text": "it just projects it and then gives you",
    "start": 1126.38,
    "duration": 5.159
  },
  {
    "text": "back a final output right so that's all",
    "start": 1129.679,
    "duration": 5.941
  },
  {
    "text": "we have done uh with the uh",
    "start": 1131.539,
    "duration": 6.921
  },
  {
    "text": "so that's all we are done with the uh",
    "start": 1135.62,
    "duration": 5.76
  },
  {
    "text": "encoder layer right so this is one layer",
    "start": 1138.46,
    "duration": 4.959
  },
  {
    "text": "of the encoder and now I could stack",
    "start": 1141.38,
    "duration": 3.78
  },
  {
    "text": "many such layers but each layer the",
    "start": 1143.419,
    "duration": 3.421
  },
  {
    "text": "internal working would remain the same",
    "start": 1145.16,
    "duration": 3.66
  },
  {
    "text": "just the output of the previous layer",
    "start": 1146.84,
    "duration": 3.36
  },
  {
    "text": "will be the input to this layer so",
    "start": 1148.82,
    "duration": 3.0
  },
  {
    "text": "nothing else changes right so we are",
    "start": 1150.2,
    "duration": 3.78
  },
  {
    "text": "done with the encoder part of the",
    "start": 1151.82,
    "duration": 4.38
  },
  {
    "text": "Transformer so the encoder is composed",
    "start": 1153.98,
    "duration": 3.96
  },
  {
    "text": "of n such identical layers and each",
    "start": 1156.2,
    "duration": 3.18
  },
  {
    "text": "layer is composed of these two sub",
    "start": 1157.94,
    "duration": 3.239
  },
  {
    "text": "layers one is the multi-headed attention",
    "start": 1159.38,
    "duration": 4.02
  },
  {
    "text": "and the other is the feed forward neural",
    "start": 1161.179,
    "duration": 4.921
  },
  {
    "text": "network uh and",
    "start": 1163.4,
    "duration": 4.62
  },
  {
    "text": "so the computer is computation is",
    "start": 1166.1,
    "duration": 3.24
  },
  {
    "text": "paralyzed in the horizontal direction",
    "start": 1168.02,
    "duration": 3.12
  },
  {
    "text": "right so what do I mean by that is that",
    "start": 1169.34,
    "duration": 3.839
  },
  {
    "text": "you of course so if you have these n",
    "start": 1171.14,
    "duration": 3.659
  },
  {
    "text": "layers right of course you cannot",
    "start": 1173.179,
    "duration": 3.841
  },
  {
    "text": "compute all the layers in parallel right",
    "start": 1174.799,
    "duration": 4.74
  },
  {
    "text": "because layer 2 will take the output of",
    "start": 1177.02,
    "duration": 4.14
  },
  {
    "text": "layer 1 as input right so unless you",
    "start": 1179.539,
    "duration": 3.661
  },
  {
    "text": "have done the layer 1 computation you",
    "start": 1181.16,
    "duration": 3.42
  },
  {
    "text": "cannot do the layer to computation right",
    "start": 1183.2,
    "duration": 3.359
  },
  {
    "text": "so when I say it's parallelized it's",
    "start": 1184.58,
    "duration": 5.219
  },
  {
    "text": "only within each layer right so for a",
    "start": 1186.559,
    "duration": 5.12
  },
  {
    "text": "given uh set of",
    "start": 1189.799,
    "duration": 5.641
  },
  {
    "text": "input samples right within that layer",
    "start": 1191.679,
    "duration": 6.581
  },
  {
    "text": "all the self attentions all the alphas",
    "start": 1195.44,
    "duration": 5.46
  },
  {
    "text": "all these Z they'll all get computed in",
    "start": 1198.26,
    "duration": 4.62
  },
  {
    "text": "parallel right unless I mean earlier",
    "start": 1200.9,
    "duration": 4.08
  },
  {
    "text": "when uh again I'll just repeat this",
    "start": 1202.88,
    "duration": 4.2
  },
  {
    "text": "because this is important in the case of",
    "start": 1204.98,
    "duration": 5.1
  },
  {
    "text": "an RNN when you are given H1 to h t and",
    "start": 1207.08,
    "duration": 6.9
  },
  {
    "text": "you had to compute Z1 to ZT right you",
    "start": 1210.08,
    "duration": 6.42
  },
  {
    "text": "first had to compute Z1 z2's and ZT and",
    "start": 1213.98,
    "duration": 4.319
  },
  {
    "text": "so on right and here we saw that using",
    "start": 1216.5,
    "duration": 3.66
  },
  {
    "text": "this large Matrix multiplications we get",
    "start": 1218.299,
    "duration": 4.321
  },
  {
    "text": "Z1 to ZT in parallel right you don't",
    "start": 1220.16,
    "duration": 4.44
  },
  {
    "text": "have to wait for the previous time step",
    "start": 1222.62,
    "duration": 3.36
  },
  {
    "text": "for the next time step to be computed",
    "start": 1224.6,
    "duration": 2.88
  },
  {
    "text": "right so this parallelism you see in",
    "start": 1225.98,
    "duration": 3.72
  },
  {
    "text": "every layer but of course across layers",
    "start": 1227.48,
    "duration": 4.319
  },
  {
    "text": "the computation is still sequential",
    "start": 1229.7,
    "duration": 3.12
  },
  {
    "text": "right because you need the previous",
    "start": 1231.799,
    "duration": 3.0
  },
  {
    "text": "layers output to do the next layers",
    "start": 1232.82,
    "duration": 4.92
  },
  {
    "text": "computation you have the input then the",
    "start": 1234.799,
    "duration": 5.461
  },
  {
    "text": "layer one outputs get computed then it",
    "start": 1237.74,
    "duration": 4.5
  },
  {
    "text": "feeds to Layer Two and so on till the",
    "start": 1240.26,
    "duration": 5.039
  },
  {
    "text": "end and each of these T cross 5 and 2",
    "start": 1242.24,
    "duration": 6.059
  },
  {
    "text": "outputs get computed in parallel right",
    "start": 1245.299,
    "duration": 6.12
  },
  {
    "text": "and now this final output of the uh",
    "start": 1248.299,
    "duration": 4.921
  },
  {
    "text": "encoder right which is the output from",
    "start": 1251.419,
    "duration": 4.561
  },
  {
    "text": "the last layer we are going to denote it",
    "start": 1253.22,
    "duration": 6.12
  },
  {
    "text": "as e right so we'll refer to it as E1 to",
    "start": 1255.98,
    "duration": 6.0
  },
  {
    "text": "E capital T because there are t such",
    "start": 1259.34,
    "duration": 5.219
  },
  {
    "text": "tokens in the input and for each token",
    "start": 1261.98,
    "duration": 4.98
  },
  {
    "text": "you get this final refine representation",
    "start": 1264.559,
    "duration": 4.681
  },
  {
    "text": "which is contextual as well as gone",
    "start": 1266.96,
    "duration": 4.56
  },
  {
    "text": "through several layers of abstraction or",
    "start": 1269.24,
    "duration": 5.54
  },
  {
    "text": "several deep layers right",
    "start": 1271.52,
    "duration": 3.26
  }
]