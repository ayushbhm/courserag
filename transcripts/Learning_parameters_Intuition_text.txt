[Music] okay so now let's talk about some intuition behind the intuition behind uh learning parameters for a feed forward neural network right and how do we connect it to what we already know right we have already seen how to learn parameters of a very simple network i mean it's not even a network but for a single neuron which had a w and a b and a single input and there was a y hat we had seen how to learn the parameters of this network using gradient descent now this thing that we know and understand well can we somehow stretch it and extend it to help us learn the parameters of all the parameters of a feed forward neural network right so that's what we'll try to focus on okay uh so the story so far is that we have introduced feed forward neural networks and now we are interested in finding an algorithm for learning the parameter right so this is what our feed forward neural network looks like now let's just quickly recall our gradient descent algorithm and make some commentary on that right so this is what our gradient descent algorithm was we had initialized the weights and then at every step we were updating the weights right and now i can think of writing this a bit more compactly right in fact we had looked at it already i know that this i could write it as a vector theta t plus 1 similarly this i could write it as theta t and this i could write it as a vector gradient right the gradient and this also i could write it as a vector theta naught right so i am going now going to change this equation and write it more compactly where i am going to replace the collection of w and b by theta right that's the only change i am going to do and that's fair enough this is how i'm going to write it more compactly so theta naught is the collection of w naught b naught and once you understand that this falls in place right so theta t plus 1 is just now w t plus one comma b t plus one and you're just doing vector uh operations now instead of like individual uh element wise operations right and that's perfectly fine as we saw in the previous slide where i had annotated the vectors right so there's nothing wrong here and where the gradient right so when i say grad delta theta right i am going to use this notation right the more appropriate elaborate notation would be gradient of the loss function with theta evaluated at time t right but i'm just going to use this shortcut notation and hence i am elaborating what i mean by that it means just the collection of the partial derivatives right so i've taken the partial derivative with this of the loss function with respect to wt the partial derivative of the loss function with respect to b it's not bt or wt it's w and b and then evaluated at the current values right which is at time step t and we have seen this what that means in the previous lecture so this is what my this notation here means right i am just clarifying that is just a collection of the partial derivatives that means it is the gradient right now this was all uh good right now in this feed forward neutral network instead of theta equal to wb right which was just a collection of two vectors now my theta is a collection of many more elements right it's all the elements of w1 which is n square elements all the elements of w2 w3 which are again n square elements and then elements of wl which is n into k then all the biases there were n biases in layer one n biases in layer two and then k in layer three right all of this collected together so i have a large army of parameters now instead of just two parameters right but if i'm going to write theta as a collection of all the parameters i can still do that i'm just going to say that theta is a collection of all the parameters earlier my vectors were of size 2 now my vectors are very large right there n square plus n square plus n into k plus n plus n plus k right in this specific example so it's a very large vector so what it's still just a vector and all these operations still can hold it just as i can add two dimensional vectors or subtract one vector from another i can do the same for these very large dimensional vectors also right so you can still use the same algorithm for learning the parameters of our model except that now earlier remember there were only these two quantities and we still had to derive this side we still had derived painfully what is the equation or what is the expression for the derivative of the loss function with respect to w what is the expression for the derivative of the loss function with respect to b and then substituted values in that right so we still have to do that computation right so it's just that our gradient of del theta now looks like a very very big vector and we should know how to compute every quantity in this vector right and we did this for those two simple values w and b and that itself was quite a bit of a derivation so our quest would be somehow come up with a formula which allows us to compute all of this at one go right without painfully deriving that in fact we'll derive it but we derive it in such a way that we could compute an entire matrix of their partial derivatives at one go instead of computing each of those n square values one by one right so that's what one of the quests of this lecture is going to be but that's all for later for now i want you to focus on this graduation from theta naught being a collection of two elements to theta naught being a collection of many elements but as long as i can tell you what these are the same algorithm still applies right because you just want to compute the derivative of the loss function with respect to each parameter and update the parameter accordingly right so insects now our delta theta looks much more complex so we have delta t the loss derivative of the loss partial derivative of the loss function with respect to w 1 1 1 that is the first weight in w1 matrix all the way up to the n square weights that you have in the w1 matrix similarly the n square weights that you have in the w2 matrix similarly the n into k weights that you had in the last layer similarly the n biases that you had in each layer and the k biases that you had in the last layer right so this is not like a something cross n matrix right because this last row has only k right so it will not be like uh i just put everything together in one collection i'm not saying that this is a matrix right this is just a collection of partial derivatives because each layer might have different so i just assume everything is n square here but we saw that other example where it could be n cross m here then m cross p here then some n here m here and then k here right for the biases right so it's all going to be different across different layers so this is not like a well-formed matrix it's just a collection i have put together just for illustrative purpose right so these are all the partial derivatives that i need to collect and i should be able to do this fairly uh conveniently and not like painfully go over every element and have to write down the formula for that and compute right i should be able to at least take one entire matrix of weights and compute the partial derivatives of all the elements at one goal right so that's what my quest is going to be but if i can do that then i am done right so this is where we are this is what the intuition is you can use the gradient descent algorithm as it is provided you have these quantities so we need to answer two questions how to choose the loss function why do we need to answer this question because we need to compute the partial derivatives of the loss function with respect to the weights right so unless i know what the loss function is i can't even start writing down what that formula is going to be so i need to know how to choose the loss function and once we choose the loss function i need to compute every element of the gradient vector right which is the partial derivatives with respect to all the weights that i had in the network right so if i know these two then i'll just come back to my gradient descent algorithm and i can find the i can learn the parameters right so that's the intuition this idea should be clear that while we have graduated from that two parameter case to like a very large number of parameters case the basic idea still remains the same i just need to be able to compute the partial derivatives of the loss function with respect to the weights if i can do that i can run gradient descent and to compute that i need to know the loss function and i need to know how to compute the partial derivative so that's what we are going to do uh in today's lecture right so this is going to be a very long lecture but this is what we are going to do okay